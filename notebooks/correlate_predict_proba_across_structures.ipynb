{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ec386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# from dynamic_routing_analysis import decoding_utils\n",
    "# from dynamic_routing_analysis import plot_utils\n",
    "# import dynamic_routing_analysis as dra\n",
    "import pingouin as pg\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 8\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "fm.FontProperties().set_family('arial')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# %matplotlib widget\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7800a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/decode_context_no_baseline_subtract_aud_stim_10ms_bins_10_units_0/\"\n",
    "results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/decode_context_no_baseline_subtract_vis_stim_10ms_bins_10_units_0/\"\n",
    "\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/decode_context_w_shifts_min_10_units_500ms_0/\"\n",
    "# results_path=\"s3://aind-scratch-data/dynamic-routing/decoding/results/time_mod_keep_units_consistent_0/\"\n",
    "\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/decode_context_10ms_no_baseline_subtract_0/\"\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/baseline_subtract_10ms_step_50ms_window_0/\"\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/baseline_subtract_10ms_step_50ms_window_aud_target_0/\"\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/baseline_subtract_10ms_step_50ms_window_vis_target_0/\"\n",
    "\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/baseline_subtract_10ms_step_50ms_window_decode_response_0/\"\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/baseline_subtract_10ms_step_50ms_window_decode_response_aud_target_0/\"\n",
    "# results_path = r\"s3://aind-scratch-data/dynamic-routing/decoding/results/baseline_subtract_10ms_step_50ms_window_decode_response_vis_target_0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_table_path=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\CO decoding results\\session_table_v0.268.csv\"\n",
    "# session_table_path=\"/Users/ethan.mcbride/Data/DR/session_table_v0.265.csv\"\n",
    "session_table=pl.read_csv(session_table_path)\n",
    "\n",
    "dr_session_list=(\n",
    "    session_table.filter(\n",
    "    pl.col('project')==\"DynamicRouting\",\n",
    "    pl.col('is_production'),\n",
    "    pl.col('is_annotated'),\n",
    "    pl.col('issues')==\"\",\n",
    "    # pl.col('is_good_behavior').eq(True),\n",
    "    )['session_id'].to_list()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define grouping columns\n",
    "grouping_cols = {\n",
    "    'session_id',\n",
    "    'structure',\n",
    "    'electrode_group_names',\n",
    "    'unit_subsample_size',\n",
    "    'bin_center',\n",
    "    'bin_size',\n",
    "    'time_aligned_to',\n",
    "    # 'unit_criteria',\n",
    "}\n",
    "\n",
    "#toggle combine_multi_probe_rec\n",
    "combine_multi_probe_rec = True\n",
    "\n",
    "if combine_multi_probe_rec:\n",
    "    combine_multi_probe_expr = pl.col('electrode_group_names').list.len().gt(1) | pl.col('is_sole_recording').eq(True)\n",
    "else:\n",
    "    combine_multi_probe_expr = pl.col('electrode_group_names').list.len().eq(1) | pl.col('is_sole_recording').eq(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "structure_grouping = {\n",
    "    'SCop': 'SCs',\n",
    "    'SCsg': 'SCs',\n",
    "    'SCzo': 'SCs',\n",
    "    'SCig': 'SCm',\n",
    "    'SCiw': 'SCm',\n",
    "    'SCdg': 'SCm',\n",
    "    'SCdw': 'SCm',\n",
    "    \"ECT1\": 'ECT',\n",
    "    \"ECT2/3\": 'ECT',    \n",
    "    \"ECT6b\": 'ECT',\n",
    "    \"ECT5\": 'ECT',\n",
    "    \"ECT6a\": 'ECT', \n",
    "    \"ECT4\": 'ECT',\n",
    "}\n",
    "keep_original_structure = False\n",
    "if keep_original_structure:\n",
    "    n_repeats = 2\n",
    "else:\n",
    "    n_repeats = 1\n",
    "\n",
    "predict_proba_wo_repeats = (\n",
    "    pl.scan_parquet(results_path)\n",
    "    #make new column that indicates whether a row is the sole recording from a structure in a session\n",
    "    .with_columns(\n",
    "        pl.col('electrode_group_names').flatten().n_unique().eq(1).over(grouping_cols - {'electrode_group_names'}).alias('is_sole_recording'),     \n",
    "    )\n",
    "    #Grab only rows according to combine_multi_probe_rec toggle\n",
    "    #Grab only rows that have is_all_trials == True, only these have predict_proba\n",
    "    .filter(\n",
    "        combine_multi_probe_expr,\n",
    "        pl.col('is_all_trials'),\n",
    "    )\n",
    "    #join on the units table to get total number of units per structure\n",
    "    .join(\n",
    "        other=(\n",
    "            pl.scan_parquet('s3://aind-scratch-data/dynamic-routing/cache/nwb_components/v0.0.268/consolidated/units.parquet')\n",
    "            .with_columns(\n",
    "                pl.col('session_id').str.split('_').list.slice(0, 2).list.join('_'),\n",
    "            )\n",
    "            #make new rows according to structure_grouping\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('structure').is_in(structure_grouping.keys()))\n",
    "                .then(pl.col('structure').repeat_by(n_repeats))\n",
    "                .otherwise(pl.col('structure').repeat_by(1))\n",
    "            )\n",
    "            .explode('structure')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('structure').is_in(structure_grouping.keys()).is_first_distinct().over('unit_id'))\n",
    "                .then(pl.col('structure').replace(structure_grouping))\n",
    "                .otherwise(pl.col('structure'))\n",
    "            )\n",
    "            .group_by('session_id','structure')\n",
    "            .agg(\n",
    "                pl.col('unit_id').len().alias('total_n_units')\n",
    "            )\n",
    "        ),\n",
    "        on=['session_id','structure'],\n",
    "        how='left',\n",
    "    )\n",
    "    .with_columns(\n",
    "        # pl.int_ranges(0, pl.col('predict_proba').list.len()).alias('trial_index')\n",
    "        pl.col('trial_indices').alias('trial_index')\n",
    "    )\n",
    "    .drop('shift_idx', 'is_all_trials', 'electrode_group_names', 'unit_criteria', 'is_sole_recording')\n",
    "    .explode('predict_proba', 'trial_index')\n",
    "    .group_by('session_id', 'structure', 'unit_subsample_size', 'trial_index', 'bin_center', 'bin_size', 'time_aligned_to',)\n",
    "    .agg(\n",
    "        pl.col('balanced_accuracy_test').mean(),\n",
    "        pl.col('predict_proba').mean(),\n",
    "        pl.col('total_n_units').first(),\n",
    "        # pl.col('unit_ids').first(),\n",
    "    )\n",
    "    .join(\n",
    "        other=(\n",
    "            pl.scan_parquet('s3://aind-scratch-data/dynamic-routing/cache/nwb_components/v0.0.268/consolidated/trials.parquet')\n",
    "            .with_columns(\n",
    "                pl.col('session_id').str.split('_').list.slice(0, 2).list.join('_'),\n",
    "                #iti column?\n",
    "            )\n",
    "            .select('session_id', 'trial_index', 'is_vis_rewarded', 'stim_name', 'is_response')\n",
    "        ),\n",
    "        on=['session_id','trial_index'],\n",
    "        how='inner',\n",
    "    ) \n",
    "    .group_by('session_id', 'structure', 'unit_subsample_size', 'bin_center', 'time_aligned_to',)\n",
    "    .agg(\n",
    "        pl.col('balanced_accuracy_test').first(),\n",
    "        pl.col('total_n_units').first(),\n",
    "        # pl.col('unit_ids').first(),\n",
    "        pl.col('predict_proba', 'trial_index', 'is_vis_rewarded', 'stim_name', 'is_response').sort_by('trial_index'),\n",
    "\n",
    "    )\n",
    "    .sort('session_id','structure', 'unit_subsample_size', 'bin_center')\n",
    "    # .group_by('session_id','structure')\n",
    "    .collect(engine='streaming')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_pd=predict_proba_wo_repeats.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfdb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_performance=pl.scan_parquet('s3://aind-scratch-data/dynamic-routing/cache/nwb_components/v0.0.268/consolidated/performance.parquet').collect()#.to_pandas()\n",
    "all_trials=pl.scan_parquet('s3://aind-scratch-data/dynamic-routing/cache/nwb_components/v0.0.268/consolidated/trials.parquet').collect()#.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead42b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials.filter(\n",
    "    pl.col('session_id').is_in(dr_session_list).not_(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59741cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_session_structure_results(predict_proba_pd, sel_session, sel_structure, sel_unit_subsample_size, sel_time_aligned_to):\n",
    "    \"\"\"\n",
    "    Get the results for a specific session and structure.\n",
    "    \"\"\"\n",
    "    \n",
    "    if sel_time_aligned_to=='response_time':\n",
    "        if sel_unit_subsample_size=='all':\n",
    "            temp_trial_info=predict_proba_pd.query(f'session_id==\"{sel_session}\" and structure==\"{sel_structure}\" and \\\n",
    "                                                        time_aligned_to==\"stim_start_time\" and unit_subsample_size.isna()'\n",
    "                                                        ).sort_values('bin_center').iloc[0]\n",
    "        else:\n",
    "            temp_trial_info=predict_proba_pd.query(f'session_id==\"{sel_session}\" and structure==\"{sel_structure}\" and \\\n",
    "                                                    time_aligned_to==\"stim_start_time\" and unit_subsample_size=={sel_unit_subsample_size}'\n",
    "                                                    ).sort_values('bin_center').iloc[0]\n",
    "        \n",
    "        trial_index=temp_trial_info['trial_index'][temp_trial_info['is_response']]\n",
    "        is_vis_rewarded=temp_trial_info['is_vis_rewarded'][temp_trial_info['is_response']]\n",
    "        stim_name=temp_trial_info['stim_name'][temp_trial_info['is_response']]\n",
    "        is_response=temp_trial_info['is_response'][temp_trial_info['is_response']]\n",
    "        \n",
    "        if sel_unit_subsample_size=='all':\n",
    "            example_area_results=predict_proba_pd.query(f'session_id==\"{sel_session}\" and structure==\"{sel_structure}\" and \\\n",
    "                                                        time_aligned_to==\"response_time\" and unit_subsample_size.isna()'\n",
    "                                                        ).sort_values('bin_center').reset_index(drop=True)\n",
    "        else:\n",
    "            example_area_results=predict_proba_pd.query(f'session_id==\"{sel_session}\" and structure==\"{sel_structure}\" and \\\n",
    "                                                        time_aligned_to==\"response_time\" and unit_subsample_size=={sel_unit_subsample_size}'\n",
    "                                                        ).sort_values('bin_center').reset_index(drop=True)\n",
    "        trial_index_list=[]\n",
    "        is_vis_rewarded_list=[]\n",
    "        stim_name_list=[]\n",
    "        is_response_list=[]\n",
    "        for rr in range(len(example_area_results)):\n",
    "            trial_index_list.append(trial_index)\n",
    "            is_vis_rewarded_list.append(is_vis_rewarded)\n",
    "            stim_name_list.append(stim_name)\n",
    "            is_response_list.append(is_response)\n",
    "\n",
    "        example_area_results['trial_index']=trial_index_list\n",
    "        example_area_results['is_vis_rewarded']=is_vis_rewarded_list\n",
    "        example_area_results['stim_name']=stim_name_list\n",
    "        example_area_results['is_response']=is_response_list\n",
    "\n",
    "    else:\n",
    "        if sel_unit_subsample_size=='all':\n",
    "            example_area_results=predict_proba_pd.query(f'session_id==\"{sel_session}\" and structure==\"{sel_structure}\" and \\\n",
    "                                                        time_aligned_to==\"{sel_time_aligned_to}\" and unit_subsample_size.isna()'\n",
    "                                                        ).sort_values('bin_center').reset_index(drop=True)\n",
    "        else:\n",
    "            example_area_results=predict_proba_pd.query(f'session_id==\"{sel_session}\" and structure==\"{sel_structure}\" and \\\n",
    "                                                        time_aligned_to==\"{sel_time_aligned_to}\" and unit_subsample_size=={sel_unit_subsample_size}'\n",
    "                                                        ).sort_values('bin_center').reset_index(drop=True)\n",
    "    #get context switches\n",
    "    is_context_switch=np.concatenate([[0],np.diff(example_area_results['is_vis_rewarded'].iloc[0])]).astype(bool)\n",
    "    context_switch_list=[]\n",
    "    for rr in range(len(example_area_results)):\n",
    "        context_switch_list.append(is_context_switch)\n",
    "    example_area_results['is_context_switch']=context_switch_list\n",
    "\n",
    "\n",
    "    return example_area_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae99fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_pd['bin_center'].unique()\n",
    "# structure_results_0['bin_center'].iloc[17]\n",
    "# structure_results_1.query('bin_center==0.1')['predict_proba'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d266931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure_results_0.query(f'bin_center==({sel_time_bin})')['trial_index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example correlations\n",
    "\n",
    "sel_session=\"664851_2023-11-13\"\n",
    "sel_structure_0=\"ACAd\"\n",
    "sel_structure_1=\"SCm\"\n",
    "# sel_session=\"670180_2023-07-27\"\n",
    "# sel_structure_0=\"PL\"\n",
    "# sel_structure_1=\"ACAd\"\n",
    "sel_time_bin=0.105 #-0.25 #0.105\n",
    "correction='flip_aud' #'subtract_mean' or 'flip_aud'\n",
    "excl_instruction_trials=True\n",
    "sel_unit_subsample_size='all'\n",
    "sel_time_aligned_to='stim_start_time'\n",
    "\n",
    "structure_results_0=get_session_structure_results(predict_proba_pd, sel_session, sel_structure_0, sel_unit_subsample_size, sel_time_aligned_to)\n",
    "structure_results_1=get_session_structure_results(predict_proba_pd, sel_session, sel_structure_1, sel_unit_subsample_size, sel_time_aligned_to)\n",
    "\n",
    "structure_results_0['bin_center']=structure_results_0['bin_center'].round(3)\n",
    "structure_results_1['bin_center']=structure_results_1['bin_center'].round(3)\n",
    "\n",
    "predict_proba_0=structure_results_0.query(f'bin_center==({sel_time_bin})')['predict_proba'].values[0]\n",
    "predict_proba_1=structure_results_1.query(f'bin_center==({sel_time_bin})')['predict_proba'].values[0]\n",
    "\n",
    "trial_indices_0=structure_results_0.query(f'bin_center==({sel_time_bin})')['trial_index'].values[0]\n",
    "trial_indices_1=structure_results_1.query(f'bin_center==({sel_time_bin})')['trial_index'].values[0]\n",
    "\n",
    "session_trials=all_trials.filter(\n",
    "    pl.col('session_id').eq(sel_session),\n",
    "    pl.col('trial_index').is_in(trial_indices_0),\n",
    "    pl.col('trial_index').is_in(trial_indices_1)\n",
    ").sort('trial_index')\n",
    "\n",
    "block_switches=session_trials.to_pandas().query('is_block_switch')['trial_index'].values\n",
    "\n",
    "r,p=stats.pearsonr(predict_proba_0, predict_proba_1)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(7,3))\n",
    "\n",
    "for bb in block_switches:\n",
    "    ax.axvline(x=bb, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axhline(y=0.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax.plot(trial_indices_0, predict_proba_0, label=sel_structure_0, color='tab:blue', alpha=0.5, linewidth=0.75)\n",
    "ax.plot(trial_indices_1, predict_proba_1, label=sel_structure_1, color='tab:orange', alpha=0.5, linewidth=0.75)\n",
    "ax.set_title(f\"Pearson correlation between {sel_structure_0} and {sel_structure_1} at {sel_time_bin}s: r={r:.3f}, p={p:.3e}\")\n",
    "ax.set_xlabel('Trial index')\n",
    "ax.set_ylabel('Predict probability')\n",
    "ax.legend()\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(3,3))\n",
    "ax.plot(predict_proba_0,predict_proba_1,'k.',alpha=0.5)\n",
    "#plot diagonal line\n",
    "ax.plot([0, 1], [0, 1], color='black', linestyle='-', linewidth=0.5)\n",
    "#fit line to data\n",
    "fit_line = np.polyfit(predict_proba_0, predict_proba_1, 1)\n",
    "ax.plot(np.array([0, 1]), np.polyval(fit_line, np.array([0, 1])), color='red', linestyle='-', linewidth=1)\n",
    "ax.set_xlabel(sel_structure_0)\n",
    "ax.set_ylabel(sel_structure_1)\n",
    "ax.set_xlim(0.1, 1)\n",
    "ax.set_ylim(0.1, 1)\n",
    "\n",
    "if (\n",
    "    session_trials['block_index'].n_unique() == 1\n",
    "    and not (\n",
    "        session_table.filter(\n",
    "            pl.col('session_id') == session_trials['session_id'][0],\n",
    "            pl.col('is_templeton'),\n",
    "        )\n",
    "    ).is_empty()\n",
    "):\n",
    "    print(f'Adding dummy context labels for Templeton session {sel_session}')\n",
    "    session_trials = (\n",
    "        session_trials\n",
    "        .with_columns(\n",
    "            pl.col('start_time').sub(pl.col('start_time').min().over('session_id')).truediv(10*60).floor().clip(0, 5).alias('block_index')\n",
    "            # short 7th block will sometimes be present: merge into 6th with clip\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('block_index').mod(2).eq(random.choice([0, 1])))\n",
    "            .then(pl.lit('vis'))\n",
    "            .otherwise(pl.lit('aud'))\n",
    "            .alias('rewarded_modality')\n",
    "        )\n",
    "        .sort('trial_index')\n",
    "    )\n",
    "\n",
    "session_trials = session_trials.to_pandas()\n",
    "\n",
    "session_trials['predict_proba_0']=predict_proba_0\n",
    "session_trials['predict_proba_1']=predict_proba_1\n",
    "\n",
    "if excl_instruction_trials:\n",
    "    # session_trials=session_trials.query('~is_instruction').reset_index(drop=True)\n",
    "    #replace is_instruction trials predict_proba with nan\n",
    "    session_trials['predict_proba_0'] = session_trials['predict_proba_0'].where(~session_trials['is_instruction'], np.nan)\n",
    "    session_trials['predict_proba_1'] = session_trials['predict_proba_1'].where(~session_trials['is_instruction'], np.nan)\n",
    "\n",
    "corrected_predict_proba_0 = []\n",
    "corrected_predict_proba_1 = []\n",
    "for bb in session_trials['block_index'].unique():\n",
    "    block_trials=session_trials.query(f'block_index=={bb}')\n",
    "    if correction=='flip_aud':\n",
    "        if block_trials['rewarded_modality'].values[0]=='vis':\n",
    "            corrected_predict_proba_0.append(block_trials['predict_proba_0'].values)\n",
    "            corrected_predict_proba_1.append(block_trials['predict_proba_1'].values)\n",
    "        elif block_trials['rewarded_modality'].values[0]=='aud':\n",
    "            corrected_predict_proba_0.append(1 - block_trials['predict_proba_0'].values)\n",
    "            corrected_predict_proba_1.append(1 - block_trials['predict_proba_1'].values)\n",
    "    elif correction=='subtract_mean':\n",
    "        corrected_predict_proba_0.append(block_trials['predict_proba_0'].values - np.nanmean(block_trials['predict_proba_0'].values))\n",
    "        corrected_predict_proba_1.append(block_trials['predict_proba_1'].values - np.nanmean(block_trials['predict_proba_1'].values))\n",
    "\n",
    "corrected_predict_proba_0 = np.concatenate(corrected_predict_proba_0)\n",
    "corrected_predict_proba_1 = np.concatenate(corrected_predict_proba_1)\n",
    "\n",
    "r,p=stats.pearsonr(corrected_predict_proba_0[~np.isnan(corrected_predict_proba_0)], corrected_predict_proba_1[~np.isnan(corrected_predict_proba_1)])\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(12,4))\n",
    "for bb in block_switches:\n",
    "    ax.axvline(x=bb, color='black', linestyle='--', linewidth=0.5)\n",
    "if correction=='flip_aud':\n",
    "    ax.axhline(y=0.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "elif correction=='subtract_mean':\n",
    "    ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax.plot(trial_indices_0, corrected_predict_proba_0, label=sel_structure_0, color='tab:blue', alpha=0.5)\n",
    "ax.plot(trial_indices_1, corrected_predict_proba_1, label=sel_structure_1, color='tab:orange', alpha=0.5)\n",
    "ax.set_title(f\"{sel_session} correlation between {sel_structure_0} and {sel_structure_1} at {sel_time_bin}s: r={r:.3f}, p={p:.3e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as editable pdf\n",
    "savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\quick figures\\2025-08-01-predict_proba_corr_updates\\ACAd_SCm_predict_proba_scatter_-0.25.pdf'\n",
    "fig.savefig(savepath, bbox_inches='tight', dpi=300,\n",
    "            transparent=True, format='pdf', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average some areas together per session:\n",
    "\n",
    "simplfied_structure_grouping = {\n",
    "    'VIS': ['VISp', 'VISa', 'VISal', 'VISam', 'VISl', 'VISli', 'VISp', 'VISpl', 'VISpm', 'VISpor'],\n",
    "    'AUD': ['AUDp', 'AUDv', 'AUDd', 'AUDpo'],\n",
    "    'AI': ['AIp', 'AIv', 'AId'],\n",
    "    'HPF': ['CA1', 'CA2', 'CA3', 'DG', 'ENTl', 'ENTm', 'PAR', 'POST', 'PRE', 'SUB', 'ProS'],\n",
    "    'OLF': ['OLF','AON','AOB','MOB','TT','DP','PIR'],\n",
    "    'THALsm': ['VAL','VM','VPL','VPLpc','VPM','MGd','MGv','MGm','LGd'],\n",
    "    'THALpm': ['LP','PO','POL','SGN','Eth', #\n",
    "               'AV','AMd','AMv','AD','IAM','IAD','LD', #\n",
    "               'IMD','MD','SMT','PR', #\n",
    "               'PVT','PT','RE','Xi', #\n",
    "               'RH','PCN','CM','CL','PF','PIL', #\n",
    "               'RT', #\n",
    "               'IGL','IntG','LGv','SubG', #\n",
    "               'MH','LH' #\n",
    "               ],\n",
    "    'AMY': ['BLAp','CEAm'],\n",
    "    'GP': ['GP','GPe','GPi'],\n",
    "    'LS': ['LSc','LSr','LSv'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b28f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba_pd['structure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ac706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba_pd.query('session_id==\"636766_2023-01-24\" and bin_center==-0.25')['predict_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bade757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each session, get the average predict proba for each structure in the simplified_structure_grouping, and delete the original structure-session row\n",
    "\n",
    "predict_proba_pd=predict_proba_pd[~predict_proba_pd['structure'].str.contains('SCzo|SCop|SCsg|SCiw|SCig|SCdw|SCdg|ECT1|ECT2/3|ECT4|ECT5|ECT6a|ECT6b')]\n",
    "\n",
    "# sel_bin_center=-0.25\n",
    "sel_bin_center=0.105\n",
    "new_predict_proba_pd = []\n",
    "\n",
    "#round bin_center to 3 decimal places to avoid floating point issues\n",
    "predict_proba_pd['bin_center']=predict_proba_pd['bin_center'].round(3)\n",
    "\n",
    "#loop through each session\n",
    "for sel_session in dr_session_list:\n",
    "    print(f'Processing session {sel_session}')\n",
    "    \n",
    "    #get the table for the session\n",
    "    predict_proba_pd_session=predict_proba_pd.query(f'session_id==\"{sel_session}\" and bin_center=={sel_bin_center}').reset_index(drop=True)\n",
    "\n",
    "    #loop through each structure in the simplified_structure_grouping\n",
    "    for new_structure, old_structures in simplfied_structure_grouping.items():\n",
    "        if len(old_structures) > 1:\n",
    "            #get the rows for the old structures\n",
    "            old_structure_rows = predict_proba_pd_session.query(f'structure in {old_structures}')\n",
    "\n",
    "            #check if length of predict_proba for each rows match\n",
    "            if old_structure_rows['predict_proba'].apply(len).nunique() > 1:\n",
    "                print(f'Warning: predict_proba lengths do not match for session {sel_session} and structures {old_structures}. Skipping...')\n",
    "                continue\n",
    "\n",
    "            if not old_structure_rows.empty:\n",
    "                new_structure_row = {\n",
    "                    'session_id': sel_session,\n",
    "                    'structure': new_structure,\n",
    "                    'unit_subsample_size': old_structure_rows['unit_subsample_size'].iloc[0],\n",
    "                    'bin_center': old_structure_rows['bin_center'].iloc[0],\n",
    "                    'time_aligned_to': old_structure_rows['time_aligned_to'].iloc[0],\n",
    "                    'balanced_accuracy_test': old_structure_rows['balanced_accuracy_test'].mean(),\n",
    "                    'total_n_units': old_structure_rows['total_n_units'].iloc[0],\n",
    "                    'predict_proba': [old_structure_rows['predict_proba'].mean()],\n",
    "                    'trial_index': [old_structure_rows['trial_index'].iloc[0]],\n",
    "                    'is_vis_rewarded': [old_structure_rows['is_vis_rewarded'].iloc[0]],\n",
    "                    'stim_name': [old_structure_rows['stim_name'].iloc[0]],\n",
    "                    'is_response': [old_structure_rows['is_response'].iloc[0]],\n",
    "                }\n",
    "\n",
    "                predict_proba_pd_session = pd.concat([predict_proba_pd_session, pd.DataFrame(new_structure_row)], axis=0, ignore_index=True)\n",
    "                \n",
    "                #drop the old structure rows from the new_predict_proba_pd\n",
    "                predict_proba_pd_session = predict_proba_pd_session.query(f'structure not in {old_structures}')\n",
    "\n",
    "\n",
    "        else:\n",
    "            #if only one old structure, just rename it to the new structure\n",
    "            predict_proba_pd_session.loc[predict_proba_pd_session['session_id'] == sel_session, 'structure'] = old_structures[0]\n",
    "\n",
    "    #update the new_predict_proba_pd with the session results\n",
    "    # new_predict_proba_pd = pd.concat([new_predict_proba_pd, predict_proba_pd_session], axis=0, ignore_index=True)\n",
    "    new_predict_proba_pd.append(predict_proba_pd_session)\n",
    "    \n",
    "    \n",
    "new_predict_proba_pd = pd.concat(new_predict_proba_pd, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predict_proba_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(predict_proba_pd['structure'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a248690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predict proba from each structure in this session (at selected time bin), correct it, append to the trials table, correlate across structures\n",
    "\n",
    "sel_time_bin=-0.095\n",
    "correction='flip_aud' #'subtract_mean' or 'flip_aud' or 'none'\n",
    "excl_instruction_trials=True\n",
    "sel_unit_subsample_size=\"all\"\n",
    "sel_time_aligned_to='stim_start_time'\n",
    "\n",
    "# data_table=new_predict_proba_pd.copy() #simplified structures\n",
    "data_table=predict_proba_pd.copy() #original with all structures\n",
    "data_table['bin_center']=data_table['bin_center'].round(3)\n",
    "\n",
    "predict_proba_corr_dict={\n",
    "    'session_id':[],\n",
    "    'time_bin':[],\n",
    "    'structure_0':[],\n",
    "    'structure_1':[],\n",
    "    'r':[],\n",
    "    'p':[],\n",
    "}\n",
    "\n",
    "for sel_session in session_table.filter(pl.col('project')==\"DynamicRouting\",pl.col('is_production'),\n",
    "                                        pl.col('issues').eq(\"\"))['session_id'].unique().to_list():\n",
    "# for sel_session in session_table.filter(pl.col('project')==\"Templeton\",pl.col('issues').eq(\"\"))['session_id'].unique().to_list():\n",
    "\n",
    "    session_structures=data_table.query(f'session_id==\"{sel_session}\"')['structure'].unique()\n",
    "    session_trials=all_trials.filter(pl.col('session_id').eq(sel_session)).sort('trial_index')\n",
    "\n",
    "    if (\n",
    "        session_trials['block_index'].n_unique() == 1\n",
    "        and not (\n",
    "            session_table.filter(\n",
    "                pl.col('session_id') == session_trials['session_id'][0], \n",
    "                pl.col('is_templeton'),\n",
    "            )\n",
    "        ).is_empty()\n",
    "    ):\n",
    "        print(f'Adding dummy context labels for Templeton session {sel_session}')\n",
    "        session_trials = (\n",
    "            session_trials\n",
    "            .with_columns(\n",
    "                pl.col('start_time').sub(pl.col('start_time').min().over('session_id')).truediv(10*60).floor().clip(0, 5).alias('block_index')\n",
    "                # short 7th block will sometimes be present: merge into 6th with clip\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('block_index').mod(2).eq(random.choice([0, 1])))\n",
    "                .then(pl.lit('vis'))\n",
    "                .otherwise(pl.lit('aud'))\n",
    "                .alias('rewarded_modality')\n",
    "            )\n",
    "            .sort('trial_index')\n",
    "        )\n",
    "\n",
    "    session_trials = session_trials.to_pandas()\n",
    "\n",
    "    for sel_structure in session_structures:\n",
    "        structure_results=get_session_structure_results(data_table, sel_session, sel_structure, sel_unit_subsample_size, sel_time_aligned_to)\n",
    "        structure_results['bin_center']=structure_results['bin_center'].round(3)\n",
    "        predict_proba=structure_results.query(f'bin_center==({sel_time_bin})')['predict_proba'].values[0]\n",
    "        \n",
    "        #limit trial indices; assumes all results use the same trials\n",
    "        trial_indices=structure_results.query(f'bin_center==({sel_time_bin})')['trial_index'].values[0]\n",
    "        session_structure_trials=session_trials.query('trial_index in @trial_indices').sort_values(by='trial_index')\n",
    "\n",
    "        if len(predict_proba)!=len(session_structure_trials):\n",
    "            print(f\"Skipping {sel_session}, {sel_structure} due to mismatch in number of trials between trials and predict_proba\")\n",
    "            predict_proba=np.array([np.nan]*len(session_structure_trials))\n",
    "\n",
    "        temp_combined_trials=session_structure_trials.copy()\n",
    "        temp_combined_trials['predict_proba']=predict_proba\n",
    "\n",
    "        corrected_predict_proba = []\n",
    "        for bb in temp_combined_trials['block_index'].unique():\n",
    "            block_trials=temp_combined_trials.query(f'block_index=={bb}')\n",
    "            if correction=='flip_aud':\n",
    "                if block_trials['rewarded_modality'].values[0]=='vis':\n",
    "                    corrected_predict_proba.append(block_trials['predict_proba'].values)\n",
    "                elif block_trials['rewarded_modality'].values[0]=='aud':\n",
    "                    corrected_predict_proba.append(1 - block_trials['predict_proba'].values)\n",
    "            elif correction=='subtract_mean':\n",
    "                corrected_predict_proba.append(block_trials['predict_proba'].values - np.nanmean(block_trials['predict_proba'].values))\n",
    "            elif correction=='none':\n",
    "                corrected_predict_proba.append(block_trials['predict_proba'].values)\n",
    "\n",
    "        corrected_predict_proba = np.concatenate(corrected_predict_proba)\n",
    "\n",
    "        session_structure_trials[f'{sel_structure}_predict_proba']=corrected_predict_proba\n",
    "\n",
    "        session_trials=session_trials.merge(\n",
    "            session_structure_trials[['trial_index', f'{sel_structure}_predict_proba']],\n",
    "            on='trial_index',\n",
    "            how='left',\n",
    "        )\n",
    "\n",
    "    # add a \"behavior\" column\n",
    "    # -1 for response to non-rewarded target\n",
    "    # 1 for no response to non-rewarded target\n",
    "    # 0 for other stimuli\n",
    "    session_trials['choice_predict_proba']=np.nan\n",
    "    #false alarms\n",
    "    session_trials.loc[\n",
    "        (session_trials['is_response']==True) & (session_trials['stim_name']=='vis1') & (session_trials['rewarded_modality']=='aud')|\n",
    "        (session_trials['is_response']==True) & (session_trials['stim_name']=='sound1') & (session_trials['rewarded_modality']=='vis')\n",
    "        ,'choice_predict_proba']=-1\n",
    "    #correct rejects\n",
    "    session_trials.loc[\n",
    "        (session_trials['is_response']==False) & (session_trials['stim_name']=='vis1') & (session_trials['rewarded_modality']=='aud')|\n",
    "        (session_trials['is_response']==False) & (session_trials['stim_name']=='sound1') & (session_trials['rewarded_modality']=='vis')\n",
    "        ,'choice_predict_proba']=1\n",
    "    # #hits\n",
    "    # session_trials.loc[\n",
    "    #     (session_trials['is_response']==True) & (session_trials['stim_name']=='vis1') & (session_trials['rewarded_modality']=='vis')|\n",
    "    #     (session_trials['is_response']==True) & (session_trials['stim_name']=='sound1') & (session_trials['rewarded_modality']=='aud')\n",
    "    #     ,'choice_predict_proba']=1\n",
    "    # #misses\n",
    "    # session_trials.loc[\n",
    "    #     (session_trials['is_response']==False) & (session_trials['stim_name']=='vis1') & (session_trials['rewarded_modality']=='vis')|\n",
    "    #     (session_trials['is_response']==False) & (session_trials['stim_name']=='sound1') & (session_trials['rewarded_modality']=='aud')\n",
    "    #     ,'choice_predict_proba']=1\n",
    "\n",
    "    if excl_instruction_trials:\n",
    "        session_trials=session_trials.query('~is_instruction').reset_index(drop=True)\n",
    "\n",
    "    for col0 in session_trials.filter(like='predict_proba').columns:\n",
    "        for col1 in session_trials.filter(like='predict_proba').columns:\n",
    "            if col0!=col1:\n",
    "                if (np.sum(np.isnan(session_trials[col0]))>0)|(np.sum(np.isnan(session_trials[col1]))>0):\n",
    "                    notnanidx=~np.isnan(session_trials[col0])&~np.isnan(session_trials[col1])\n",
    "                    if sum(notnanidx)==0:\n",
    "                        r=np.nan\n",
    "                        p=np.nan\n",
    "                    else:\n",
    "                        r,p=stats.pearsonr(session_trials[col0][notnanidx], session_trials[col1][notnanidx])\n",
    "                else:\n",
    "                    r,p=stats.pearsonr(session_trials[col0], session_trials[col1])\n",
    "                # print(f\"{col0} vs {col1}: r={r:.3f}, p={p:.3e}\")\n",
    "                predict_proba_corr_dict['session_id'].append(sel_session)\n",
    "                predict_proba_corr_dict['time_bin'].append(sel_time_bin)\n",
    "                predict_proba_corr_dict['structure_0'].append(col0.replace('_predict_proba',''))\n",
    "                predict_proba_corr_dict['structure_1'].append(col1.replace('_predict_proba',''))\n",
    "                predict_proba_corr_dict['r'].append(r)\n",
    "                predict_proba_corr_dict['p'].append(p)\n",
    "\n",
    "predict_proba_corr_df=pd.DataFrame(predict_proba_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585eea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba.shape\n",
    "# session_trials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_table.query(f'bin_center==({sel_time_bin})')['trial_index'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure_results=get_session_structure_results(data_table, sel_session, sel_structure, sel_unit_subsample_size, sel_time_aligned_to)\n",
    "# structure_results['bin_center'].unique()\n",
    "\n",
    "\n",
    "# choice_values=session_trials['choice_predict_proba'].values\n",
    "# not_nan_index=~np.isnan(choice_values)\n",
    "\n",
    "# fig,ax=plt.subplots(1,1,figsize=(8,4))\n",
    "# ax.plot(session_trials['MOs_predict_proba'])\n",
    "# ax.plot(session_trials['trial_index'].values[not_nan_index],(choice_values[not_nan_index]+1)/2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dea5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot example of predict proba and choice on same plot\n",
    "\n",
    "sel_session=\"664851_2023-11-13\"\n",
    "sel_structure=\"ACAd\"\n",
    "\n",
    "correction='flip_aud' #'subtract_mean' or 'flip_aud' or 'none'\n",
    "excl_instruction_trials=True\n",
    "sel_time_bin=0.105#-0.25\n",
    "sel_unit_subsample_size='all'\n",
    "sel_time_aligned_to='stim_start_time'\n",
    "\n",
    "structure_results=get_session_structure_results(predict_proba_pd, sel_session, sel_structure, sel_unit_subsample_size, sel_time_aligned_to)\n",
    "structure_results['bin_center']=structure_results['bin_center'].round(3)\n",
    "predict_proba=structure_results.query(f'bin_center==({sel_time_bin})')['predict_proba'].values[0]\n",
    "session_trials=all_trials.filter(pl.col('session_id').eq(sel_session)).sort('trial_index').to_pandas()\n",
    "\n",
    "temp_combined_trials=session_trials.copy()\n",
    "temp_combined_trials['predict_proba']=predict_proba\n",
    "\n",
    "corrected_predict_proba = []\n",
    "for bb in temp_combined_trials['block_index'].unique():\n",
    "    block_trials=temp_combined_trials.query(f'block_index=={bb}')\n",
    "    if correction=='flip_aud':\n",
    "        if block_trials['rewarded_modality'].values[0]=='vis':\n",
    "            corrected_predict_proba.append(block_trials['predict_proba'].values)\n",
    "        elif block_trials['rewarded_modality'].values[0]=='aud':\n",
    "            corrected_predict_proba.append(1 - block_trials['predict_proba'].values)\n",
    "    elif correction=='subtract_mean':\n",
    "        corrected_predict_proba.append(block_trials['predict_proba'].values - np.nanmean(block_trials['predict_proba'].values))\n",
    "    elif correction=='none':\n",
    "        corrected_predict_proba.append(block_trials['predict_proba'].values)\n",
    "\n",
    "corrected_predict_proba = np.concatenate(corrected_predict_proba)\n",
    "\n",
    "session_trials[f'{sel_structure}_predict_proba']=corrected_predict_proba\n",
    "\n",
    "# add a \"behavior\" column\n",
    "# -1 for response to non-rewarded target\n",
    "# 1 for no response to non-rewarded target\n",
    "session_trials['choice_predict_proba']=np.nan\n",
    "#false alarms\n",
    "session_trials.loc[\n",
    "    (session_trials['is_response']==True) & (session_trials['stim_name']=='vis1') & (session_trials['rewarded_modality']=='aud')|\n",
    "    (session_trials['is_response']==True) & (session_trials['stim_name']=='sound1') & (session_trials['rewarded_modality']=='vis')\n",
    "    ,'choice_predict_proba']=-1\n",
    "#correct rejects\n",
    "session_trials.loc[\n",
    "    (session_trials['is_response']==False) & (session_trials['stim_name']=='vis1') & (session_trials['rewarded_modality']=='aud')|\n",
    "    (session_trials['is_response']==False) & (session_trials['stim_name']=='sound1') & (session_trials['rewarded_modality']=='vis')\n",
    "    ,'choice_predict_proba']=1\n",
    "\n",
    "if excl_instruction_trials:\n",
    "    instruction_trials=session_trials.query('is_instruction').index.values\n",
    "    session_trials.loc[instruction_trials,'choice_predict_proba']=np.nan\n",
    "    session_trials.loc[instruction_trials,f'{sel_structure}_predict_proba']=np.nan\n",
    "\n",
    "\n",
    "nanind=~np.isnan(session_trials['choice_predict_proba'])&~np.isnan(session_trials[f'{sel_structure}_predict_proba'])\n",
    "r,p=stats.pearsonr(session_trials['choice_predict_proba'][nanind], session_trials[f'{sel_structure}_predict_proba'][nanind])\n",
    "\n",
    "#plot predict_proba and choice on same plot\n",
    "fig,ax=plt.subplots(1,1,figsize=(8,4))\n",
    "for bb in session_trials.query('is_block_switch')['trial_index'].values:\n",
    "    ax.axvline(x=bb, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.plot(session_trials['trial_index'], (session_trials['choice_predict_proba']+1)/2, 'r.', label='Choice Vector')\n",
    "ax.plot(session_trials['trial_index'], session_trials[f'{sel_structure}_predict_proba'], color='k', linewidth=1, label='Structure Predict Proba')\n",
    "ax.set_xlabel('Trial Index')\n",
    "ax.set_ylabel('Predict Proba')\n",
    "ax.legend()\n",
    "ax.set_title(f\"{sel_session} {sel_structure} predict_proba at {sel_time_bin}s\\nr = {r:.3f}, p = {p:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute mean correlation across sessions for each structure pair\n",
    "\n",
    "unique_combos=predict_proba_corr_df[['structure_0','structure_1']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "mean_corr=unique_combos.copy()\n",
    "mean_corr['mean_r']=np.nan\n",
    "mean_corr['n_sessions']=0\n",
    "for rr in range(len(unique_combos)):\n",
    "    sel_structure_0=unique_combos.loc[rr,'structure_0']\n",
    "    sel_structure_1=unique_combos.loc[rr,'structure_1']\n",
    "    temp_df=predict_proba_corr_df.query(f'structure_0==@sel_structure_0 and structure_1==@sel_structure_1')\n",
    "    mean_corr.loc[rr,'mean_r']=temp_df['r'].mean()\n",
    "    mean_corr.loc[rr,'n_sessions']=len(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_incl_structures=False\n",
    "# custom_incl_structures_list=[\n",
    "#     'ACAd', 'ACAv', 'CA1', 'CA3', 'CP', 'DG', 'FRP',\n",
    "#     'ILA', 'LP', 'MD', 'MOp', 'MOs', 'MRN', 'ORBl',\n",
    "#     'ORBm', 'ORBvl', 'PL', 'RSPd', 'RSPv',\n",
    "#     'SCm', 'SCs', 'SSp', 'SUB', 'VISp',\n",
    "#     ]\n",
    "custom_incl_structures_list=[\n",
    "    'ACAd', 'ACAv', 'AI', 'FRP', 'ILA', 'MOs', 'MOp', 'ORBl', 'ORBm', 'ORBvl', 'PL',\n",
    "    'RSPagl', 'RSPd', 'RSPv', 'SSp', 'SSs', 'VIS',\n",
    "    'APN', 'MRN', 'SCm', 'SCs',\n",
    "    'CP', 'LS',\n",
    "    'HPF', \n",
    "    'THALpm', 'THALsm',\n",
    "]\n",
    "\n",
    "unique_structures=predict_proba_corr_df['structure_0'].sort_values().unique()\n",
    "\n",
    "# unique_structures=unique_structures[~np.isin(unique_structures, ['SCop', 'SCsg', 'SCzo', 'SCig', 'SCiw', 'SCdg', 'SCdw', 'ECT5', 'ECT6a',\n",
    "#                                                                  'OLF', 'HPF', 'CTXsp', 'STR', 'PAL', 'TH', 'HY', 'MB', 'P', 'MY', 'CB', \n",
    "#                                                                  'fiber tracts', 'scwm', 'VL', 'V3', 'V4','choice'])]\n",
    "unique_structures=unique_structures[~np.isin(unique_structures, ['SCop', 'SCsg', 'SCzo', 'SCig', 'SCiw', 'SCdg', 'SCdw', 'ECT5', 'ECT6a',\n",
    "                                                                 'CTXsp', 'STR', 'PAL', 'TH', 'HY', 'MB', 'P', 'MY', 'CB', \n",
    "                                                                 'fiber tracts', 'scwm', 'VL', 'V3', 'V4'])]\n",
    "\n",
    "combo_value_counts=predict_proba_corr_df[['structure_0','structure_1']].value_counts()\n",
    "\n",
    "if custom_incl_structures:\n",
    "    incl_structures=custom_incl_structures_list\n",
    "else:\n",
    "    incl_structures=[]\n",
    "    for st in unique_structures:\n",
    "        if (predict_proba_corr_df[['structure_0','structure_1']].value_counts()[st]>=3).sum()>=25:\n",
    "            incl_structures.append(st)\n",
    "\n",
    "    incl_structures=np.sort(incl_structures)\n",
    "\n",
    "\n",
    "\n",
    "#build correlation matrix from this dataframe\n",
    "corr_matrix=np.full((len(incl_structures), len(incl_structures)), np.nan)\n",
    "for rr, sel_structure_0 in enumerate(incl_structures):\n",
    "    for cc, sel_structure_1 in enumerate(incl_structures):\n",
    "        if sel_structure_0==sel_structure_1:\n",
    "            corr_matrix[rr,cc]=np.nan\n",
    "        else:\n",
    "            temp_df=predict_proba_corr_df.query(f'structure_0==\"{sel_structure_0}\" and structure_1==\"{sel_structure_1}\"')\n",
    "            #only save if at least 3 sessions\n",
    "            if len(temp_df)>=3:\n",
    "                corr_matrix[rr,cc]=temp_df['r'].mean()\n",
    "\n",
    "# corr_matrix[np.isnan(corr_matrix)]=np.nanmean(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "incl_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_order=[\n",
    "    'ACAd', 'ACAv', 'AI', 'FRP', 'ILA', 'MOp', 'MOs', 'ORBl', 'ORBm', 'ORBvl', 'PL',\n",
    "    'RSPagl', 'RSPd', 'RSPv', 'SSp', 'SSs', 'VIS',\n",
    "    'APN', 'MRN', 'SCm', 'SCs',\n",
    "    'CP', 'LS',\n",
    "    'HPF', \n",
    "    'THALpm', 'THALsm',\n",
    "]\n",
    "\n",
    "custom_order_index=np.arange(len(custom_order),dtype=int)\n",
    "\n",
    "custom_order_pd = pd.DataFrame({\n",
    "    'structure': custom_order,\n",
    "    'index': custom_order_index\n",
    "})\n",
    "\n",
    "custom_order_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2279ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(7,6))\n",
    "\n",
    "masked_array = np.ma.array(corr_matrix, mask=np.isnan(corr_matrix))\n",
    "cmap = matplotlib.cm.viridis\n",
    "cmap.set_bad('grey',0.5)\n",
    "\n",
    "im=ax.imshow(np.abs(masked_array), aspect='auto', cmap=cmap, vmin=0.0, vmax=0.5, extent=[-0.5,len(incl_structures)-0.5,len(incl_structures)-0.5,-0.5])\n",
    "ax.set_xticks(np.arange(len(incl_structures)), incl_structures, rotation=90)\n",
    "ax.set_yticks(np.arange(len(incl_structures)), incl_structures)\n",
    "\n",
    "#colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('mean Pearson r between structure predict probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as editable pdf\n",
    "savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\quick figures\\2025-08-01-predict_proba_corr_updates\\predict_proba_corr_matrix_uncorrected_custom_order_0.3-0.7.pdf'\n",
    "fig.savefig(savepath, bbox_inches='tight', dpi=300,\n",
    "            transparent=True, format='pdf', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c98f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot just choice row\n",
    "\n",
    "choices_df=pd.DataFrame({\n",
    "    'structure': incl_structures,\n",
    "    'r_with_choice': np.abs(corr_matrix[np.where(incl_structures=='choice')[0][0],:]),\n",
    "    'bin_center': sel_time_bin,\n",
    "})\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(7,3))\n",
    "# choice_row=corr_matrix[np.where(incl_structures=='choice')[0][0],:]\n",
    "# ax.bar(x=np.arange(len(incl_structures)), height=choice_row)\n",
    "# ax.set_xticks(np.arange(len(incl_structures)), incl_structures, rotation=90)\n",
    "# ax.set_ylabel('mean Pearson r with choice')\n",
    "\n",
    "choices_df.sort_values('r_with_choice', ascending=False).plot.bar(x='structure', y='r_with_choice', ax=ax, legend=False)\n",
    "ax.set_ylabel('mean Pearson r with choice')\n",
    "# ax.set_ylim(-0.01, 0.45)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choices_df_aud=choices_df.copy()\n",
    "\n",
    "choice_merged_df=pd.merge(choices_df, choices_df_aud, on='structure', suffixes=('_vis', '_aud'))\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(7,3))\n",
    "choice_merged_df.sort_values('r_with_choice_vis', ascending=False).plot.bar(x='structure', y=['r_with_choice_vis', 'r_with_choice_aud'], ax=ax, legend=True)\n",
    "ax.set_ylabel('mean Pearson r with choice')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralCoclustering\n",
    "from sklearn.cluster import SpectralBiclustering\n",
    "from sklearn.metrics import consensus_score\n",
    "\n",
    "cluster_corr_matrix=np.abs(corr_matrix.copy())\n",
    "\n",
    "# for rowind in range(cluster_corr_matrix.shape[0]):\n",
    "#     for colind in range(cluster_corr_matrix.shape[1]):\n",
    "#         if rowind==colind:\n",
    "#             cluster_corr_matrix[rowind, colind] = np.nanmean(cluster_corr_matrix)\n",
    "#         else:\n",
    "#             cluster_corr_matrix[rowind, colind] = np.nanmean([cluster_corr_matrix[rowind, :],cluster_corr_matrix[:, colind]])\n",
    "cluster_corr_matrix[np.isnan(cluster_corr_matrix)]=np.nanmean(cluster_corr_matrix)\n",
    "\n",
    "data=cluster_corr_matrix.copy()\n",
    "\n",
    "model = SpectralBiclustering(n_clusters=2, method=\"log\", random_state=0)\n",
    "# model = SpectralCoclustering(n_clusters=2, random_state=0)\n",
    "model.fit(data)\n",
    "\n",
    "# score = consensus_score(model.biclusters_, (rows[:, row_idx], columns[:, col_idx]))\n",
    "\n",
    "# print(\"consensus score: {:.3f}\".format(score))\n",
    "\n",
    "if custom_incl_structures:\n",
    "    custom_order_pd['cluster'] = model.row_labels_\n",
    "    custom_order_pd.sort_values(by=['cluster', 'index'], inplace=True)\n",
    "    sort_idx=custom_order_pd.index.values\n",
    "    fit_data = corr_matrix[sort_idx]\n",
    "    fit_data = fit_data[:, sort_idx]\n",
    "    \n",
    "else:\n",
    "    sort_idx = np.argsort(model.row_labels_)\n",
    "    fit_data = corr_matrix[sort_idx]\n",
    "    fit_data = fit_data[:, sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_order_pd['cluster'] = model.row_labels_\n",
    "# custom_order_pd.sort_values(by=['cluster', 'index'], inplace=True)\n",
    "# custom_order_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c52969",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordered_indices\n",
    "# np.argsort(model.row_labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Figure out a clustering score\n",
    "## try other clustering methods?\n",
    "### PROPERLY deal with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902cd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_idx\n",
    "np.array(incl_structures)[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef6f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.row_labels_[sort_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1161039",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_array = np.ma.array(fit_data, mask=np.isnan(fit_data))\n",
    "cmap = matplotlib.cm.viridis\n",
    "cmap.set_bad('grey',0.5)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(9,8))\n",
    "im=ax.imshow(masked_array, aspect='auto', cmap=cmap, vmin=0.0, vmax=0.4, extent=[-0.5,len(incl_structures)-0.5,len(incl_structures)-0.5,-0.5])\n",
    "ax.set_xticks(np.arange(len(incl_structures)), np.array(incl_structures)[sort_idx], rotation=90)\n",
    "ax.set_yticks(np.arange(len(incl_structures)), np.array(incl_structures)[sort_idx])\n",
    "\n",
    "row_labels = model.row_labels_\n",
    "sorted_row_labels = row_labels[sort_idx]\n",
    "cluster_borders = np.where(np.diff(sorted_row_labels) != 0)[0] + 0.5\n",
    "\n",
    "for xx in cluster_borders:\n",
    "    ax.axvline(x=xx, color='black', linestyle='-', linewidth=2)\n",
    "    ax.axhline(y=xx, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "#colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('mean Pearson r between structure predict probabilities')\n",
    "\n",
    "ax.set_title(f'Spectral biclustering of structure predict probability correlations\\nbin_center={sel_time_bin}s, correction={correction}, excl_instruction_trials={excl_instruction_trials}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as editable pdf\n",
    "savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\quick figures\\2025-08-01-predict_proba_corr_updates\\predict_proba_corr_matrix_uncorrected_clustered_custom_order_0.3-0.7.pdf'\n",
    "fig.savefig(savepath, bbox_inches='tight', dpi=300,\n",
    "            transparent=True, format='pdf', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.cluster.HDBSCAN as hdbscan\n",
    "import hdbscan\n",
    "\n",
    "cluster_corr_matrix=corr_matrix.copy()\n",
    "data=cluster_corr_matrix.copy()\n",
    "\n",
    "model = hdbscan.HDBSCAN(min_cluster_size=2)\n",
    "\n",
    "# model.fit_predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aecade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stackexchange\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_missing(X, n_clusters, max_iter=10):\n",
    "    \"\"\"Perform K-Means clustering on data with missing values.\n",
    "\n",
    "    Args:\n",
    "      X: An [n_samples, n_features] array of data to cluster.\n",
    "      n_clusters: Number of clusters to form.\n",
    "      max_iter: Maximum number of EM iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "      labels: An [n_samples] vector of integer labels.\n",
    "      centroids: An [n_clusters, n_features] array of cluster centroids.\n",
    "      X_hat: Copy of X with the missing values filled in.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize missing values to their column means\n",
    "    missing = ~np.isfinite(X)\n",
    "    mu = np.nanmean(X, 0, keepdims=1)\n",
    "    X_hat = np.where(missing, mu, X)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        if i > 0:\n",
    "            # initialize KMeans with the previous set of centroids. this is much\n",
    "            # faster and makes it easier to check convergence (since labels\n",
    "            # won't be permuted on every iteration), but might be more prone to\n",
    "            # getting stuck in local minima.\n",
    "            cls = KMeans(n_clusters, init=prev_centroids)\n",
    "        else:\n",
    "            # do multiple random initializations in parallel\n",
    "            cls = KMeans(n_clusters)\n",
    "\n",
    "        # perform clustering on the filled-in data\n",
    "        labels = cls.fit_predict(X_hat)\n",
    "        centroids = cls.cluster_centers_\n",
    "\n",
    "        # fill in the missing values based on their cluster centroids\n",
    "        X_hat[missing] = centroids[labels][missing]\n",
    "\n",
    "        # when the labels have stopped changing then we have converged\n",
    "        if i > 0 and np.all(labels == prev_labels):\n",
    "            print(\"Converged after {} iterations\".format(i))\n",
    "            break\n",
    "\n",
    "        prev_labels = labels\n",
    "        prev_centroids = cls.cluster_centers_\n",
    "\n",
    "    return labels, centroids, X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38319b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=corr_matrix.copy()\n",
    "labels, centroids, X_hat = kmeans_missing(data, n_clusters=2)\n",
    "\n",
    "fit_data=X_hat[np.argsort(labels)]\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(9,8))\n",
    "im=ax.imshow(fit_data, aspect='auto', cmap='viridis', vmin=0, vmax=0.6, extent=[-0.5,len(incl_structures)-0.5,len(incl_structures)-0.5,-0.5])\n",
    "# ax.set_xticks(np.arange(len(labels)), incl_structures[np.argsort(labels)], rotation=90)\n",
    "ax.set_xticks(np.arange(len(labels)), incl_structures, rotation=90)\n",
    "ax.set_yticks(np.arange(len(labels)), incl_structures[np.argsort(labels)])\n",
    "\n",
    "sorted_row_labels = labels[np.argsort(labels)]\n",
    "cluster_borders = np.where(np.diff(sorted_row_labels) != 0)[0] + 0.5\n",
    "\n",
    "for xx in cluster_borders:\n",
    "    # ax.axvline(x=xx, color='black', linestyle='-', linewidth=2)\n",
    "    ax.axhline(y=xx, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "#colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('mean Pearson r between structure predict probabilities')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr_ibl_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
