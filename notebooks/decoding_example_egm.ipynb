{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode context from spikes or facemap\n",
    "\n",
    "1 - either use all annotated & uploaded ephys sessions as input or provide a list of session_ids\n",
    "\n",
    "2 - set a savepath and filename for the output - one .pkl file per session\n",
    "\n",
    "3 - set parameters - descriptions below\n",
    "\n",
    "4 - run decoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(r\"C:\\Users\\shailaja.akella\\Dropbox (Personal)\\DR\\dynamic_routing_analysis_ethan\\src\")\n",
    "\n",
    "import npc_lims\n",
    "from dynamic_routing_analysis import decoding_utils, path_utils\n",
    "from npc_sessions import DynamicRoutingSession\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import pandas as pd\n",
    "import upath\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1A get all uploaded & annotated ephys sessions\n",
    "\n",
    "ephys_sessions = tuple(s for s in npc_lims.get_session_info(is_ephys=True, is_uploaded=True, \n",
    "                                                            is_annotated=True, project='DynamicRouting', issues = []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1B alternatively, provide a list of session ids:\n",
    "# session_id_list=['733891_2024-09-19','712815_2024-05-22','708016_2024-05-01','664851_2023-11-14','702136_2024-03-05','686176_2023-12-05']\n",
    "# session_id_list=['703333_2024-04-08']\n",
    "session_id_list=['667252_2023-09-25'] #only 4 blocks - test error handling\n",
    "session_list=[]\n",
    "for ss in session_id_list:\n",
    "    session_list.append(npc_lims.get_session_info(ss))\n",
    "ephys_sessions=tuple(session_list)\n",
    "ephys_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 set savepath and filename\n",
    "savepath=upath.UPath(r\"\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\decoding results\\test_logger\")\n",
    "filename='test_logger.pkl'\n",
    "\n",
    "# filename='2024_10_28'\n",
    "# savepath = path_utils.DECODING_ROOT_PATH / 'decoding_test_2024_10_28'\n",
    "\n",
    "except_list={}\n",
    "\n",
    "#3 set parameters\n",
    "#linear shift decoding currently just takes the average firing rate over all bins defined here\n",
    "spikes_binsize=0.2 #bin size in seconds\n",
    "spikes_time_before=0.2 #time before the stimulus per trial\n",
    "spikes_time_after=0.01 #time after the stimulus per trial\n",
    "\n",
    "# #not used for linear shift decoding, were used in a previous iteration of decoding analysis\n",
    "# decoder_binsize=0.2\n",
    "# decoder_time_before=0.2\n",
    "# decoder_time_after=0.1\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_units': ['all'], #number of units to sample for each area (list)\n",
    "    'n_repeats': 25,  # number of times to repeat decoding with different randomly sampled units\n",
    "    'input_data_type': 'spikes',  # spikes or facemap or LP\n",
    "    'vid_angle_facemotion': 'face', # behavior, face, eye\n",
    "    'vid_angle_LP': 'behavior',\n",
    "    'central_section': '4_blocks_plus',\n",
    "    'predict': 'context', # 'context' or 'vis_appropriate_response'\n",
    "    # for linear shift decoding, how many trials to use for the shift. '4_blocks_plus' is best\n",
    "    'exclude_cue_trials': False,  # option to totally exclude autorewarded trials\n",
    "    'n_unit_threshold': 20,  # minimum number of units to include an area in the analysis\n",
    "    'keep_n_SVDs': 500,  # number of SVD components to keep for facemap data\n",
    "    'LP_parts_to_keep': ['ear_base_l', 'eye_bottom_l', 'jaw', 'nose_tip', 'whisker_pad_l_side'],\n",
    "    'spikes_binsize': spikes_binsize,\n",
    "    'spikes_time_before': spikes_time_before,\n",
    "    'spikes_time_after': spikes_time_after,\n",
    "    # 'decoder_binsize':decoder_binsize,\n",
    "    # 'decoder_time_before':decoder_time_before,\n",
    "    # 'decoder_time_after':decoder_time_after,\n",
    "    'savepath': savepath,\n",
    "    'filename': filename,\n",
    "    'use_structure_probe': True,  # if True, append probe name to area name when multiple probes in the same area\n",
    "    'crossval': '5_fold_constant',  # '5_fold', '5_fold_constant', or 'blockwise' - blockwise untested with linear shift\n",
    "    'labels_as_index': True,  # convert labels (context names) to index [0,1]\n",
    "    'decoder_type': 'LogisticRegression',  # 'linearSVC' or 'LDA' or 'RandomForest' or 'LogisticRegression'\n",
    "    'only_use_all_units': True, #if True, do not run decoding with different areas, only with all areas -- for debugging\n",
    "}\n",
    "\n",
    "\n",
    "for ephys_session in ephys_sessions[:1]:\n",
    "    # if os.path.exists(savepath + '/' + ephys_session.id[:17] + '_' + filename + '.pkl'): \n",
    "    #     print(ephys_session.id[:17] + ' completed, skipping...')    \n",
    "    #     continue\n",
    "    # try:\n",
    "        session = DynamicRoutingSession(ephys_session.id)\n",
    "        print(session.id+' loaded')\n",
    "        if 'structure' in session.electrodes[:].columns:\n",
    "            session_info=ephys_session\n",
    "            session_id=str(session_info.id)\n",
    "            trials=pd.read_parquet(\n",
    "                npc_lims.get_cache_path('trials',session_id,'any')\n",
    "            )\n",
    "            units=pd.read_parquet(\n",
    "                npc_lims.get_cache_path('units',session_id,'any')\n",
    "            )\n",
    "            decoding_utils.decode_context_with_linear_shift(session=None,params=params,trials=trials,units=units,session_info=session_info)\n",
    "\n",
    "            #find path of decoder result\n",
    "            file_path= savepath / (ephys_session.id[:17] + '_' + filename)\n",
    "\n",
    "            decoding_results=decoding_utils.concat_decoder_results(file_path,savepath=savepath,return_table=True,single_session=True)\n",
    "\n",
    "            #find n_units to loop through for next step\n",
    "            if decoding_results is not None:\n",
    "                n_units=[]\n",
    "                for col in decoding_results.filter(like='true_accuracy_').columns.values:\n",
    "                    if len(col.split('_'))==3:\n",
    "                        temp_n_units=col.split('_')[2]\n",
    "                        try:\n",
    "                            n_units.append(int(temp_n_units))\n",
    "                        except:\n",
    "                            n_units.append(temp_n_units)\n",
    "                    else:\n",
    "                        n_units.append(None)\n",
    "\n",
    "                for nu in n_units:\n",
    "                    decoding_utils.concat_trialwise_decoder_results(file_path,savepath=savepath,return_table=False,n_units=nu,single_session=True)\n",
    "\n",
    "        else:\n",
    "            print('no structure column found in electrodes table, moving to next recording')\n",
    "        session=[]\n",
    "    # except Exception as e:\n",
    "        # except_list[session.id]=repr(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath=upath.UPath(r\"\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\decoding results\\predict_appropriate_response\")\n",
    "# decoding_utils.concat_decoder_results(file_path,savepath=savepath,return_table=True,single_session=True)\n",
    "# decoding_utils.concat_trialwise_decoder_results(file_path,savepath=savepath,return_table=False,n_units=nu,single_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath=r\"\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\decoding results\\test\"\n",
    "# filename='decoding_results_test'\n",
    "\n",
    "# decoding_utils.concat_decoder_summary_tables(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://aind-scratch-data/dynamic-routing/ethan/decoding-results/logreg_many_nunits_0_2024-12-10-0/667252_2023-09-25_2024-12-10-0.json\n"
     ]
    }
   ],
   "source": [
    "import upath\n",
    "\n",
    "path=[]\n",
    "del path\n",
    "# path=path_utils.DECODING_ROOT_PATH\n",
    "\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'n_units_test_2024-11-06T00:18:30.855494'\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'n_units_test_medium_unit_criteria_2024-11-07T00:47:13.551561'\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'full_test_LDA_medcrit_2024-11-09T00:33:11.111162'\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'full_test_logreg_medcrit_2024-11-11T18:39:59.601162' / 're_run'\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'full_logreg_medcrit_2024-11-26T16:45:38.919765'###old###\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'full_logreg_medcrit_2024-11-26T23:54:35.702811'\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'full_logreg_medcrit_2024-11-26T23:54:35.702811' / 'summary_re_run_0'\n",
    "# path=path_utils.DECODING_ROOT_PATH / 'full_logreg_medcrit_2024-11-26T23:54:35.702811' / 'summary_re_run_1'\n",
    "path=path_utils.DECODING_ROOT_PATH / 'logreg_many_nunits_0_2024-12-10-0'\n",
    "\n",
    "# filename='decoding_results_test_2024_10_28.pkl'\n",
    "all_paths = []\n",
    "all_filenames = []\n",
    "csvs = []\n",
    "# all_paths_0 = []\n",
    "# all_filenames_0 = []\n",
    "# csvs_0 = []\n",
    "for file in path.iterdir():\n",
    "    # if file.is_file():\n",
    "    all_paths.append(file)\n",
    "    print(file)\n",
    "    all_filenames.append(file.name)\n",
    "    if 'results.csv' in str(file):\n",
    "        csvs.append(file)\n",
    "\n",
    "# for file in path_0.iterdir():\n",
    "#     # if file.is_file():\n",
    "#     all_paths_0.append(file)\n",
    "#     print(file)\n",
    "#     all_filenames_0.append(file.name)\n",
    "#     if 'results.csv' in str(file):\n",
    "#         csvs_0.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_paths)/21\n",
    "len(csvs)\n",
    "\n",
    "# path.name.split('T17')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouseid='686176'\n",
    "date='2023-12-07'\n",
    "session_paths=[]\n",
    "for file in path.iterdir():\n",
    "    if mouseid in str(file) and date in str(file):\n",
    "        session_paths.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load decoding results from pickle\n",
    "import pickle\n",
    "results=pickle.loads(upath.UPath(session_paths[0]).read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_area='SNr'\n",
    "test_array=results['686176_2023-12-07']['results'][sel_area]['no_shift']['all'][0]['predict_proba'][:,1]\n",
    "fig,ax=plt.subplots(1,1)\n",
    "ax.plot(test_array)\n",
    "ax.set_xlabel('trial')\n",
    "ax.set_ylabel('predict_proba')\n",
    "ax.set_title(sel_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confidence=pd.read_pickle(r\"D:\\decoding_results_from_CO\\logreg_2024-11-27_re_concat_1\\decoder_confidence_all_trials_all_units.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.hstack(all_confidence['predict_proba'].values)<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath = path\n",
    "# file_path = savepath / f\"703333_2024-04-08_.pkl\"\n",
    "\n",
    "# decoding_results=decoding_utils.concat_decoder_results(file_path,savepath=savepath,return_table=True,single_session=True)\n",
    "\n",
    "# #find n_units to loop through for next step\n",
    "# n_units=[]\n",
    "# for col in decoding_results.filter(like='true_accuracy_').columns.values:\n",
    "#     if len(col.split('_'))==3:\n",
    "#         temp_n_units=col.split('_')[2]\n",
    "#         try:\n",
    "#             n_units.append(int(temp_n_units))\n",
    "#         except:\n",
    "#             n_units.append(temp_n_units)\n",
    "#     else:\n",
    "#         n_units.append(None)\n",
    "\n",
    "# decoding_results=[]\n",
    "\n",
    "# for nu in n_units:\n",
    "#     decoding_utils.concat_trialwise_decoder_results(file_path,savepath=savepath,return_table=False,n_units=nu,single_session=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=path / '703333_2024-04-08_linear_shift_decoding_results.csv'\n",
    "\n",
    "decoding_results=pd.read_csv(filepath)\n",
    "\n",
    "decoding_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare different n units\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# #copy files if do not exist\n",
    "# for temp_path in all_paths_0:\n",
    "#     if 'T17' in temp_path.name:\n",
    "#         temp_name = temp_path.name.split('T17')[0] + '2024-10-29T17' + path.name.split('T17')[1]\n",
    "#     else:\n",
    "#         temp_name = temp_path.name\n",
    "#     if temp_name not in all_filenames:\n",
    "#         # print(path.name)\n",
    "#         print(temp_name)\n",
    "#         if '.csv' in temp_name:\n",
    "#             result=pd.read_csv(temp_path)\n",
    "#             result.to_csv(path / temp_name, index=False)\n",
    "#         elif '.pkl' in temp_name:\n",
    "#             result=pickle.loads(upath.UPath(temp_path).read_bytes())\n",
    "#             (path / temp_name).write_bytes(pickle.dumps(result, protocol=pickle.HIGHEST_PROTOCOL))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upath.UPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= upath.UPath('s3://aind-scratch-data/dynamic-routing/ethan/decoding-results/full_test_1_2024-10-29T17:46:03.914748/626791_2022-08-16_2024-10-29T17:46:03.914748.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath=r'D:\\decoding_results_from_CO\\n_units_test_2024-11-06'\n",
    "# savepath=r'D:\\decoding_results_from_CO\\n_units_test_medium_unit_criteria_2024-11-07'\n",
    "# savepath=r'D:\\decoding_results_from_CO\\lda_test_2024-11-11'\n",
    "# savepath=r'D:\\decoding_results_from_CO\\logreg_test_2024-11-13'\n",
    "savepath=r'D:\\decoding_results_from_CO\\logreg_2024-11-27_re_concat_1'\n",
    "decoding_utils.concat_decoder_summary_tables(path,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_pickle(r\"D:\\decoding_results_from_CO\\logreg_2024-11-27_re_concat_1\\decoder_confidence_all_trials_all_units.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['probe'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['trial_index']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
