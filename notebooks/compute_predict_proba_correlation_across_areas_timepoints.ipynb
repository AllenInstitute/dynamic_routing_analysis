{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bf9504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 8\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "fm.FontProperties().set_family('arial')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# %matplotlib widget\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3ec9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_table_path=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\CO decoding results\\session_table_v0.268.csv\"\n",
    "# session_table_path=\"/Users/ethan.mcbride/Data/DR/session_table_v0.265.csv\"\n",
    "session_table=pl.read_csv(session_table_path)\n",
    "\n",
    "dr_session_list=(\n",
    "    session_table.filter(\n",
    "    pl.col('project')==\"DynamicRouting\",\n",
    "    pl.col('is_production'),\n",
    "    pl.col('is_annotated'),\n",
    "    pl.col('issues')==\"\",\n",
    "    pl.col('is_engaged'),\n",
    "    pl.col('is_good_behavior').eq(True),\n",
    "    )['session_id'].to_list()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load results from parquet files\n",
    "savepath = r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\CO decoding results\\compare-context-lick-stimulus-predict-proba-2025-09-22\\separate_aud_vis_stim_trials\"\n",
    "results_dfs={}\n",
    "for filename in os.listdir(savepath):\n",
    "    if filename.endswith(\"_decoding_predict_proba_table.parquet\"):\n",
    "        key = filename.replace(\"_decoding_predict_proba_table.parquet\", \"\")\n",
    "        df = pd.read_parquet(os.path.join(savepath, filename))\n",
    "        results_dfs[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a816bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_performance=pl.scan_parquet('s3://aind-scratch-data/dynamic-routing/cache/nwb_components/v0.0.268/consolidated/performance.parquet').collect()#.to_pandas()\n",
    "all_trials=pl.scan_parquet('s3://aind-scratch-data/dynamic-routing/cache/nwb_components/v0.0.268/consolidated/trials.parquet').collect()#.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f91242",
   "metadata": {},
   "outputs": [],
   "source": [
    "###update the code below to match subsets of trials, i.e. only aud stim trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42faaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load specific parquet file\n",
    "results_dfs={}\n",
    "loadpath=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\CO decoding results\\compare-context-lick-stimulus-predict-proba-2025-09-22\"\n",
    "filename=\"context_vis_stim_25ms_bins_w_repeats_decoding_predict_proba_table.parquet\"\n",
    "\n",
    "key=filename.replace(\"_decoding_predict_proba_table.parquet\", \"\")\n",
    "results_dfs[key] = pd.read_parquet(os.path.join(loadpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b05b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 2 structures - OPTIMIZED VERSION\n",
    "# sel_structure_1='ORBl'\n",
    "# sel_structure_2='ACAd'\n",
    "# sel_session='664851_2023-11-13'\n",
    "\n",
    "sel_key='context_vis_stim_25ms_bins_w_repeats'\n",
    "# sel_key='context_500ms_bins'\n",
    "\n",
    "correction = 'flip_aud' # 'flip_aud', 'subtract_mean', 'none'\n",
    "excl_instruction_trials = True\n",
    "\n",
    "# Preprocess data once\n",
    "results_dfs[sel_key]['bin_center'] = np.round(results_dfs[sel_key]['bin_center'], 3)\n",
    "dr_session_set = set(dr_session_list)  # Convert to set for O(1) lookup\n",
    "\n",
    "# Pre-filter all_trials if needed\n",
    "if excl_instruction_trials:\n",
    "    all_trials_filtered = all_trials.to_pandas().query('~is_instruction')\n",
    "else:\n",
    "    all_trials_filtered = all_trials.to_pandas()\n",
    "\n",
    "# Pre-compute choice predict proba logic\n",
    "def compute_choice_predict_proba(df):\n",
    "    \"\"\"Vectorized computation of choice predict proba\"\"\"\n",
    "    choice_proba = np.full(len(df), np.nan)\n",
    "    # False alarms\n",
    "    fa_mask = ((df['is_response'] == True) & \n",
    "               (((df['stim_name'] == 'vis1') & (df['rewarded_modality'] == 'aud')) |\n",
    "                ((df['stim_name'] == 'sound1') & (df['rewarded_modality'] == 'vis'))))\n",
    "    choice_proba[fa_mask] = -1\n",
    "    \n",
    "    # Correct rejects  \n",
    "    cr_mask = ((df['is_response'] == False) & \n",
    "               (((df['stim_name'] == 'vis1') & (df['rewarded_modality'] == 'aud')) |\n",
    "                ((df['stim_name'] == 'sound1') & (df['rewarded_modality'] == 'vis'))))\n",
    "    choice_proba[cr_mask] = 1\n",
    "    return choice_proba\n",
    "\n",
    "# Initialize results storage\n",
    "results_data = []\n",
    "\n",
    "# Main processing loop\n",
    "for sel_session in results_dfs[sel_key]['session_id'].unique():\n",
    "    if sel_session not in dr_session_set:\n",
    "        continue\n",
    "        \n",
    "    # Get session data once\n",
    "    session_df = results_dfs[sel_key].query('session_id == @sel_session').copy()\n",
    "    session_trials = all_trials_filtered.query('session_id == @sel_session').copy()\n",
    "    \n",
    "    if session_trials.empty:\n",
    "        continue\n",
    "    \n",
    "    # Compute choice predict proba once\n",
    "    session_trials['choice_predict_proba'] = compute_choice_predict_proba(session_trials)\n",
    "    \n",
    "    # Create lookup dictionaries for faster access\n",
    "    session_df_grouped = session_df.groupby(['bin_center', 'structure'])['predict_proba'].first()\n",
    "\n",
    "    trial_indices = session_trials['trial_index'].values\n",
    "\n",
    "    #assume all structures have the same trial indices\n",
    "    predict_proba_trial_indices = session_df['trial_index'].iloc[0]\n",
    "\n",
    "    trial_intersection = np.intersect1d(trial_indices, predict_proba_trial_indices)\n",
    "\n",
    "    temp_predict_proba_index=[]\n",
    "    for x in predict_proba_trial_indices:\n",
    "        if x in trial_intersection:\n",
    "            temp_predict_proba_index.append(True)\n",
    "        else:\n",
    "            temp_predict_proba_index.append(False)\n",
    "    temp_predict_proba_index=np.array(temp_predict_proba_index)\n",
    "\n",
    "    session_trials = session_trials[session_trials['trial_index'].isin(trial_intersection)]\n",
    "\n",
    "    structure_list = np.concatenate([session_df['structure'].unique(), np.array(['choice'])])\n",
    "    bin_centers = session_df['bin_center'].unique()\n",
    "    \n",
    "    # Process all structures and bin centers for this session\n",
    "    session_predict_proba_cols = {}\n",
    "    \n",
    "    for bin_center in bin_centers:\n",
    "        # Add choice column for each bin center\n",
    "        session_predict_proba_cols[f'choice_predict_proba_{bin_center}'] = session_trials['choice_predict_proba'].values\n",
    "        \n",
    "        # Process structures for this bin center\n",
    "        bin_structures = session_df.query('bin_center == @bin_center')['structure'].unique()\n",
    "        \n",
    "        for structure in bin_structures:\n",
    "            try:\n",
    "                temp_predict_proba = session_df_grouped.loc[(bin_center, structure)]\n",
    "\n",
    "                temp_predict_proba = temp_predict_proba[temp_predict_proba_index]\n",
    "                \n",
    "                # if len(temp_predict_proba) > trial_indices.max():\n",
    "                #     temp_predict_proba = temp_predict_proba[trial_indices]\n",
    "                # else:\n",
    "                #     print(f'warning! predict_proba length too short for {structure}, session {sel_session}, bin {bin_center}')\n",
    "                #     continue\n",
    "\n",
    "                # if len(temp_predict_proba) != len(session_trials):\n",
    "                #     print(f'warning! predict_proba length mismatch for {structure}, session {sel_session}, bin {bin_center}')\n",
    "                #     continue\n",
    "                \n",
    "                # Vectorized correction computation\n",
    "                if correction == 'flip_aud':\n",
    "                    # Create correction mask\n",
    "                    aud_mask = session_trials['rewarded_modality'] == 'aud'\n",
    "                    corrected_proba = temp_predict_proba.copy()\n",
    "                    corrected_proba[aud_mask] = 1 - corrected_proba[aud_mask]\n",
    "                elif correction == 'subtract_mean':\n",
    "                    # Group by block and subtract mean\n",
    "                    corrected_parts = []\n",
    "                    for block_idx in session_trials['block_index'].unique():\n",
    "                        block_mask = session_trials['block_index'] == block_idx\n",
    "                        block_proba = temp_predict_proba[block_mask]\n",
    "                        corrected_parts.append(block_proba - np.nanmean(block_proba))\n",
    "                    corrected_proba = np.concatenate(corrected_parts)\n",
    "                else:  # correction == 'none'\n",
    "                    corrected_proba = temp_predict_proba.copy()\n",
    "                \n",
    "                session_predict_proba_cols[f'{structure}_predict_proba_{bin_center}'] = corrected_proba\n",
    "                \n",
    "            except KeyError:\n",
    "                continue\n",
    "    \n",
    "    # Add all computed columns to session_trials at once\n",
    "    for col_name, col_data in session_predict_proba_cols.items():\n",
    "        session_trials[col_name] = col_data\n",
    "    \n",
    "    # Compute correlations for all structure pairs and bin centers\n",
    "    for bin_center in bin_centers:\n",
    "        for structure_1 in structure_list:\n",
    "            for structure_2 in ['choice']:  # structure_list:\n",
    "                if structure_1 == structure_2:\n",
    "                    continue\n",
    "                \n",
    "                col1 = f'{structure_1}_predict_proba_{bin_center}'\n",
    "                col2 = f'{structure_2}_predict_proba_{bin_center}'\n",
    "                \n",
    "                if col1 not in session_trials.columns or col2 not in session_trials.columns:\n",
    "                    continue\n",
    "                \n",
    "                result1 = session_trials[col1].values\n",
    "                result2 = session_trials[col2].values\n",
    "                \n",
    "                if len(result1) != len(result2):\n",
    "                    continue\n",
    "                \n",
    "                # Vectorized NaN handling\n",
    "                valid_mask = ~(np.isnan(result1) | np.isnan(result2))\n",
    "                \n",
    "                if np.sum(valid_mask) < 3:  # Need at least 3 points for correlation\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    r, p = stats.pearsonr(result1[valid_mask], result2[valid_mask])\n",
    "                    \n",
    "                    results_data.append({\n",
    "                        'structure_1': structure_1,\n",
    "                        'structure_2': structure_2,\n",
    "                        'session_id': sel_session,\n",
    "                        'results_key': sel_key,\n",
    "                        'bin_center': bin_center,\n",
    "                        'pearson_r': r,\n",
    "                        'p_value': p\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "# Create DataFrame from results\n",
    "predict_proba_corr_by_bin_center_df = pd.DataFrame(results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath=r'\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\CO decoding results\\predict_proba_corr_across_bin_centers_2025-10-01'\n",
    "predict_proba_corr_by_bin_center_df.to_parquet(os.path.join(savepath, \"predict_proba_corr_across_bin_centers_\"+sel_key+\"_choice_corrected.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d508fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare correlation values across different structure pairs\n",
    "structure1='MOs'\n",
    "structure2='choice'\n",
    "\n",
    "sel_key='context_no_baseline_subtract_vis_stim_10units'\n",
    "\n",
    "corr_by_session=[]\n",
    "\n",
    "pair_df=predict_proba_corr_by_bin_center_df.query('structure_1==@structure1 and structure_2==@structure2 and results_key==@sel_key')\n",
    "\n",
    "for sel_session in pair_df['session_id'].unique():\n",
    "    temp_session_df=pair_df.query('session_id==@sel_session').sort_values('bin_center')\n",
    "    if temp_session_df.shape[0]==0:\n",
    "        continue\n",
    "    corr_by_session.append(temp_session_df['pearson_r'].values)\n",
    "\n",
    "corr_by_session=np.vstack(corr_by_session)\n",
    "\n",
    "bins=np.round(pair_df['bin_center'].unique(),3)+0.025\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,3))\n",
    "ax.axhline(0,color='k',linewidth=0.5,linestyle='--')\n",
    "ax.axvline(0,color='k',linewidth=0.5,linestyle='--')\n",
    "ax.plot(bins, corr_by_session.T, color='gray', alpha=0.3)\n",
    "ax.plot(bins, np.nanmean(corr_by_session,axis=0),'k')\n",
    "ax.set_xlabel('bin center (s)')\n",
    "ax.set_ylabel('Pearson r')\n",
    "ax.set_title(f\"{structure1} vs {structure2}; {sel_key}\\n(n={corr_by_session.shape[0]} sessions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea51970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot list of areas against single area\n",
    "\n",
    "# sel_structure='SCm'\n",
    "\n",
    "# struct_list=['SCm','MRN','CP','MOs','AId','ACAd','FRP','ORBl','PL','ILA','SSp','MOp','VISp','CA1','MD','RT','choice',]\n",
    "# struct_list=['SCm','MRN','CP','MOs','AId','ACAd','FRP','ORBl','PL','choice',]\n",
    "# struct_list=['SCm','MRN','CP','MOs','MOp','SSp','AId','ACAd','FRP','ORBl','VTA','GPe','RT','MD','choice',]\n",
    "# struct_list=['VISp','AUDp','LGd','MGd','MD','RT','VAL']\n",
    "# struct_list=['choice']\n",
    "# struct_list=['SCm','MRN','CP','MOs','AId','ACAd','ORBl','VTA','GPe','RT','MD','choice',]\n",
    "\n",
    "\n",
    "# struct_list=['ACAd','MOs','PL','ORBl','FRP','AId','MOp','SSp','AUDp','VISp'] #ctx\n",
    "# struct_list=['SCm','SCs','MRN','PAG','APN','CP','GPe','VTA','SNr'] #mb\n",
    "# struct_list=['MD','RT','VAL','VPL','ZI','VL','POL','LGd','MGd'] #thal\n",
    "\n",
    "structure_sets={\n",
    "    'cortex': ['ACAd','MOs','PL','ORBl','FRP','AId','MOp','SSp','AUDp','VISp'],\n",
    "    'mb_bg': ['SCm','SCs','MRN','PAG','APN','CP','GPe','VTA','SNr'],\n",
    "    'thalamus': ['MD','RT','VAL','VPL','ZI','VL','POL','VPM','LGd','MGd'],\n",
    "}\n",
    "\n",
    "\n",
    "# savepath=r\"C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\quick figures\\2025-10-01-decoding_latency\"\n",
    "\n",
    "color_list=plt.cm.tab10.colors\n",
    "\n",
    "sel_key='context_no_baseline_subtract_vis_stim_10units'\n",
    "\n",
    "for structure_set_name, struct_list in structure_sets.items():\n",
    "\n",
    "    for sel_structure in struct_list:\n",
    "        sel_structure='choice'\n",
    "        n_list=[]\n",
    "\n",
    "        fig,ax=plt.subplots(1,1,figsize=(5.5,3))\n",
    "        ax.axhline(0,color='k',linewidth=0.5,linestyle='--')\n",
    "        ax.axvline(0,color='k',linewidth=0.5,linestyle='--')\n",
    "        for ss,sel_structure_2 in enumerate(struct_list):\n",
    "            if sel_structure_2 == sel_structure:\n",
    "                continue\n",
    "            pair_df=predict_proba_corr_by_bin_center_df.query('structure_2==@sel_structure and structure_1==@sel_structure_2 and results_key==@sel_key')\n",
    "\n",
    "            corr_by_session=[]\n",
    "\n",
    "            for sel_session in pair_df['session_id'].unique():\n",
    "                temp_session_df=pair_df.query('session_id==@sel_session').sort_values('bin_center')\n",
    "                if temp_session_df.shape[0]==0:\n",
    "                    continue\n",
    "                corr_by_session.append(temp_session_df['pearson_r'].values)\n",
    "\n",
    "            if len(corr_by_session)<=1:\n",
    "                continue\n",
    "\n",
    "            corr_by_session=np.vstack(corr_by_session)\n",
    "\n",
    "            bins=np.round(pair_df['bin_center'].unique(),3)+0.025\n",
    "\n",
    "            if ss<len(color_list):\n",
    "                line_style='-'\n",
    "            if ss>len(color_list)-1:\n",
    "                ss=ss-len(color_list)\n",
    "                line_style='--'\n",
    "\n",
    "            ax.plot(bins, np.nanmean(corr_by_session,axis=0), label=sel_structure_2+f' ({corr_by_session.shape[0]})', color=color_list[ss], linestyle=line_style)\n",
    "        ax.set_xlabel('bin center (s)')\n",
    "        ax.set_ylabel('Pearson r')\n",
    "        # ax.set_ylim([0.1,0.9])\n",
    "        # ax.set_xlim([-0.05,0.25])\n",
    "        ax.set_title(f\"{sel_structure} vs other areas; {sel_key}\")\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.35, 1))\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(savepath, f\"{sel_structure}_vs_other_areas_{sel_key}_{structure_set_name}.png\"), dpi=300)\n",
    "        plt.close(fig)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88088485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr_ibl_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
