{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.signal as sg\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import npc_lims\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from npc_sessions import DynamicRoutingSession\n",
    "import npc_session\n",
    "from dynamic_routing_analysis import spike_utils, plot_utils\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "regenerate_table=False\n",
    "all_data_loadpath=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\all_data_plus_performance.pkl\"\n",
    "\n",
    "if regenerate_table:\n",
    "    savepath=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\"\n",
    "    stim_context_loadpath = os.path.join(savepath,\"all_stim_context_modulation.pkl\")\n",
    "    lick_loadpath = os.path.join(savepath,\"all_lick_modulation.pkl\")\n",
    "    performance_loadpath = os.path.join(savepath,\"performance_dict.pkl\")\n",
    "    spike_utils.concat_single_unit_metrics_across_sessions(stim_context_loadpath=stim_context_loadpath,lick_loadpath=lick_loadpath,\n",
    "                                                           performance_loadpath=performance_loadpath,savepath=savepath)\n",
    "\n",
    "all_data = pd.read_pickle(all_data_loadpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_project='DynamicRouting'\n",
    "sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                            isi_violations_ratio<=0.1 and \\\n",
    "                            amplitude_cutoff<=0.1 and \\\n",
    "                            project.str.contains(@sel_project) and \\\n",
    "                            ~structure.isna() and ~location.isna() and \\\n",
    "                            cross_modal_dprime>=1.0')\n",
    "\n",
    "adj_pvals=spike_utils.calculate_single_unit_metric_adjusted_pvals(sel_units,sel_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed051df419b647cbbde2081870722916",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot overall stimulus modulation\n",
    "spike_utils.plot_stimulus_modulation(adj_pvals,sel_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate stimulus modulation by region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fdrcorrection(sel_units['lick_modulation_p_value'])\n",
    "# np.mean(adj_pvals['context_linear_shift']<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\example_PSTHs\\stim\"\n",
    "\n",
    "# multimodal_units=np.random.choice(mixed_stim_resp['unit_id'].values,100)\n",
    "# for uid in multimodal_units:\n",
    "#     if sel_units.query('unit_id==@uid')['structure'].values[0]=='RT':\n",
    "#         try:\n",
    "#             plot_utils.plot_unit_by_id(uid,save_path,'stimulus: multimodal')\n",
    "#         except:\n",
    "#             print(f'unit {uid} failed')\n",
    "\n",
    "# vis1_only_units=np.random.choice(vis1_stim_resp['unit_id'].values,20)\n",
    "# for uid in vis1_only_units:\n",
    "#     try:\n",
    "#         plot_utils.plot_stim_response_by_unit_id(uid,save_path,'visual responsive')\n",
    "#     except:\n",
    "#         print(f'unit {uid} failed')\n",
    "\n",
    "sound1_only_units=np.random.choice(sound1_stim_resp['unit_id'].values,30)\n",
    "for uid in sound1_only_units:\n",
    "    try:\n",
    "        plot_utils.plot_stim_response_by_unit_id(uid,save_path,'auditory responsive')\n",
    "    except:\n",
    "        print(f'unit {uid} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=pd.read_parquet(\n",
    "                npc_lims.get_cache_path('trials',uid[:17],version='any')\n",
    "            )\n",
    "trials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulus responses\n",
    "labels=['vis1 only','vis2 only','both vis',\n",
    "        'sound1 only','sound2 only','both sound',\n",
    "        'mixed','none','catch']\n",
    "sizes=[len(vis1_stim_resp),len(vis2_stim_resp),len(both_vis_stim_resp),\n",
    "        len(sound1_stim_resp),len(sound2_stim_resp),len(both_sound_stim_resp),\n",
    "        len(mixed_stim_resp),len(no_stim_resp),len(catch_stim_resp)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax.set_title('n = '+str(len(sel_units))+' units')\n",
    "fig.suptitle('stimulus responsiveness')\n",
    "fig.tight_layout()\n",
    "\n",
    "# if 'Templeton' in sel_project:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"stimulus_responsiveness_Templeton.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "# else:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"stimulus_responsiveness_DR.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulus context modulation\n",
    "vis1_context_stim_mod=adj_pvals.query('vis1_context<0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "vis2_context_stim_mod=adj_pvals.query('vis2_context<0.05 and vis1_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "sound1_context_stim_mod=adj_pvals.query('sound1_context<0.05 and sound2_context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "sound2_context_stim_mod=adj_pvals.query('sound2_context<0.05 and sound1_context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "\n",
    "both_vis_context_stim_mod=adj_pvals.query('vis1_context<0.05 and vis2_context<0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "both_aud_context_stim_mod=adj_pvals.query('sound1_context<0.05 and sound2_context<0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "multi_modal_context_stim_mod=adj_pvals.query('((vis1_context<0.05 or vis2_context<0.05) and (sound1_context<0.05 or sound2_context<0.05)) and any_stim<0.05')\n",
    "\n",
    "no_context_stim_mod=adj_pvals.query('vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "\n",
    "#evoked stimulus context modulation\n",
    "vis1_context_evoked_stim_mod=adj_pvals.query('vis1_context_evoked<0.05 and vis2_context_evoked>=0.05 and sound1_context_evoked>=0.05 and sound2_context_evoked>=0.05 and any_stim<0.05')\n",
    "vis2_context_evoked_stim_mod=adj_pvals.query('vis2_context_evoked<0.05 and vis1_context_evoked>=0.05 and sound1_context_evoked>=0.05 and sound2_context_evoked>=0.05 and any_stim<0.05')\n",
    "sound1_context_evoked_stim_mod=adj_pvals.query('sound1_context_evoked<0.05 and sound2_context_evoked>=0.05 and vis1_context_evoked>=0.05 and vis2_context_evoked>=0.05 and any_stim<0.05')\n",
    "sound2_context_evoked_stim_mod=adj_pvals.query('sound2_context_evoked<0.05 and sound1_context_evoked>=0.05 and vis1_context_evoked>=0.05 and vis2_context_evoked>=0.05 and any_stim<0.05')\n",
    "\n",
    "both_vis_context_evoked_stim_mod=adj_pvals.query('vis1_context_evoked<0.05 and vis2_context_evoked<0.05 and sound1_context_evoked>=0.05 and sound2_context_evoked>=0.05 and any_stim<0.05')\n",
    "both_aud_context_evoked_stim_mod=adj_pvals.query('sound1_context_evoked<0.05 and sound2_context_evoked<0.05 and vis1_context_evoked>=0.05 and vis2_context_evoked>=0.05 and any_stim<0.05')\n",
    "multi_modal_context_evoked_stim_mod=adj_pvals.query('((vis1_context_evoked<0.05 or vis2_context_evoked<0.05) and (sound1_context_evoked<0.05 or sound2_context_evoked<0.05)) and any_stim<0.05')\n",
    "\n",
    "no_context_evoked_stim_mod=adj_pvals.query('vis1_context_evoked>=0.05 and vis2_context_evoked>=0.05 and sound1_context_evoked>=0.05 and sound2_context_evoked>=0.05 and any_stim<0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['vis1 only','vis2 only','both vis',\n",
    "        'sound1 only','sound2 only','both sound',\n",
    "        'mixed','none']\n",
    "sizes=[len(vis1_context_stim_mod),len(vis2_context_stim_mod),len(both_vis_context_stim_mod),\n",
    "        len(sound1_context_stim_mod),len(sound2_context_stim_mod),len(both_aud_context_stim_mod),\n",
    "        len(multi_modal_context_stim_mod),len(no_context_stim_mod)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax.set_title('n = '+str(len(any_stim_resp))+' units')\n",
    "# ax.set_title('n = '+str(len(stim_and_context))+' units')\n",
    "\n",
    "fig.suptitle('context modulation of stimulus response')\n",
    "fig.tight_layout()\n",
    "\n",
    "# if 'Templeton' in sel_project:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_modulation_raw_stim_resp_Templeton.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "# else:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_modulation_raw_stim_resp_DR.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['vis1 only','vis2 only','both vis',\n",
    "        'sound1 only','sound2 only','both sound',\n",
    "        'mixed','none']\n",
    "sizes=[len(vis1_context_evoked_stim_mod),len(vis2_context_evoked_stim_mod),len(both_vis_context_evoked_stim_mod),\n",
    "        len(sound1_context_evoked_stim_mod),len(sound2_context_evoked_stim_mod),len(both_aud_context_evoked_stim_mod),\n",
    "        len(multi_modal_context_evoked_stim_mod),len(no_context_evoked_stim_mod)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax.set_title('n = '+str(len(any_stim_resp))+' units')\n",
    "\n",
    "fig.suptitle('context modulation of evoked stimulus response')\n",
    "fig.tight_layout()\n",
    "\n",
    "# if 'Templeton' in sel_project:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_modulation_evoked_stim_resp_Templeton.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "# else:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_modulation_evoked_stim_resp_DR.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lick modulation only\n",
    "lick_resp=adj_pvals.query('lick<0.05 and context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "\n",
    "#lick and context\n",
    "lick_and_context_resp=adj_pvals.query('context<0.05 and lick<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "\n",
    "#lick and stimulus\n",
    "lick_and_stim_resp=adj_pvals.query('lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05')\n",
    "\n",
    "#all three\n",
    "all_resp=adj_pvals.query('context<0.05 and lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "\n",
    "#stimulus modulation only\n",
    "only_stim_resp=adj_pvals.query('(vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05 and lick>=0.05')\n",
    "\n",
    "#context modulation only\n",
    "context_resp=adj_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "\n",
    "#stim and context modulation\n",
    "stim_and_context_resp=adj_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and lick>=0.05')\n",
    "\n",
    "neither_stim_nor_context_resp=adj_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_pvals['lick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_only_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\example_PSTHs\\context\"\n",
    "\n",
    "# # context_only_units=np.random.choice(context_resp['unit_id'].values,10)\n",
    "# context_any_units=np.random.choice(adj_pvals.query('context<0.05 and context_roc_auc<0.3')['unit_id'].values,10)\n",
    "# for uid in context_any_units:\n",
    "#     # try:\n",
    "#         plot_utils.plot_context_offset_by_unit_id(uid,save_path,'context only')\n",
    "#     # except:\n",
    "#     #     print(f'unit {uid} failed')\n",
    "\n",
    "plot_utils.plot_context_offset_by_unit_id('666986_2023-08-17_C-75',save_path,'context')\n",
    "\n",
    "# save_path=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\example_PSTHs\\lick\"\n",
    "# # lick_only_units=np.random.choice(lick_resp['unit_id'].values,25)\n",
    "# lick_any_units=np.random.choice(adj_pvals.query('lick<0.05  and lick_roc_auc>0.6 and structure==\"MOp\"')['unit_id'].values,10)\n",
    "# for uid in lick_any_units:\n",
    "#     try:\n",
    "#         plot_utils.plot_motor_response_by_unit_id(uid,save_path,'lick only')\n",
    "#     except:\n",
    "#         print(f'unit {uid} failed')\n",
    "\n",
    "# plot_utils.plot_motor_response_by_unit_id('706401_2024-04-22_C-72',save_path,'lick only')\n",
    "\n",
    "# all_resp_units=np.random.choice(all_resp['unit_id'].values,5)\n",
    "# for uid in all_resp_units:\n",
    "#     try:\n",
    "#         plot_utils.plot_unit_by_id(uid,save_path,'lick & context & stim')\n",
    "#     except:\n",
    "#         print(f'unit {uid} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['stimulus only','stimulus and context','context only',\n",
    "        'context and lick','lick only', 'lick & stimulus & context',\n",
    "         'lick and stimulus',  'none']\n",
    "sizes=[len(only_stim_resp),len(stim_and_context_resp),len(context_resp),\n",
    "        len(lick_and_context_resp),len(lick_resp),len(all_resp),\n",
    "        len(lick_and_stim_resp), len(neither_stim_nor_context_resp)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'tab:red' , 'tab:purple', 'tab:brown', \n",
    "               'tab:pink', 'grey'])\n",
    "ax.set_title('n = '+str(len(sel_units))+' units')\n",
    "fig.suptitle('context, lick, and stim modulation')\n",
    "fig.tight_layout()\n",
    "\n",
    "# if 'Templeton' in sel_project:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_lick_stim_mod_Templeton.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "# else:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_lick_stim_mod_DR.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempsavepath=r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\"\n",
    "\n",
    "stim_lick_context_summary={\n",
    "    'stimulus only':len(only_stim_resp),\n",
    "    'stimulus and context':len(stim_and_context_resp),\n",
    "    'context only':len(context_resp),\n",
    "    'context and lick':len(lick_and_context_resp),\n",
    "    'lick only':len(lick_resp), \n",
    "    'lick & stimulus & context':len(all_resp),\n",
    "    'lick and stimulus':len(lick_and_stim_resp),  \n",
    "    'none':len(neither_stim_nor_context_resp),\n",
    "}\n",
    "\n",
    "stim_lick_context_summary=pd.DataFrame(stim_lick_context_summary,index=['all'])\n",
    "stim_lick_context_summary.to_csv(os.path.join(tempsavepath,'stim_lick_context_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bar plot version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context, lick, and stim modulation per layer\n",
    "\n",
    "layers=['2/3','4','5','6']\n",
    "\n",
    "layer_n={}\n",
    "\n",
    "lick_resp_layer={}\n",
    "lick_and_context_resp_layer={}\n",
    "lick_and_stim_resp_layer={}\n",
    "all_resp_layer={}\n",
    "any_stim_resp_layer={}\n",
    "context_resp_layer={}\n",
    "stim_and_context_resp_layer={}\n",
    "neither_stim_nor_context_resp_layer={}\n",
    "\n",
    "for layer in layers:\n",
    "\n",
    "    if layer=='2/3':\n",
    "        layer_pvals=adj_pvals.query('location.str.contains(@layer) or location.str.contains(\"1\") and not location.str.contains(\"CA1\")')\n",
    "    else:\n",
    "        layer_pvals=adj_pvals.query('location.str.contains(@layer)')\n",
    "\n",
    "    layer_n[layer]=len(layer_pvals)\n",
    "    #lick modulation only\n",
    "    lick_resp_layer[layer]=layer_pvals.query('lick<0.05 and context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "    #lick and context\n",
    "    lick_and_context_resp_layer[layer]=layer_pvals.query('context<0.05 and lick<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "    #lick and stimulus\n",
    "    lick_and_stim_resp_layer[layer]=layer_pvals.query('lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05')\n",
    "    #all three\n",
    "    all_resp_layer[layer]=layer_pvals.query('context<0.05 and lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "    #stimulus modulation only\n",
    "    any_stim_resp_layer[layer]=layer_pvals.query('(vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05 and lick>=0.05')\n",
    "    #context modulation only\n",
    "    context_resp_layer[layer]=layer_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "    #stim and context modulation\n",
    "    stim_and_context_resp_layer[layer]=layer_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and lick>=0.05')\n",
    "    neither_stim_nor_context_resp_layer[layer]=layer_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot stuff\n",
    "labels=['stimulus only','stimulus and context','context only',\n",
    "        'context and lick','lick only', 'lick & stimulus & context',\n",
    "         'lick and stimulus',  'none']\n",
    "\n",
    "L23_sizes=[len(any_stim_resp_layer['2/3']),len(stim_and_context_resp_layer['2/3']),len(context_resp_layer['2/3']),\n",
    "        len(lick_and_context_resp_layer['2/3']),len(lick_resp_layer['2/3']),len(all_resp_layer['2/3']),\n",
    "        len(lick_and_stim_resp_layer['2/3']), len(neither_stim_nor_context_resp_layer['2/3'])]\n",
    "\n",
    "L4_sizes=[len(any_stim_resp_layer['4']),len(stim_and_context_resp_layer['4']),len(context_resp_layer['4']),\n",
    "        len(lick_and_context_resp_layer['4']),len(lick_resp_layer['4']),len(all_resp_layer['4']),\n",
    "        len(lick_and_stim_resp_layer['4']), len(neither_stim_nor_context_resp_layer['4'])]\n",
    "\n",
    "L5_sizes=[len(any_stim_resp_layer['5']),len(stim_and_context_resp_layer['5']),len(context_resp_layer['5']),\n",
    "        len(lick_and_context_resp_layer['5']),len(lick_resp_layer['5']),len(all_resp_layer['5']),\n",
    "        len(lick_and_stim_resp_layer['5']), len(neither_stim_nor_context_resp_layer['5'])]\n",
    "\n",
    "L6_sizes=[len(any_stim_resp_layer['6']),len(stim_and_context_resp_layer['6']),len(context_resp_layer['6']),\n",
    "        len(lick_and_context_resp_layer['6']),len(lick_resp_layer['6']),len(all_resp_layer['6']),\n",
    "        len(lick_and_stim_resp_layer['6']), len(neither_stim_nor_context_resp_layer['6'])]\n",
    "\n",
    "fig,ax=plt.subplots(2,2,figsize=(10,10))\n",
    "ax[0,0].pie(L23_sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax[0,0].set_title('L2/3 n='+str(layer_n['2/3']))\n",
    "ax[0,1].pie(L4_sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax[0,1].set_title('L4 n='+str(layer_n['4']))\n",
    "ax[1,0].pie(L5_sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax[1,0].set_title('L5 n='+str(layer_n['5']))\n",
    "ax[1,1].pie(L6_sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax[1,1].set_title('L6 n='+str(layer_n['6']))\n",
    "fig.suptitle('context, lick, and stim modulation by layer')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# if 'Templeton' in sel_project:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_lick_stim_mod_by_layer_Templeton.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "# else:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_lick_stim_mod_by_layer_DR.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context, lick, and stim modulation per RS/FS\n",
    "\n",
    "RS_FS=['RS','FS']\n",
    "\n",
    "RS_FS_n={}\n",
    "\n",
    "lick_resp_RS_FS={}\n",
    "lick_and_context_resp_RS_FS={}\n",
    "lick_and_stim_resp_RS_FS={}\n",
    "all_resp_RS_FS={}\n",
    "any_stim_resp_RS_FS={}\n",
    "context_resp_RS_FS={}\n",
    "stim_and_context_resp_RS_FS={}\n",
    "neither_stim_nor_context_resp_RS_FS={}\n",
    "\n",
    "for celltype in RS_FS:\n",
    "\n",
    "    if celltype=='RS':\n",
    "        celltype_pvals=adj_pvals.query('peak_to_valley>0.0004')\n",
    "    elif celltype=='FS':\n",
    "        celltype_pvals=adj_pvals.query('peak_to_valley<=0.0004')\n",
    "\n",
    "    RS_FS_n[celltype]=len(celltype_pvals)\n",
    "    #lick modulation only\n",
    "    lick_resp_RS_FS[celltype]=celltype_pvals.query('lick<0.05 and context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "    #lick and context\n",
    "    lick_and_context_resp_RS_FS[celltype]=celltype_pvals.query('context<0.05 and lick<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "    #lick and stimulus\n",
    "    lick_and_stim_resp_RS_FS[celltype]=celltype_pvals.query('lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05')\n",
    "    #all three\n",
    "    all_resp_RS_FS[celltype]=celltype_pvals.query('context<0.05 and lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "    #stimulus modulation only\n",
    "    any_stim_resp_RS_FS[celltype]=celltype_pvals.query('(vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05 and lick>=0.05')\n",
    "    #context modulation only\n",
    "    context_resp_RS_FS[celltype]=celltype_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "    #stim and context modulation\n",
    "    stim_and_context_resp_RS_FS[celltype]=celltype_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and lick>=0.05')\n",
    "    neither_stim_nor_context_resp_RS_FS[celltype]=celltype_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot stuff\n",
    "labels=['stimulus only','stimulus and context','context only',\n",
    "        'context and lick','lick only', 'lick & stimulus & context',\n",
    "         'lick and stimulus',  'none']\n",
    "\n",
    "RS_sizes=[len(any_stim_resp_RS_FS['RS']),len(stim_and_context_resp_RS_FS['RS']),len(context_resp_RS_FS['RS']),\n",
    "        len(lick_and_context_resp_RS_FS['RS']),len(lick_resp_RS_FS['RS']),len(all_resp_RS_FS['RS']),\n",
    "        len(lick_and_stim_resp_RS_FS['RS']), len(neither_stim_nor_context_resp_RS_FS['RS'])]\n",
    "\n",
    "FS_sizes=[len(any_stim_resp_RS_FS['FS']),len(stim_and_context_resp_RS_FS['FS']),len(context_resp_RS_FS['FS']),\n",
    "        len(lick_and_context_resp_RS_FS['FS']),len(lick_resp_RS_FS['FS']),len(all_resp_RS_FS['FS']),\n",
    "        len(lick_and_stim_resp_RS_FS['FS']), len(neither_stim_nor_context_resp_RS_FS['FS'])]\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].pie(RS_sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax[0].set_title('RS n='+str(RS_FS_n['RS']))\n",
    "ax[1].pie(FS_sizes,labels=labels,autopct='%1.1f%%')\n",
    "ax[1].set_title('FS n='+str(RS_FS_n['FS']))\n",
    "fig.suptitle('context, lick, and stim modulation by cell type')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# if 'Templeton' in sel_project:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_lick_stim_mod_by_celltype_Templeton.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "# else:\n",
    "#         fig.savefig(\n",
    "#                 os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_lick_stim_mod_by_celltype_DR.png\"),\n",
    "#                 dpi=300, facecolor='w', edgecolor='w',\n",
    "#                 orientation='portrait', format='png',\n",
    "#                 transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                 metadata=None)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_units['session_id'].unique()\n",
    "# adj_pvals.query('location.str.contains(\"MOs5\")')\n",
    "# layer\n",
    "# adj_pvals['location'].iloc[0]\n",
    "# adj_pvals['structure'].values\n",
    "# sel_units['structure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_pvals['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context, lick, stim modulation per cell type (FS, RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare raw vs evoked context-based stimulus modulation\n",
    "raw_context_stim_mod_only=adj_pvals.query('(vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05) and \\\n",
    "                                          (vis1_context_evoked>=0.05 and vis2_context_evoked>=0.05 and sound1_context_evoked>=0.05 and sound2_context_evoked>=0.05) \\\n",
    "                                          and any_stim<0.05')\n",
    "\n",
    "evoked_context_stim_mod_only=adj_pvals.query('(vis1_context_evoked<0.05 or vis2_context_evoked<0.05 or sound1_context_evoked<0.05 or sound2_context_evoked<0.05) and \\\n",
    "                                            (vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05) \\\n",
    "                                            and any_stim<0.05')\n",
    "\n",
    "raw_and_evoked_context_stim_mod=adj_pvals.query('(vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05) and \\\n",
    "                                                (vis1_context_evoked<0.05 or vis2_context_evoked<0.05 or sound1_context_evoked<0.05 or sound2_context_evoked<0.05) \\\n",
    "                                                and any_stim<0.05')\n",
    "\n",
    "neither_raw_nor_evoked_context_stim_mod=adj_pvals.query('vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and \\\n",
    "                                                        vis1_context_evoked>=0.05 and vis2_context_evoked>=0.05 and sound1_context_evoked>=0.05 and sound2_context_evoked>=0.05 \\\n",
    "                                                        and any_stim<0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_context_stim_only_units=np.random.choice(raw_context_stim_mod_only['unit_id'].values,5)\n",
    "for uid in raw_context_stim_only_units:\n",
    "    try:\n",
    "        plot_utils.plot_unit_by_id(uid,save_path,'context mod raw stim only')\n",
    "    except:\n",
    "        print(f'unit {uid} failed')\n",
    "\n",
    "raw_and_evoked_context_stim_mod_units=np.random.choice(raw_and_evoked_context_stim_mod['unit_id'].values,5)\n",
    "for uid in raw_and_evoked_context_stim_mod_units:\n",
    "    try:\n",
    "        plot_utils.plot_unit_by_id(uid,save_path,'context mod raw & evoked stim')\n",
    "    except:\n",
    "        print(f'unit {uid} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['raw only','evoked only','both raw and evoked',\n",
    "        'neither']\n",
    "sizes=[len(raw_context_stim_mod_only),len(evoked_context_stim_mod_only),len(raw_and_evoked_context_stim_mod),\n",
    "        len(neither_raw_nor_evoked_context_stim_mod)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'grey'])\n",
    "ax.set_title('n = '+str(len(any_stim_resp))+' units')\n",
    "fig.suptitle('context modulation of raw vs. evoked stimulus responses')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_raw_vs_evoked_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_raw_vs_evoked_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare baseline vs. stim context mod\n",
    "context_stim_mod_only=adj_pvals.query('(vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05) and context>=0.05')\n",
    "context_baseline_mod_only=adj_pvals.query('context<0.05 and vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05')\n",
    "context_stim_and_baseline_mod=adj_pvals.query('context<0.05 and (vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05)')\n",
    "no_mod=adj_pvals.query('context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['stimulus only','baseline only','both stimulus and baseline',\n",
    "        'neither']\n",
    "sizes=[len(context_stim_mod_only),len(context_baseline_mod_only),len(context_stim_and_baseline_mod),\n",
    "        len(no_mod)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'grey'])\n",
    "ax.set_title('n = '+str(len(sel_units))+' units')\n",
    "fig.suptitle('context modulation of stimulus vs. baseline')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_stim_vs_baseline_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_stim_vs_baseline_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#of baseline and stim context-modulated units,\n",
    "#how many both go up, down, or in different directions?\n",
    "\n",
    "context_stim_and_baseline_mod=adj_pvals.query('context<0.05 and (vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05)')\n",
    "stim_pos=context_stim_and_baseline_mod.query('(vis1_context_sign>0 or vis2_context_sign>0 or sound1_context_sign>0 or sound2_context_sign>0)')\n",
    "\n",
    "vis1_pos_baseline_pos=context_stim_and_baseline_mod.query('vis1_context_sign>0 and context_sign>0')\n",
    "vis1_pos_baseline_neg=context_stim_and_baseline_mod.query('vis1_context_sign>0 and context_sign<0')\n",
    "vis1_neg_baseline_pos=context_stim_and_baseline_mod.query('vis1_context_sign<0 and context_sign>0')\n",
    "vis1_neg_baseline_neg=context_stim_and_baseline_mod.query('vis1_context_sign<0 and context_sign<0')\n",
    "vis1_combo=context_stim_and_baseline_mod.query('vis1_context<0.05')\n",
    "\n",
    "vis2_pos_baseline_pos=context_stim_and_baseline_mod.query('vis2_context_sign>0 and context_sign>0')\n",
    "vis2_pos_baseline_neg=context_stim_and_baseline_mod.query('vis2_context_sign>0 and context_sign<0')\n",
    "vis2_neg_baseline_pos=context_stim_and_baseline_mod.query('vis2_context_sign<0 and context_sign>0')\n",
    "vis2_neg_baseline_neg=context_stim_and_baseline_mod.query('vis2_context_sign<0 and context_sign<0')\n",
    "vis2_combo=context_stim_and_baseline_mod.query('vis2_context<0.05')\n",
    "\n",
    "sound1_pos_baseline_pos=context_stim_and_baseline_mod.query('sound1_context_sign>0 and context_sign>0')\n",
    "sound1_pos_baseline_neg=context_stim_and_baseline_mod.query('sound1_context_sign>0 and context_sign<0')\n",
    "sound1_neg_baseline_pos=context_stim_and_baseline_mod.query('sound1_context_sign<0 and context_sign>0')\n",
    "sound1_neg_baseline_neg=context_stim_and_baseline_mod.query('sound1_context_sign<0 and context_sign<0')\n",
    "sound1_combo=context_stim_and_baseline_mod.query('sound1_context<0.05')\n",
    "\n",
    "sound2_pos_baseline_pos=context_stim_and_baseline_mod.query('sound2_context_sign>0 and context_sign>0')\n",
    "sound2_pos_baseline_neg=context_stim_and_baseline_mod.query('sound2_context_sign>0 and context_sign<0')\n",
    "sound2_neg_baseline_pos=context_stim_and_baseline_mod.query('sound2_context_sign<0 and context_sign>0')\n",
    "sound2_neg_baseline_neg=context_stim_and_baseline_mod.query('sound2_context_sign<0 and context_sign<0')\n",
    "sound2_combo=context_stim_and_baseline_mod.query('sound2_context<0.05')\n",
    "\n",
    "\n",
    "stim_pos_baseline_pos=pd.concat([vis1_pos_baseline_pos,vis2_pos_baseline_pos,sound1_pos_baseline_neg,sound2_pos_baseline_neg],axis=0)\n",
    "stim_pos_baseline_neg=pd.concat([vis1_pos_baseline_neg,vis2_pos_baseline_neg,sound1_pos_baseline_pos,sound2_pos_baseline_pos],axis=0)\n",
    "stim_neg_baseline_pos=pd.concat([vis1_neg_baseline_pos,vis2_neg_baseline_pos,sound1_neg_baseline_neg,sound2_neg_baseline_neg],axis=0)\n",
    "stim_neg_baseline_neg=pd.concat([vis1_neg_baseline_neg,vis2_neg_baseline_neg,sound1_neg_baseline_pos,sound2_neg_baseline_pos],axis=0)\n",
    "all_stim_combo=pd.concat([vis1_combo,vis2_combo,sound1_combo,sound2_combo],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis1\n",
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['vis1 up; baseline up','vis1 up, baseline down','vis1 down; baseline up','vis1 down; baseline down']\n",
    "sizes=[len(vis1_pos_baseline_pos),len(vis1_pos_baseline_neg),len(vis1_neg_baseline_pos),\n",
    "        len(vis1_neg_baseline_neg)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'tab:red'])\n",
    "ax.set_title('n = '+str(len(vis1_combo))+' units')\n",
    "fig.suptitle('sign of context modulation of vis target')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_vis1_vs_baseline_sign_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_vis1_vs_baseline_sign_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "        \n",
    "#vis2\n",
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['vis2 up; baseline up','vis2 up, baseline down','vis2 down; baseline up','vis2 down; baseline down']\n",
    "sizes=[len(vis2_pos_baseline_pos),len(vis1_pos_baseline_neg),len(vis1_neg_baseline_pos),\n",
    "        len(vis2_neg_baseline_neg)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'tab:red'])\n",
    "ax.set_title('n = '+str(len(vis2_combo))+' units')\n",
    "fig.suptitle('sign of context modulation of vis nontarget')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_vis2_vs_baseline_sign_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_vis2_vs_baseline_sign_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "        \n",
    "#sound1\n",
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['sound1 up; baseline up','sound1 up, baseline down','sound1 down; baseline up','sound1 down; baseline down']\n",
    "sizes=[len(sound1_pos_baseline_pos),len(sound1_pos_baseline_neg),len(sound1_neg_baseline_pos),\n",
    "        len(sound1_neg_baseline_neg)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'tab:red'])\n",
    "ax.set_title('n = '+str(len(sound1_combo))+' units')\n",
    "fig.suptitle('sign of context modulation of aud target')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_sound1_vs_baseline_sign_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_sound1_vs_baseline_sign_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "        \n",
    "#sound2\n",
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['sound2 up; baseline up','sound2 up, baseline down','sound2 down; baseline up','sound2 down; baseline down']\n",
    "sizes=[len(sound2_pos_baseline_pos),len(sound2_pos_baseline_neg),len(sound2_neg_baseline_pos),\n",
    "        len(sound2_neg_baseline_neg)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'tab:red'])\n",
    "ax.set_title('n = '+str(len(sound2_combo))+' units')\n",
    "fig.suptitle('sign of context modulation of aud nontarget')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_sound2_vs_baseline_sign_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_sound2_vs_baseline_sign_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "        \n",
    "\n",
    "#all stims combined\n",
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['stim up; same baseline up','stim up, same baseline down','stim down; same baseline up','stim down; same baseline down']\n",
    "sizes=[len(stim_pos_baseline_pos),len(stim_pos_baseline_neg),len(stim_neg_baseline_pos),\n",
    "        len(stim_neg_baseline_neg)]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "               'tab:red'])\n",
    "ax.set_title('n = '+str(len(all_stim_combo))+' units')\n",
    "fig.suptitle('sign of context modulation of stimulus and baseline')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_allstim_vs_baseline_sign_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_allstim_vs_baseline_sign_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context-modulated stim responses vs. not\n",
    "\n",
    "context_mod_any_stim_resp=adj_pvals.query('(vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05) and any_stim<0.05')\n",
    "non_context_mod_stim_resp=adj_pvals.query('vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "non_stim_mod=adj_pvals.query('any_stim>=0.05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw vs evoked context modulation of stimulus\n",
    "labels=['context modulated','context independent','not stim modulated']\n",
    "\n",
    "sizes=[len(context_mod_any_stim_resp),len(non_context_mod_stim_resp),len(non_stim_mod),]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "       colors=['tab:blue', 'tab:orange','grey'])\n",
    "\n",
    "ax.set_title('n = '+str(len(sel_units))+' units')\n",
    "fig.suptitle('context modulated vs. independent stimulus responses')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_stim_vs_not_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_stim_vs_not_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for units with context modulation of a given stim response, how does context modulate each other stim response?\n",
    "#not exclusive\n",
    "\n",
    "#vis1 up context mod units\n",
    "vis1_up_context_mod_units=adj_pvals.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "\n",
    "vis1_up_vis2_context_mod_units_up=vis1_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "vis1_up_vis2_context_mod_units_down=vis1_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "\n",
    "vis1_up_sound1_context_mod_units_up=vis1_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "vis1_up_sound1_context_mod_units_down=vis1_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "vis1_up_sound2_context_mod_units_up=vis1_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "vis1_up_sound2_context_mod_units_down=vis1_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n",
    "vis1_up_baseline_context_mod_units_up=vis1_up_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "vis1_up_baseline_context_mod_units_down=vis1_up_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "\n",
    "#vis1 down context mod units\n",
    "vis1_down_context_mod_units=adj_pvals.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "\n",
    "vis1_down_vis2_context_mod_units_up=vis1_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "vis1_down_vis2_context_mod_units_down=vis1_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "\n",
    "vis1_down_sound1_context_mod_units_up=vis1_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "vis1_down_sound1_context_mod_units_down=vis1_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "vis1_down_sound2_context_mod_units_up=vis1_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "vis1_down_sound2_context_mod_units_down=vis1_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n",
    "vis1_down_baseline_context_mod_units_up=vis1_down_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "vis1_down_baseline_context_mod_units_down=vis1_down_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "\n",
    "#vis2 up context mod units\n",
    "vis2_up_context_mod_units=adj_pvals.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "\n",
    "vis2_up_vis1_context_mod_units_up=vis2_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "vis2_up_vis1_context_mod_units_down=vis2_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "\n",
    "vis2_up_sound1_context_mod_units_up=vis2_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "vis2_up_sound1_context_mod_units_down=vis2_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "vis2_up_sound2_context_mod_units_up=vis2_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "vis2_up_sound2_context_mod_units_down=vis2_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n",
    "vis2_up_baseline_context_mod_units_up=vis2_up_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "vis2_up_baseline_context_mod_units_down=vis2_up_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "\n",
    "#vis2 down context mod units\n",
    "vis2_down_context_mod_units=adj_pvals.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "\n",
    "vis2_down_vis1_context_mod_units_up=vis2_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "vis2_down_vis1_context_mod_units_down=vis2_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "\n",
    "vis2_down_sound1_context_mod_units_up=vis2_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "vis2_down_sound1_context_mod_units_down=vis2_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "vis2_down_sound2_context_mod_units_up=vis2_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "vis2_down_sound2_context_mod_units_down=vis2_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n",
    "vis2_down_baseline_context_mod_units_up=vis2_down_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "vis2_down_baseline_context_mod_units_down=vis2_down_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "\n",
    "#sound1 up context mod units\n",
    "sound1_up_context_mod_units=adj_pvals.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "sound1_up_vis1_context_mod_units_up=sound1_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "sound1_up_vis1_context_mod_units_down=sound1_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "\n",
    "sound1_up_vis2_context_mod_units_up=sound1_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "sound1_up_vis2_context_mod_units_down=sound1_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "\n",
    "sound1_up_sound2_context_mod_units_up=sound1_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "sound1_up_sound2_context_mod_units_down=sound1_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "\n",
    "sound1_up_baseline_context_mod_units_up=sound1_up_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "sound1_up_baseline_context_mod_units_down=sound1_up_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "\n",
    "#sound1 down context mod units\n",
    "sound1_down_context_mod_units=adj_pvals.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "\n",
    "sound1_down_vis1_context_mod_units_up=sound1_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "sound1_down_vis1_context_mod_units_down=sound1_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "\n",
    "sound1_down_vis2_context_mod_units_up=sound1_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "sound1_down_vis2_context_mod_units_down=sound1_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "\n",
    "sound1_down_sound2_context_mod_units_up=sound1_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "sound1_down_sound2_context_mod_units_down=sound1_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "\n",
    "sound1_down_baseline_context_mod_units_up=sound1_down_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "sound1_down_baseline_context_mod_units_down=sound1_down_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "\n",
    "#sound2 up context mod units\n",
    "sound2_up_context_mod_units=adj_pvals.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n",
    "sound2_up_vis1_context_mod_units_up=sound2_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "sound2_up_vis1_context_mod_units_down=sound2_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "\n",
    "sound2_up_vis2_context_mod_units_up=sound2_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "sound2_up_vis2_context_mod_units_down=sound2_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "\n",
    "sound2_up_sound1_context_mod_units_up=sound2_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "sound2_up_sound1_context_mod_units_down=sound2_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "\n",
    "sound2_up_baseline_context_mod_units_up=sound2_up_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "sound2_up_baseline_context_mod_units_down=sound2_up_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "\n",
    "#sound2 down context mod units\n",
    "sound2_down_context_mod_units=adj_pvals.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "\n",
    "sound2_down_vis1_context_mod_units_up=sound2_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "sound2_down_vis1_context_mod_units_down=sound2_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "\n",
    "sound2_down_vis2_context_mod_units_up=sound2_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "sound2_down_vis2_context_mod_units_down=sound2_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "\n",
    "sound2_down_sound1_context_mod_units_up=sound2_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "sound2_down_sound1_context_mod_units_down=sound2_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "\n",
    "sound2_down_baseline_context_mod_units_up=sound2_down_context_mod_units.query('context_sign<0 and context<0.05')\n",
    "sound2_down_baseline_context_mod_units_down=sound2_down_context_mod_units.query('context_sign>0 and context<0.05')\n",
    "\n",
    "#baseline up context mod units\n",
    "baseline_up_context_mod_units=adj_pvals.query('context<0.05 and context_sign>0')\n",
    "\n",
    "baseline_up_vis1_context_mod_units_up=baseline_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "baseline_up_vis1_context_mod_units_down=baseline_up_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "\n",
    "baseline_up_vis2_context_mod_units_up=baseline_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "baseline_up_vis2_context_mod_units_down=baseline_up_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "\n",
    "baseline_up_sound1_context_mod_units_up=baseline_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "baseline_up_sound1_context_mod_units_down=baseline_up_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "baseline_up_sound2_context_mod_units_up=baseline_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "baseline_up_sound2_context_mod_units_down=baseline_up_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n",
    "#baseline down context mod units\n",
    "baseline_down_context_mod_units=adj_pvals.query('context<0.05 and context_sign<0')\n",
    "\n",
    "baseline_down_vis1_context_mod_units_up=baseline_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign>0')\n",
    "baseline_down_vis1_context_mod_units_down=baseline_down_context_mod_units.query('vis1_context<0.05 and vis1_context_sign<0')\n",
    "\n",
    "baseline_down_vis2_context_mod_units_up=baseline_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign>0')\n",
    "baseline_down_vis2_context_mod_units_down=baseline_down_context_mod_units.query('vis2_context<0.05 and vis2_context_sign<0')\n",
    "\n",
    "baseline_down_sound1_context_mod_units_up=baseline_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign<0')\n",
    "baseline_down_sound1_context_mod_units_down=baseline_down_context_mod_units.query('sound1_context<0.05 and sound1_context_sign>0')\n",
    "\n",
    "baseline_down_sound2_context_mod_units_up=baseline_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign<0')\n",
    "baseline_down_sound2_context_mod_units_down=baseline_down_context_mod_units.query('sound2_context<0.05 and sound2_context_sign>0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_pvals.query('vis1_context<0.05 and vis1_context_sign<0').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot intersection baseline and stim context mod\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(baseline_up_vis1_context_mod_units_up),len(baseline_up_vis1_context_mod_units_down),\n",
    "            len(baseline_up_context_mod_units)-len(baseline_up_vis1_context_mod_units_up)-len(baseline_up_vis1_context_mod_units_down),]\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(baseline_up_vis2_context_mod_units_up),len(baseline_up_vis2_context_mod_units_down),\n",
    "            len(baseline_up_context_mod_units)-len(baseline_up_vis2_context_mod_units_up)-len(baseline_up_vis2_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(baseline_up_sound1_context_mod_units_up),len(baseline_up_sound1_context_mod_units_down),\n",
    "                len(baseline_up_context_mod_units)-len(baseline_up_sound1_context_mod_units_up)-len(baseline_up_sound1_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(baseline_up_sound2_context_mod_units_up),len(baseline_up_sound2_context_mod_units_down),\n",
    "                len(baseline_up_context_mod_units)-len(baseline_up_sound2_context_mod_units_up)-len(baseline_up_sound2_context_mod_units_down),]\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('vis 2')\n",
    "\n",
    "ax[2].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 1')\n",
    "\n",
    "ax[3].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('sound 2')\n",
    "\n",
    "fig.suptitle('baseline context mod up units: context mod of other stimuli \\n n = '+str(len(baseline_up_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_baseline_up_vs_stim_up_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_baseline_up_vs_stim_up_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "#plot intersection baseline and stim context mod\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(baseline_down_vis1_context_mod_units_up),len(baseline_down_vis1_context_mod_units_down),\n",
    "            len(baseline_down_context_mod_units)-len(baseline_down_vis1_context_mod_units_up)-len(baseline_down_vis1_context_mod_units_down),]\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(baseline_down_vis2_context_mod_units_up),len(baseline_down_vis2_context_mod_units_down),\n",
    "            len(baseline_down_context_mod_units)-len(baseline_down_vis2_context_mod_units_up)-len(baseline_down_vis2_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(baseline_down_sound1_context_mod_units_up),len(baseline_down_sound1_context_mod_units_down),\n",
    "                len(baseline_down_context_mod_units)-len(baseline_down_sound1_context_mod_units_up)-len(baseline_down_sound1_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(baseline_down_sound2_context_mod_units_up),len(baseline_down_sound2_context_mod_units_down),\n",
    "                len(baseline_down_context_mod_units)-len(baseline_down_sound2_context_mod_units_up)-len(baseline_down_sound2_context_mod_units_down),]\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('vis 2')\n",
    "\n",
    "ax[2].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 1')\n",
    "\n",
    "ax[3].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('sound 2')\n",
    "\n",
    "fig.suptitle('baseline context mod down units: context mod of other stimuli \\n n = '+str(len(baseline_down_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_baseline_down_vs_stim_down_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_baseline_down_vs_stim_down_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "        \n",
    "\n",
    "#plot intersection of vis1 and context modulation of other stimuli\n",
    "\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(vis1_up_vis2_context_mod_units_up),len(vis1_up_vis2_context_mod_units_down),\n",
    "            len(vis1_up_context_mod_units)-len(vis1_up_vis2_context_mod_units_up)-len(vis1_up_vis2_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(vis1_up_sound1_context_mod_units_up),len(vis1_up_sound1_context_mod_units_down),\n",
    "              len(vis1_up_context_mod_units)-len(vis1_up_sound1_context_mod_units_up)-len(vis1_up_sound1_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(vis1_up_sound2_context_mod_units_up),len(vis1_up_sound2_context_mod_units_down),\n",
    "              len(vis1_up_context_mod_units)-len(vis1_up_sound2_context_mod_units_up)-len(vis1_up_sound2_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(vis1_up_baseline_context_mod_units_up),len(vis1_up_baseline_context_mod_units_down),\n",
    "                len(vis1_up_context_mod_units)-len(vis1_up_baseline_context_mod_units_up)-len(vis1_up_baseline_context_mod_units_down),]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 2')\n",
    "\n",
    "ax[1].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('sound 1')\n",
    "\n",
    "ax[2].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 2')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('vis1 context mod up units: context mod of other stimuli \\n n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_vis1_up_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_vis1_up_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "        \n",
    "\n",
    "#plot intersection of vis1 down and context modulation of other stimuli\n",
    "\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(vis1_down_vis2_context_mod_units_up),len(vis1_down_vis2_context_mod_units_down),\n",
    "            len(vis1_down_context_mod_units)-len(vis1_down_vis2_context_mod_units_up)-len(vis1_down_vis2_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(vis1_down_sound1_context_mod_units_up),len(vis1_down_sound1_context_mod_units_down),\n",
    "              len(vis1_down_context_mod_units)-len(vis1_down_sound1_context_mod_units_up)-len(vis1_down_sound1_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(vis1_down_sound2_context_mod_units_up),len(vis1_down_sound2_context_mod_units_down),\n",
    "              len(vis1_down_context_mod_units)-len(vis1_down_sound2_context_mod_units_up)-len(vis1_down_sound2_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(vis1_down_baseline_context_mod_units_up),len(vis1_down_baseline_context_mod_units_down),\n",
    "                len(vis1_down_context_mod_units)-len(vis1_down_baseline_context_mod_units_up)-len(vis1_down_baseline_context_mod_units_down),]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 2')\n",
    "\n",
    "ax[1].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('sound 1')\n",
    "\n",
    "ax[2].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 2')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('vis1 context mod down units: context mod of other stimuli \\n n = '+str(len(vis1_down_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_vis1_down_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_vis1_down_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "\n",
    "#plot intersection of vis2 up and context modulation of other stimuli\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(vis2_up_vis1_context_mod_units_up),len(vis2_up_vis1_context_mod_units_down),\n",
    "            len(vis2_up_context_mod_units)-len(vis2_up_vis1_context_mod_units_up)-len(vis2_up_vis1_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(vis2_up_sound1_context_mod_units_up),len(vis2_up_sound1_context_mod_units_down),\n",
    "              len(vis2_up_context_mod_units)-len(vis2_up_sound1_context_mod_units_up)-len(vis2_up_sound1_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(vis2_up_sound2_context_mod_units_up),len(vis2_up_sound2_context_mod_units_down),\n",
    "              len(vis2_up_context_mod_units)-len(vis2_up_sound2_context_mod_units_up)-len(vis2_up_sound2_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(vis2_up_baseline_context_mod_units_up),len(vis2_up_baseline_context_mod_units_down),\n",
    "                len(vis2_up_context_mod_units)-len(vis2_up_baseline_context_mod_units_up)-len(vis2_up_baseline_context_mod_units_down),]\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('sound 1')\n",
    "\n",
    "ax[2].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 2')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('vis2 context mod up units: context mod of other stimuli \\n n = '+str(len(vis2_up_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_vis2_up_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_vis2_up_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "#plot intersection of vis2 down and context modulation of other stimuli\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(vis2_down_vis1_context_mod_units_up),len(vis2_down_vis1_context_mod_units_down),\n",
    "            len(vis2_down_context_mod_units)-len(vis2_down_vis1_context_mod_units_up)-len(vis2_down_vis1_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(vis2_down_sound1_context_mod_units_up),len(vis2_down_sound1_context_mod_units_down),\n",
    "              len(vis2_down_context_mod_units)-len(vis2_down_sound1_context_mod_units_up)-len(vis2_down_sound1_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(vis2_down_sound2_context_mod_units_up),len(vis2_down_sound2_context_mod_units_down),\n",
    "              len(vis2_down_context_mod_units)-len(vis2_down_sound2_context_mod_units_up)-len(vis2_down_sound2_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(vis2_down_baseline_context_mod_units_up),len(vis2_down_baseline_context_mod_units_down),\n",
    "                len(vis2_down_context_mod_units)-len(vis2_down_baseline_context_mod_units_up)-len(vis2_down_baseline_context_mod_units_down),]\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('sound 1')\n",
    "\n",
    "ax[2].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 2')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('vis2 context mod down units: context mod of other stimuli \\n n = '+str(len(vis2_down_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_vis2_down_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_vis2_down_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "#plot intersection of sound1 up and context modulation of other stimuli\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(sound1_up_vis1_context_mod_units_up),len(sound1_up_vis1_context_mod_units_down),\n",
    "            len(sound1_up_context_mod_units)-len(sound1_up_vis1_context_mod_units_up)-len(sound1_up_vis1_context_mod_units_down),]\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(sound1_up_vis2_context_mod_units_up),len(sound1_up_vis2_context_mod_units_down),\n",
    "            len(sound1_up_context_mod_units)-len(sound1_up_vis2_context_mod_units_up)-len(sound1_up_vis2_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(sound1_up_sound2_context_mod_units_up),len(sound1_up_sound2_context_mod_units_down),\n",
    "              len(sound1_up_context_mod_units)-len(sound1_up_sound2_context_mod_units_up)-len(sound1_up_sound2_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(sound1_up_baseline_context_mod_units_up),len(sound1_up_baseline_context_mod_units_down),\n",
    "                len(sound1_up_context_mod_units)-len(sound1_up_baseline_context_mod_units_up)-len(sound1_up_baseline_context_mod_units_down),]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('vis 2')\n",
    "\n",
    "ax[2].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 2')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('sound1 context mod up units: context mod of other stimuli \\n n = '+str(len(sound1_up_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_sound1_up_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_sound1_up_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "#plot intersection of sound1 down and context modulation of other stimuli\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(sound1_down_vis1_context_mod_units_up),len(sound1_down_vis1_context_mod_units_down),\n",
    "            len(sound1_down_context_mod_units)-len(sound1_down_vis1_context_mod_units_up)-len(sound1_down_vis1_context_mod_units_down),]\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(sound1_down_vis2_context_mod_units_up),len(sound1_down_vis2_context_mod_units_down),\n",
    "            len(sound1_down_context_mod_units)-len(sound1_down_vis2_context_mod_units_up)-len(sound1_down_vis2_context_mod_units_down),]\n",
    "#sound2\n",
    "sound2_labels=['sound2 up','sound2 down','no change']\n",
    "sound2_sizes=[len(sound1_down_sound2_context_mod_units_up),len(sound1_down_sound2_context_mod_units_down),\n",
    "              len(sound1_down_context_mod_units)-len(sound1_down_sound2_context_mod_units_up)-len(sound1_down_sound2_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(sound1_down_baseline_context_mod_units_up),len(sound1_down_baseline_context_mod_units_down),\n",
    "                len(sound1_down_context_mod_units)-len(sound1_down_baseline_context_mod_units_up)-len(sound1_down_baseline_context_mod_units_down),]\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('vis 2')\n",
    "\n",
    "ax[2].pie(sound2_sizes,labels=sound2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 2')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('sound1 context mod down units: context mod of other stimuli \\n n = '+str(len(sound1_down_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_sound1_down_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_sound1_down_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "#plot intersection of sound2 up and context modulation of other stimuli\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(sound2_up_vis1_context_mod_units_up),len(sound2_up_vis1_context_mod_units_down),\n",
    "            len(sound2_up_context_mod_units)-len(sound2_up_vis1_context_mod_units_up)-len(sound2_up_vis1_context_mod_units_down),]\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(sound2_up_vis2_context_mod_units_up),len(sound2_up_vis2_context_mod_units_down),\n",
    "            len(sound2_up_context_mod_units)-len(sound2_up_vis2_context_mod_units_up)-len(sound2_up_vis2_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(sound2_up_sound1_context_mod_units_up),len(sound2_up_sound1_context_mod_units_down),\n",
    "              len(sound2_up_context_mod_units)-len(sound2_up_sound1_context_mod_units_up)-len(sound2_up_sound1_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(sound2_up_baseline_context_mod_units_up),len(sound2_up_baseline_context_mod_units_down),\n",
    "                len(sound2_up_context_mod_units)-len(sound2_up_baseline_context_mod_units_up)-len(sound2_up_baseline_context_mod_units_down),]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('vis 2')\n",
    "\n",
    "ax[2].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 1')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('sound2 context mod up units: context mod of other stimuli \\n n = '+str(len(sound2_up_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_sound2_up_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_sound2_up_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "\n",
    "#plot intersection of sound2 down and context modulation of other stimuli\n",
    "\n",
    "#vis1\n",
    "vis1_labels=['vis1 up','vis1 down','no change']\n",
    "vis1_sizes=[len(sound2_down_vis1_context_mod_units_up),len(sound2_down_vis1_context_mod_units_down),\n",
    "            len(sound2_down_context_mod_units)-len(sound2_down_vis1_context_mod_units_up)-len(sound2_down_vis1_context_mod_units_down),]\n",
    "#vis2\n",
    "vis2_labels=['vis2 up','vis2 down','no change']\n",
    "vis2_sizes=[len(sound2_down_vis2_context_mod_units_up),len(sound2_down_vis2_context_mod_units_down),\n",
    "            len(sound2_down_context_mod_units)-len(sound2_down_vis2_context_mod_units_up)-len(sound2_down_vis2_context_mod_units_down),]\n",
    "#sound1\n",
    "sound1_labels=['sound1 up','sound1 down','no change']\n",
    "sound1_sizes=[len(sound2_down_sound1_context_mod_units_up),len(sound2_down_sound1_context_mod_units_down),\n",
    "              len(sound2_down_context_mod_units)-len(sound2_down_sound1_context_mod_units_up)-len(sound2_down_sound1_context_mod_units_down),]\n",
    "#baseline\n",
    "baseline_labels=['baseline up','baseline down','no change']\n",
    "baseline_sizes=[len(sound2_down_baseline_context_mod_units_up),len(sound2_down_baseline_context_mod_units_down),\n",
    "                len(sound2_down_context_mod_units)-len(sound2_down_baseline_context_mod_units_up)-len(sound2_down_baseline_context_mod_units_down),]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,4))\n",
    "ax[0].pie(vis1_sizes,labels=vis1_labels,autopct='%1.1f%%',\n",
    "          colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[0].set_title('vis 1')\n",
    "\n",
    "ax[1].pie(vis2_sizes,labels=vis2_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[1].set_title('vis 2')\n",
    "\n",
    "ax[2].pie(sound1_sizes,labels=sound1_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[2].set_title('sound 1')\n",
    "\n",
    "ax[3].pie(baseline_sizes,labels=baseline_labels,autopct='%1.1f%%',\n",
    "            colors=['tab:blue', 'tab:orange','grey'])\n",
    "ax[3].set_title('baseline')\n",
    "\n",
    "# ax.set_title('n = '+str(len(vis1_up_context_mod_units))+' units')\n",
    "fig.suptitle('sound2 context mod down units: context mod of other stimuli \\n n = '+str(len(sound2_down_context_mod_units))+' units')\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\",\"context_mod_sound2_down_vs_other_stim_Templeton.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "else:\n",
    "        fig.savefig(\n",
    "                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\",\"context_mod_sound2_down_vs_other_stim_DR.png\"),\n",
    "                dpi=300, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units that have vis1 positive and sound1 negative context modulation, and vice versa\n",
    "# where are they??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_units=evoked_context_stim_mod_only['unit_id'].values\n",
    "all_data.query('unit_id in @sel_units and structure==\"MOs\"')['unit_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimulus responsiveness by area\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_responsive_to_stim={\n",
    "        'area':[],\n",
    "        'vis1':[],\n",
    "        'vis2':[],\n",
    "        'sound1':[],\n",
    "        'sound2':[],\n",
    "        'both_vis':[],\n",
    "        'both_sound':[],\n",
    "        'mixed':[],\n",
    "        'none':[],\n",
    "        'vis1_pos':[],\n",
    "        'vis2_pos':[],\n",
    "        'sound1_pos':[],\n",
    "        'sound2_pos':[],\n",
    "        'both_vis_pos':[],\n",
    "        'both_sound_pos':[],\n",
    "        'mixed_pos':[],\n",
    "        'vis1_neg':[],\n",
    "        'vis2_neg':[],\n",
    "        'sound1_neg':[],\n",
    "        'sound2_neg':[],\n",
    "        'both_vis_neg':[],\n",
    "        'both_sound_neg':[],\n",
    "        'mixed_neg':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "        'n_sessions_w_20_units':[],\n",
    "        'n_sessions_w_15_units':[],\n",
    "        'n_sessions_w_10_units':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        for n_units in [20,15,10]:\n",
    "                n_sessions_w_units=sel_units.groupby('session_id').filter(lambda x: len(x)>=n_units)['session_id'].unique()\n",
    "                area_number_responsive_to_stim['n_sessions_w_'+str(n_units)+'_units'].append(len(n_sessions_w_units))\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_sign':sel_units['vis1_stimulus_modulation_sign'],\n",
    "        'vis2_sign':sel_units['vis2_stimulus_modulation_sign'],\n",
    "        'sound1_sign':sel_units['sound1_stimulus_modulation_sign'],\n",
    "        'sound2_sign':sel_units['sound2_stimulus_modulation_sign'],\n",
    "        })\n",
    "\n",
    "        #stimulus modulation across all units\n",
    "        #each stim only\n",
    "        vis1_stim_resp=adj_pvals.query('vis1<0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        vis2_stim_resp=adj_pvals.query('vis2<0.05 and vis1>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        sound1_stim_resp=adj_pvals.query('sound1<0.05 and sound2>=0.05 and vis1>=0.05 and vis2>=0.05')\n",
    "        sound2_stim_resp=adj_pvals.query('sound2<0.05 and sound1>=0.05 and vis1>=0.05 and vis2>=0.05')\n",
    "\n",
    "        #both vis\n",
    "        both_vis_stim_resp=adj_pvals.query('vis1<0.05 and vis2<0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #both aud\n",
    "        both_sound_stim_resp=adj_pvals.query('sound1<0.05 and sound2<0.05 and vis1>=0.05 and vis2>=0.05')\n",
    "\n",
    "        #at least one vis and one aud\n",
    "        mixed_stim_resp=adj_pvals.query('((vis1<0.05 or vis2<0.05) and (sound1<0.05 and sound2<0.05))')\n",
    "\n",
    "        #none\n",
    "        no_stim_resp=adj_pvals.query('vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "\n",
    "        area_number_responsive_to_stim['area'].append(sel_area)\n",
    "        area_number_responsive_to_stim['vis1'].append(len(vis1_stim_resp))\n",
    "        area_number_responsive_to_stim['vis2'].append(len(vis2_stim_resp))\n",
    "        area_number_responsive_to_stim['sound1'].append(len(sound1_stim_resp))\n",
    "        area_number_responsive_to_stim['sound2'].append(len(sound2_stim_resp))\n",
    "        area_number_responsive_to_stim['both_vis'].append(len(both_vis_stim_resp))\n",
    "        area_number_responsive_to_stim['both_sound'].append(len(both_sound_stim_resp))\n",
    "        area_number_responsive_to_stim['mixed'].append(len(mixed_stim_resp))\n",
    "        area_number_responsive_to_stim['none'].append(len(no_stim_resp))\n",
    "        area_number_responsive_to_stim['total_n'].append(len(sel_units))\n",
    "        area_number_responsive_to_stim['n_sessions'].append(n_sessions)\n",
    "\n",
    "        #positive vs. negative modulation\n",
    "        #positive modulation\n",
    "        vis1_pos_stim_resp=adj_pvals.query('vis1<0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and vis1_sign>0')\n",
    "        vis2_pos_stim_resp=adj_pvals.query('vis2<0.05 and vis1>=0.05 and sound1>=0.05 and sound2>=0.05 and vis2_sign>0')\n",
    "        sound1_pos_stim_resp=adj_pvals.query('sound1<0.05 and sound2>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1_sign>0')\n",
    "        sound2_pos_stim_resp=adj_pvals.query('sound2<0.05 and sound1>=0.05 and vis1>=0.05 and vis2>=0.05 and sound2_sign>0')\n",
    "\n",
    "        #both vis\n",
    "        both_vis_pos_stim_resp=adj_pvals.query('vis1<0.05 and vis2<0.05 and sound1>=0.05 and sound2>=0.05 and vis1_sign>0 and vis2_sign>0')\n",
    "        #both aud\n",
    "        both_sound_pos_stim_resp=adj_pvals.query('sound1<0.05 and sound2<0.05 and vis1>=0.05 and vis2>=0.05 and sound1_sign>0 and sound2_sign>0')\n",
    "\n",
    "        #at least one vis and one aud\n",
    "        mixed_pos_stim_resp=adj_pvals.query('(((vis1<0.05 and vis1_sign>0) or (vis2<0.05 and vis2_sign>0)) and ((sound1<0.05 and sound1_sign>0) and (sound2<0.05 and sound2_sign>0)))')\n",
    "\n",
    "        #negative modulation\n",
    "        vis1_neg_stim_resp=adj_pvals.query('vis1<0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and vis1_sign<0')\n",
    "        vis2_neg_stim_resp=adj_pvals.query('vis2<0.05 and vis1>=0.05 and sound1>=0.05 and sound2>=0.05 and vis2_sign<0')\n",
    "        sound1_neg_stim_resp=adj_pvals.query('sound1<0.05 and sound2>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1_sign<0')\n",
    "        sound2_neg_stim_resp=adj_pvals.query('sound2<0.05 and sound1>=0.05 and vis1>=0.05 and vis2>=0.05 and sound2_sign<0')\n",
    "\n",
    "        #both vis\n",
    "        both_vis_neg_stim_resp=adj_pvals.query('vis1<0.05 and vis2<0.05 and sound1>=0.05 and sound2>=0.05 and vis1_sign<0 and vis2_sign<0')\n",
    "        #both aud\n",
    "        both_sound_neg_stim_resp=adj_pvals.query('sound1<0.05 and sound2<0.05 and vis1>=0.05 and vis2>=0.05 and sound1_sign<0 and sound2_sign<0')\n",
    "\n",
    "        #at least one vis and one aud\n",
    "        mixed_neg_stim_resp=adj_pvals.query('(((vis1<0.05 and vis1_sign<0) or (vis2<0.05 and vis2_sign<0)) and ((sound1<0.05 and sound1_sign<0) and (sound2<0.05 and sound2_sign<0)))')\n",
    "\n",
    "        area_number_responsive_to_stim['vis1_pos'].append(len(vis1_pos_stim_resp))\n",
    "        area_number_responsive_to_stim['vis2_pos'].append(len(vis2_pos_stim_resp))\n",
    "        area_number_responsive_to_stim['sound1_pos'].append(len(sound1_pos_stim_resp))\n",
    "        area_number_responsive_to_stim['sound2_pos'].append(len(sound2_pos_stim_resp))\n",
    "        area_number_responsive_to_stim['both_vis_pos'].append(len(both_vis_pos_stim_resp))\n",
    "        area_number_responsive_to_stim['both_sound_pos'].append(len(both_sound_pos_stim_resp))\n",
    "        area_number_responsive_to_stim['mixed_pos'].append(len(mixed_pos_stim_resp))\n",
    "\n",
    "        area_number_responsive_to_stim['vis1_neg'].append(len(vis1_neg_stim_resp))\n",
    "        area_number_responsive_to_stim['vis2_neg'].append(len(vis2_neg_stim_resp))\n",
    "        area_number_responsive_to_stim['sound1_neg'].append(len(sound1_neg_stim_resp))\n",
    "        area_number_responsive_to_stim['sound2_neg'].append(len(sound2_neg_stim_resp))\n",
    "        area_number_responsive_to_stim['both_vis_neg'].append(len(both_vis_neg_stim_resp))\n",
    "        area_number_responsive_to_stim['both_sound_neg'].append(len(both_sound_neg_stim_resp))\n",
    "        area_number_responsive_to_stim['mixed_neg'].append(len(mixed_neg_stim_resp))\n",
    "\n",
    "\n",
    "        labels=['vis1 only','vis2 only','both vis',\n",
    "                'sound1 only','sound2 only','both sound',\n",
    "                'mixed','none']\n",
    "        \n",
    "        sizes=[len(vis1_stim_resp),len(vis2_stim_resp),len(both_vis_stim_resp),\n",
    "                len(sound1_stim_resp),len(sound2_stim_resp),len(both_sound_stim_resp),\n",
    "                len(mixed_stim_resp),len(no_stim_resp)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%')\n",
    "                ax.set_title('area='+sel_area+'; n_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('stimulus responsive units')\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                if 'Templeton' in sel_project:\n",
    "                      fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\stimulus responsiveness\",sel_area.replace('/','')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\stimulus responsiveness\",sel_area.replace('/','')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_responsive_to_stim=pd.DataFrame(area_number_responsive_to_stim)\n",
    "\n",
    "area_fraction_responsive_to_stim=area_number_responsive_to_stim.copy()\n",
    "# total_n={\n",
    "#     'area':[],\n",
    "#     'total_n':[],\n",
    "# }\n",
    "# for rr,row in area_fraction_responsive_to_stim.iterrows():\n",
    "#     total_n['area'].append(row['area'])\n",
    "#     total_n['total_n'].append(row[1:].sum())\n",
    "#     if row[1:].sum()>0:\n",
    "#         area_fraction_responsive_to_stim.iloc[rr,1:]=row[1:]/row[1:].sum()\n",
    "\n",
    "# area_fraction_responsive_to_stim=pd.merge(area_fraction_responsive_to_stim,pd.DataFrame(total_n),on='area')\n",
    "\n",
    "\n",
    "for rr,row in area_fraction_responsive_to_stim.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_responsive_to_stim.iloc[rr,1:-5]=row.iloc[1:-5]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_responsive_to_stim.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\area_fraction_responsive_to_stim.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_responsive_to_stim.to_csv(\n",
    "        r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_responsive_to_stim.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # context modulation vs. stimulus modulation\n",
    "\n",
    "# area_number_context_mod={\n",
    "#         'area':[],\n",
    "#         'any_stim':[],\n",
    "#         'context':[],\n",
    "#         'stim_and_context':[],\n",
    "#         'neither':[],\n",
    "# }\n",
    "\n",
    "# for sel_area in all_data['structure'].unique():\n",
    "\n",
    "#         sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "#                                 isi_violations_ratio<=0.1 and \\\n",
    "#                                 amplitude_cutoff<=0.1 and \\\n",
    "#                                 project.str.contains(\"DynamicRouting\") and \\\n",
    "#                                 structure.str.contains(@sel_area)')\n",
    "\n",
    "#         adj_pvals=pd.DataFrame({\n",
    "#         'unit_id':sel_units['unit_id'],\n",
    "#         'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "#         'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "#         'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "#         'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "#         'context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "#         })\n",
    "\n",
    "#         #stimulus modulation only\n",
    "#         any_stim_resp=adj_pvals.query('vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05 and context>=0.05')\n",
    "\n",
    "#         #context modulation only\n",
    "#         context_resp=adj_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "\n",
    "#         #stim and context modulation\n",
    "#         stim_and_context_resp=adj_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "\n",
    "#         neither_stim_nor_context_resp=adj_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')  \n",
    "\n",
    "#         area_number_context_mod['area'].append(sel_area)\n",
    "#         area_number_context_mod_mag['any_stim'].append(len(any_stim_resp))\n",
    "#         area_number_context_mod['context'].append(len(context_resp))\n",
    "#         area_number_context_mod['stim_and_context'].append(len(stim_and_context_resp))\n",
    "#         area_number_context_mod['neither'].append(len(neither_stim_nor_context_resp))\n",
    "\n",
    "#         labels=['stimulus only','stimulus and context','context only','neither']\n",
    "#         sizes=[len(any_stim_resp),len(stim_and_context_resp),len(context_resp),\n",
    "#                 len(neither_stim_nor_context_resp)]\n",
    "        \n",
    "#         if np.sum(sizes)>0:\n",
    "#                 fig,ax=plt.subplots()\n",
    "#                 ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "#                         colors=['tab:blue', 'tab:orange', 'tab:green', 'grey'])\n",
    "#                 ax.set_title('area='+sel_area+'; n='+str(len(sel_units))+' units')\n",
    "\n",
    "#                 fig.tight_layout()\n",
    "\n",
    "#                 fig.savefig(\n",
    "#                         os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\plots\\context_modulation_vs_stim_resp\",sel_area+\"_DR.png\"),\n",
    "#                         dpi=300, facecolor='w', edgecolor='w',\n",
    "#                         orientation='portrait', format='png',\n",
    "#                         transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "#                         metadata=None)\n",
    "\n",
    "#                 plt.close()\n",
    "\n",
    "# area_number_context_mod=pd.DataFrame(area_number_context_mod)\n",
    "\n",
    "# area_fraction_context_mod=area_number_context_mod.copy()\n",
    "# total_n={\n",
    "#     'area':[],\n",
    "#     'total_n':[],\n",
    "# }\n",
    "# for rr,row in area_fraction_context_mod.iterrows():\n",
    "#     total_n['area'].append(row['area'])\n",
    "#     total_n['total_n'].append(row[1:].sum())\n",
    "#     if row[1:].sum()>0:\n",
    "#         area_fraction_context_mod.iloc[rr,1:]=row[1:]/row[1:].sum()\n",
    "\n",
    "# area_fraction_context_mod=pd.merge(area_fraction_context_mod,pd.DataFrame(total_n),on='area')\n",
    "\n",
    "# area_fraction_context_mod.to_csv(\n",
    "#     r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\area_fraction_context_mod.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context modulation vs. stimulus modulation vs. lick modulation\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_context_mod={\n",
    "        'area':[],\n",
    "        'any_stim':[],\n",
    "        'only_stim':[],\n",
    "        'any_context':[],\n",
    "        'only_context':[],\n",
    "        'any_context_linear_shift':[],\n",
    "        'only_context_linear_shift':[],\n",
    "        'any_lick':[],\n",
    "        'only_lick':[],\n",
    "        'stim_and_context':[],\n",
    "        'lick_and_stim':[],\n",
    "        'lick_and_context':[],\n",
    "        'lick_and_stim_and_context':[],\n",
    "        'none':[],\n",
    "        'any_context_pos':[],\n",
    "        'any_context_neg':[],\n",
    "        'any_lick_pos':[],\n",
    "        'any_lick_neg':[],\n",
    "        'any_stim_pos':[],\n",
    "        'any_stim_neg':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "        'n_sessions_w_20_units':[],\n",
    "        'n_sessions_w_15_units':[],\n",
    "        'n_sessions_w_10_units':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "        \n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        for n_units in [20,15,10]:\n",
    "                n_sessions_w_units=sel_units.groupby('session_id').filter(lambda x: len(x)>=n_units)['session_id'].unique()\n",
    "                area_number_context_mod['n_sessions_w_'+str(n_units)+'_units'].append(len(n_sessions_w_units))\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "        'lick':fdrcorrection(sel_units['lick_modulation_p_value'])[1],\n",
    "        'vis1_sign':sel_units['vis1_stimulus_modulation_sign'],\n",
    "        'vis2_sign':sel_units['vis2_stimulus_modulation_sign'],\n",
    "        'sound1_sign':sel_units['sound1_stimulus_modulation_sign'],\n",
    "        'sound2_sign':sel_units['sound2_stimulus_modulation_sign'],\n",
    "        'context_sign':sel_units['baseline_context_modulation_sign'],\n",
    "        'lick_sign':sel_units['lick_modulation_sign'],\n",
    "        'context_linear_shift':sel_units[['linear_shift_baseline_context_p_value_higher',\n",
    "                                        'linear_shift_baseline_context_p_value_lower']].min(axis=1),\n",
    "        })\n",
    "\n",
    "        #lick modulation only\n",
    "        only_lick_resp=adj_pvals.query('lick<0.05 and context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #any lick modulation\n",
    "        any_lick_resp=adj_pvals.query('lick<0.05')\n",
    "        #lick and context\n",
    "        lick_and_context_resp=adj_pvals.query('context<0.05 and lick<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #lick and stimulus\n",
    "        lick_and_stim_resp=adj_pvals.query('lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05')\n",
    "        #all three\n",
    "        all_resp=adj_pvals.query('context<0.05 and lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "        \n",
    "        #stimulus modulation only\n",
    "        only_stim_resp=adj_pvals.query('(vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05 and lick>=0.05')\n",
    "        #any stim modulation\n",
    "        any_stim_resp=adj_pvals.query('vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05')\n",
    "       \n",
    "        #context modulation only\n",
    "        only_context_resp=adj_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "        #any context modulation\n",
    "        any_context_resp=adj_pvals.query('context<0.05')\n",
    "\n",
    "        #linear-shifted conext modulation\n",
    "        only_context_linear_shift_resp=adj_pvals.query('context_linear_shift<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "        #any context modulation\n",
    "        any_context_linear_shift_resp=adj_pvals.query('context_linear_shift<0.05')\n",
    "\n",
    "        #stim and context modulation\n",
    "        stim_and_context_resp=adj_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and lick>=0.05')\n",
    "        #none\n",
    "        no_resp=adj_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "        \n",
    "        #pos vs. neg modulation\n",
    "        #context\n",
    "        any_context_pos=adj_pvals.query('context<0.05 and context_sign>0')\n",
    "        any_context_neg=adj_pvals.query('context<0.05 and context_sign<0')\n",
    "        #lick\n",
    "        any_lick_pos=adj_pvals.query('lick<0.05 and lick_sign>0')\n",
    "        any_lick_neg=adj_pvals.query('lick<0.05 and lick_sign<0')\n",
    "        #stim\n",
    "        any_stim_pos=adj_pvals.query('(vis1<0.05 and vis1_sign>0) or (vis2<0.05 and vis2_sign>0) or (sound1<0.05 and sound1_sign>0) or (sound2<0.05 and sound2_sign>0)')\n",
    "        any_stim_neg=adj_pvals.query('(vis1<0.05 and vis1_sign<0) or (vis2<0.05 and vis2_sign<0) or (sound1<0.05 and sound1_sign<0) or (sound2<0.05 and sound2_sign<0)')\n",
    "\n",
    "        area_number_context_mod['area'].append(sel_area)\n",
    "        area_number_context_mod['only_stim'].append(len(only_stim_resp))\n",
    "        area_number_context_mod['any_stim'].append(len(any_stim_resp))\n",
    "        area_number_context_mod['only_context'].append(len(only_context_resp))\n",
    "        area_number_context_mod['any_context'].append(len(any_context_resp))\n",
    "        area_number_context_mod['any_context_linear_shift'].append(len(any_context_linear_shift_resp))\n",
    "        area_number_context_mod['only_context_linear_shift'].append(len(only_context_linear_shift_resp))\n",
    "        area_number_context_mod['only_lick'].append(len(only_lick_resp))\n",
    "        area_number_context_mod['any_lick'].append(len(any_lick_resp))\n",
    "        area_number_context_mod['stim_and_context'].append(len(stim_and_context_resp))\n",
    "        area_number_context_mod['lick_and_stim'].append(len(lick_and_stim_resp))\n",
    "        area_number_context_mod['lick_and_context'].append(len(lick_and_context_resp))\n",
    "        area_number_context_mod['lick_and_stim_and_context'].append(len(all_resp))\n",
    "        area_number_context_mod['none'].append(len(no_resp))\n",
    "        area_number_context_mod['total_n'].append(len(sel_units))\n",
    "        area_number_context_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "        area_number_context_mod['any_context_pos'].append(len(any_context_pos))\n",
    "        area_number_context_mod['any_context_neg'].append(len(any_context_neg))\n",
    "        area_number_context_mod['any_lick_pos'].append(len(any_lick_pos))\n",
    "        area_number_context_mod['any_lick_neg'].append(len(any_lick_neg))\n",
    "        area_number_context_mod['any_stim_pos'].append(len(any_stim_pos))\n",
    "        area_number_context_mod['any_stim_neg'].append(len(any_stim_neg))\n",
    "\n",
    "        # labels=['stimulus only','stimulus and context','context only','neither']\n",
    "        # sizes=[len(any_stim_resp),len(stim_and_context_resp),len(context_resp),\n",
    "        #         len(neither_stim_nor_context_resp)]\n",
    "        \n",
    "        labels=['stimulus only','stimulus and context','context only',\n",
    "                'context and lick','lick only', 'lick & stimulus & context',\n",
    "                'lick and stimulus',  'none']\n",
    "        sizes=[len(only_stim_resp),len(stim_and_context_resp),len(only_context_resp),\n",
    "                len(lick_and_context_resp),len(only_lick_resp),len(all_resp),\n",
    "                len(lick_and_stim_resp), len(no_resp)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "                        'tab:red' , 'tab:purple', 'tab:brown', \n",
    "                        'tab:pink', 'grey'])\n",
    "                ax.set_title('area='+sel_area+'; n_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "\n",
    "                fig.tight_layout()\n",
    "\n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\context_lick_stim_resp\",sel_area.replace('/','')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\context_lick_stim_resp\",sel_area.replace('/','')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_mod=pd.DataFrame(area_number_context_mod)\n",
    "\n",
    "area_fraction_context_mod=area_number_context_mod.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_mod.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_context_mod.iloc[rr,1:-5]=row.iloc[1:-5]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_lick_mod.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_stim_lick_mod.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAGNITUDE!\n",
    "# context modulation vs. stimulus modulation vs. lick modulation\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_context_mod={\n",
    "        'area':[],\n",
    "        'stim_mag':[],\n",
    "        'context_mag':[],\n",
    "        'context_linear_shift_mag':[],\n",
    "        'lick_mag':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "        \n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        magnitudes=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':sel_units['vis1_stimulus_modulation_zscore'],\n",
    "        'vis2':sel_units['vis2_stimulus_modulation_zscore'],\n",
    "        'sound1':sel_units['sound1_stimulus_modulation_zscore'],\n",
    "        'sound2':sel_units['sound2_stimulus_modulation_zscore'],\n",
    "        'context':sel_units['baseline_context_modulation_zscore'],\n",
    "        'lick':sel_units['lick_modulation_zscore'],\n",
    "        'context_linear_shift_mag':(sel_units['linear_shift_baseline_context_true_value']-\n",
    "                                    sel_units['linear_shift_baseline_context_null_median'])/\n",
    "                                    sel_units['linear_shift_baseline_context_null_std'],\n",
    "        })\n",
    "        \n",
    "        #remove any nan or inf values\n",
    "        stim_mag = np.array(np.nanmax(np.abs(magnitudes[['vis1','vis2','sound1','sound2']].values),axis=1),dtype=float)\n",
    "        stim_mag = np.mean(stim_mag[~np.isnan(stim_mag) & ~np.isinf(stim_mag)])\n",
    "\n",
    "        context_mag = np.array(np.abs(magnitudes['context'].values),dtype=float)\n",
    "        context_mag = np.mean(context_mag[~np.isnan(context_mag) & ~np.isinf(context_mag)])\n",
    "\n",
    "        context_linear_shift_mag = np.array(np.abs(magnitudes['context_linear_shift_mag'].values),dtype=float)\n",
    "        context_linear_shift_mag = np.mean(context_linear_shift_mag[~np.isnan(context_linear_shift_mag) & ~np.isinf(context_linear_shift_mag)])\n",
    "\n",
    "        lick_mag = np.array(np.abs(magnitudes['lick'].values),dtype=float)\n",
    "        lick_mag = np.mean(lick_mag[~np.isnan(lick_mag) & ~np.isinf(lick_mag)])\n",
    "\n",
    "        area_number_context_mod['area'].append(sel_area)\n",
    "        area_number_context_mod['stim_mag'].append(stim_mag)\n",
    "        area_number_context_mod['context_mag'].append(context_mag)\n",
    "        area_number_context_mod['context_linear_shift_mag'].append(context_linear_shift_mag)\n",
    "        area_number_context_mod['lick_mag'].append(lick_mag)\n",
    "\n",
    "        area_number_context_mod['total_n'].append(len(sel_units))\n",
    "        area_number_context_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "\n",
    "area_number_context_mod=pd.DataFrame(area_number_context_mod)\n",
    "\n",
    "area_fraction_context_mod=area_number_context_mod.copy()\n",
    "\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\area_magnitude_context_stim_lick_mod.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_magnitude_context_stim_lick_mod.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnitudes['context_linear_shift_mag']\n",
    "# magnitudes[magnitudes!=np.inf]\n",
    "# magnitudes[~np.any(magnitudes==np.inf,axis=1)]\n",
    "\n",
    "# np.nanmean(magnitudes['lick'])\n",
    "\n",
    "# (sel_units['linear_shift_baseline_context_true_value']-sel_units['linear_shift_baseline_context_null_median'])/sel_units['linear_shift_baseline_context_null_std']\n",
    "# np.array(stim_mag,dtype=float)\n",
    "# stim_mag\n",
    "# ~np.isnan(stim_mag) & ~np.isinf(stim_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context, lick, stimulus mod by layer\n",
    "\n",
    "# context modulation vs. stimulus modulation vs. lick modulation\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_context_layer_mod={\n",
    "        'area':[],\n",
    "        'any_stim':[],\n",
    "        'only_stim':[],\n",
    "        'any_context':[],\n",
    "        'only_context':[],\n",
    "        'any_lick':[],\n",
    "        'only_lick':[],\n",
    "        'stim_and_context':[],\n",
    "        'lick_and_stim':[],\n",
    "        'lick_and_context':[],\n",
    "        'lick_and_stim_and_context':[],\n",
    "        'none':[],\n",
    "        'any_context_pos':[],\n",
    "        'any_context_neg':[],\n",
    "        'any_lick_pos':[],\n",
    "        'any_lick_neg':[],\n",
    "        'any_stim_pos':[],\n",
    "        'any_stim_neg':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['location'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                location==@sel_area')\n",
    "        \n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "        'lick':fdrcorrection(sel_units['lick_modulation_p_value'])[1],\n",
    "        'vis1_sign':sel_units['vis1_stimulus_modulation_sign'],\n",
    "        'vis2_sign':sel_units['vis2_stimulus_modulation_sign'],\n",
    "        'sound1_sign':sel_units['sound1_stimulus_modulation_sign'],\n",
    "        'sound2_sign':sel_units['sound2_stimulus_modulation_sign'],\n",
    "        'context_sign':sel_units['baseline_context_modulation_sign'],\n",
    "        'lick_sign':sel_units['lick_modulation_sign'],\n",
    "        })\n",
    "\n",
    "        #lick modulation only\n",
    "        only_lick_resp=adj_pvals.query('lick<0.05 and context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #any lick modulation\n",
    "        any_lick_resp=adj_pvals.query('lick<0.05')\n",
    "        #lick and context\n",
    "        lick_and_context_resp=adj_pvals.query('context<0.05 and lick<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #lick and stimulus\n",
    "        lick_and_stim_resp=adj_pvals.query('lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05')\n",
    "        #all three\n",
    "        all_resp=adj_pvals.query('context<0.05 and lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "        \n",
    "        #stimulus modulation only\n",
    "        only_stim_resp=adj_pvals.query('(vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05 and lick>=0.05')\n",
    "        #any stim modulation\n",
    "        any_stim_resp=adj_pvals.query('vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05')\n",
    "       \n",
    "        #context modulation only\n",
    "        only_context_resp=adj_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "        #any context modulation\n",
    "        any_context_resp=adj_pvals.query('context<0.05')\n",
    "\n",
    "        #stim and context modulation\n",
    "        stim_and_context_resp=adj_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and lick>=0.05')\n",
    "        #none\n",
    "        no_resp=adj_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "        \n",
    "        #pos vs. neg modulation\n",
    "        #context\n",
    "        any_context_pos=adj_pvals.query('context<0.05 and context_sign>0')\n",
    "        any_context_neg=adj_pvals.query('context<0.05 and context_sign<0')\n",
    "        #lick\n",
    "        any_lick_pos=adj_pvals.query('lick<0.05 and lick_sign>0')\n",
    "        any_lick_neg=adj_pvals.query('lick<0.05 and lick_sign<0')\n",
    "        #stim\n",
    "        any_stim_pos=adj_pvals.query('(vis1<0.05 and vis1_sign>0) or (vis2<0.05 and vis2_sign>0) or (sound1<0.05 and sound1_sign>0) or (sound2<0.05 and sound2_sign>0)')\n",
    "        any_stim_neg=adj_pvals.query('(vis1<0.05 and vis1_sign<0) or (vis2<0.05 and vis2_sign<0) or (sound1<0.05 and sound1_sign<0) or (sound2<0.05 and sound2_sign<0)')\n",
    "\n",
    "        area_number_context_layer_mod['area'].append(sel_area)\n",
    "        area_number_context_layer_mod['only_stim'].append(len(only_stim_resp))\n",
    "        area_number_context_layer_mod['any_stim'].append(len(any_stim_resp))\n",
    "        area_number_context_layer_mod['only_context'].append(len(only_context_resp))\n",
    "        area_number_context_layer_mod['any_context'].append(len(any_context_resp))\n",
    "        area_number_context_layer_mod['only_lick'].append(len(only_lick_resp))\n",
    "        area_number_context_layer_mod['any_lick'].append(len(any_lick_resp))\n",
    "        area_number_context_layer_mod['stim_and_context'].append(len(stim_and_context_resp))\n",
    "        area_number_context_layer_mod['lick_and_stim'].append(len(lick_and_stim_resp))\n",
    "        area_number_context_layer_mod['lick_and_context'].append(len(lick_and_context_resp))\n",
    "        area_number_context_layer_mod['lick_and_stim_and_context'].append(len(all_resp))\n",
    "        area_number_context_layer_mod['none'].append(len(no_resp))\n",
    "        area_number_context_layer_mod['total_n'].append(len(sel_units))\n",
    "        area_number_context_layer_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "        area_number_context_layer_mod['any_context_pos'].append(len(any_context_pos))\n",
    "        area_number_context_layer_mod['any_context_neg'].append(len(any_context_neg))\n",
    "        area_number_context_layer_mod['any_lick_pos'].append(len(any_lick_pos))\n",
    "        area_number_context_layer_mod['any_lick_neg'].append(len(any_lick_neg))\n",
    "        area_number_context_layer_mod['any_stim_pos'].append(len(any_stim_pos))\n",
    "        area_number_context_layer_mod['any_stim_neg'].append(len(any_stim_neg))\n",
    "\n",
    "        # labels=['stimulus only','stimulus and context','context only','neither']\n",
    "        # sizes=[len(any_stim_resp),len(stim_and_context_resp),len(context_resp),\n",
    "        #         len(neither_stim_nor_context_resp)]\n",
    "        \n",
    "        labels=['stimulus only','stimulus and context','context only',\n",
    "                'context and lick','lick only', 'lick & stimulus & context',\n",
    "                'lick and stimulus',  'none']\n",
    "        sizes=[len(only_stim_resp),len(stim_and_context_resp),len(only_context_resp),\n",
    "                len(lick_and_context_resp),len(only_lick_resp),len(all_resp),\n",
    "                len(lick_and_stim_resp), len(no_resp)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "                        'tab:red' , 'tab:purple', 'tab:brown', \n",
    "                        'tab:pink', 'grey'])\n",
    "                ax.set_title('area='+sel_area+'; n_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "\n",
    "                fig.tight_layout()\n",
    "\n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\context_lick_stim_resp_by_layer\",sel_area.replace('/','-')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\plots\\context_lick_stim_resp_by_layer\",sel_area.replace('/','-')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_layer_mod=pd.DataFrame(area_number_context_layer_mod)\n",
    "\n",
    "area_fraction_context_layer_mod=area_number_context_layer_mod.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_layer_mod.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_context_layer_mod.iloc[rr,1:-2]=row.iloc[1:-2]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_layer_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_lick_mod_by_layer.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_layer_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_stim_lick_mod_by_layer.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context, lick, stimulus mod by cell type\n",
    "cell_types=['RS','FS']\n",
    "# context modulation vs. stimulus modulation vs. lick modulation\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_context_celltype_mod={\n",
    "        'area':[],\n",
    "        'celltype':[],\n",
    "        'any_stim':[],\n",
    "        'only_stim':[],\n",
    "        'any_context':[],\n",
    "        'only_context':[],\n",
    "        'any_lick':[],\n",
    "        'only_lick':[],\n",
    "        'stim_and_context':[],\n",
    "        'lick_and_stim':[],\n",
    "        'lick_and_context':[],\n",
    "        'lick_and_stim_and_context':[],\n",
    "        'none':[],\n",
    "        # 'any_context_pos':[],\n",
    "        # 'any_context_neg':[],\n",
    "        # 'any_lick_pos':[],\n",
    "        # 'any_lick_neg':[],\n",
    "        # 'any_stim_pos':[],\n",
    "        # 'any_stim_neg':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['location'].unique():\n",
    "    \n",
    "    for celltype in cell_types:\n",
    "        \n",
    "        if celltype=='RS':\n",
    "                sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                        isi_violations_ratio<=0.1 and \\\n",
    "                                        amplitude_cutoff<=0.1 and \\\n",
    "                                        project.str.contains(@sel_project) and \\\n",
    "                                        location==@sel_area and \\\n",
    "                                        peak_to_valley>0.0004')\n",
    "        elif celltype=='FS':\n",
    "                sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                        isi_violations_ratio<=0.1 and \\\n",
    "                                        amplitude_cutoff<=0.1 and \\\n",
    "                                        project.str.contains(@sel_project) and \\\n",
    "                                        location==@sel_area and \\\n",
    "                                        peak_to_valley<=0.0004')\n",
    "        \n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "        'lick':fdrcorrection(sel_units['lick_modulation_p_value'])[1],\n",
    "        'vis1_sign':sel_units['vis1_stimulus_modulation_sign'],\n",
    "        'vis2_sign':sel_units['vis2_stimulus_modulation_sign'],\n",
    "        'sound1_sign':sel_units['sound1_stimulus_modulation_sign'],\n",
    "        'sound2_sign':sel_units['sound2_stimulus_modulation_sign'],\n",
    "        'context_sign':sel_units['baseline_context_modulation_sign'],\n",
    "        'lick_sign':sel_units['lick_modulation_sign'],\n",
    "        })\n",
    "\n",
    "        #lick modulation only\n",
    "        only_lick_resp=adj_pvals.query('lick<0.05 and context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #any lick modulation\n",
    "        any_lick_resp=adj_pvals.query('lick<0.05')\n",
    "        #lick and context\n",
    "        lick_and_context_resp=adj_pvals.query('context<0.05 and lick<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05')\n",
    "        #lick and stimulus\n",
    "        lick_and_stim_resp=adj_pvals.query('lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05')\n",
    "        #all three\n",
    "        all_resp=adj_pvals.query('context<0.05 and lick<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05)')\n",
    "\n",
    "        #stimulus modulation only\n",
    "        only_stim_resp=adj_pvals.query('(vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and context>=0.05 and lick>=0.05')\n",
    "        #any stim modulation\n",
    "        any_stim_resp=adj_pvals.query('vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05')\n",
    "\n",
    "        #context modulation only\n",
    "        only_context_resp=adj_pvals.query('context<0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "        #any context modulation\n",
    "        any_context_resp=adj_pvals.query('context<0.05')\n",
    "\n",
    "        #stim and context modulation\n",
    "        stim_and_context_resp=adj_pvals.query('context<0.05 and (vis1<0.05 or vis2<0.05 or sound1<0.05 or sound2<0.05) and lick>=0.05')\n",
    "        #none\n",
    "        no_resp=adj_pvals.query('context>=0.05 and vis1>=0.05 and vis2>=0.05 and sound1>=0.05 and sound2>=0.05 and lick>=0.05')\n",
    "\n",
    "        area_number_context_celltype_mod['area'].append(sel_area)\n",
    "        area_number_context_celltype_mod['celltype'].append(celltype)\n",
    "        area_number_context_celltype_mod['only_stim'].append(len(only_stim_resp))\n",
    "        area_number_context_celltype_mod['any_stim'].append(len(any_stim_resp))\n",
    "        area_number_context_celltype_mod['only_context'].append(len(only_context_resp))\n",
    "        area_number_context_celltype_mod['any_context'].append(len(any_context_resp))\n",
    "        area_number_context_celltype_mod['only_lick'].append(len(only_lick_resp))\n",
    "        area_number_context_celltype_mod['any_lick'].append(len(any_lick_resp))\n",
    "        area_number_context_celltype_mod['stim_and_context'].append(len(stim_and_context_resp))\n",
    "        area_number_context_celltype_mod['lick_and_stim'].append(len(lick_and_stim_resp))\n",
    "        area_number_context_celltype_mod['lick_and_context'].append(len(lick_and_context_resp))\n",
    "        area_number_context_celltype_mod['lick_and_stim_and_context'].append(len(all_resp))\n",
    "        area_number_context_celltype_mod['none'].append(len(no_resp))\n",
    "        area_number_context_celltype_mod['total_n'].append(len(sel_units))\n",
    "        area_number_context_celltype_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "        labels=['stimulus only','stimulus and context','context only',\n",
    "                'context and lick','lick only', 'lick & stimulus & context',\n",
    "                'lick and stimulus',  'none']\n",
    "        sizes=[len(only_stim_resp),len(stim_and_context_resp),len(only_context_resp),\n",
    "                len(lick_and_context_resp),len(only_lick_resp),len(all_resp),\n",
    "                len(lick_and_stim_resp), len(no_resp)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "                        'tab:red' , 'tab:purple', 'tab:brown', \n",
    "                        'tab:pink', 'grey'])\n",
    "                ax.set_title('area='+sel_area+'; '+celltype+'; n_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "\n",
    "                fig.tight_layout()\n",
    "\n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\context_lick_stim_resp_by_layer_celltype\",sel_area.replace('/','-')+' '+celltype+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\context_lick_stim_resp_by_layer_celltype\",sel_area.replace('/','-')+' '+celltype+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_celltype_mod=pd.DataFrame(area_number_context_celltype_mod)\n",
    "\n",
    "area_fraction_context_celltype_mod=area_number_context_celltype_mod.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_celltype_mod.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_context_celltype_mod.iloc[rr,2:-2]=row.iloc[2:-2]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_celltype_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_lick_mod_by_celltype.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_celltype_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_stim_lick_mod_by_celltype.csv\",\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_area.replace('/','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context mod of stimulus responsiveness by area\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "###TODO: Add sign to this!\n",
    "\n",
    "area_number_context_stim_mod={\n",
    "        'area':[],\n",
    "        'vis1':[],\n",
    "        'vis2':[],\n",
    "        'sound1':[],\n",
    "        'sound2':[],\n",
    "        'both_vis':[],\n",
    "        'both_sound':[],\n",
    "        'mixed':[],\n",
    "        'none':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "        'n_stim_responsive':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_context':fdrcorrection(sel_units['vis1_context_modulation_p_value'])[1],\n",
    "        'vis2_context':fdrcorrection(sel_units['vis2_context_modulation_p_value'])[1],\n",
    "        'sound1_context':fdrcorrection(sel_units['sound1_context_modulation_p_value'])[1],\n",
    "        'sound2_context':fdrcorrection(sel_units['sound2_context_modulation_p_value'])[1],\n",
    "        })\n",
    "        \n",
    "        adj_pvals['any_stim']=adj_pvals[['vis1','vis2','sound1','sound2']].min(axis=1)\n",
    "        \n",
    "        #stimulus context modulation\n",
    "        vis1_context_stim_mod=adj_pvals.query('vis1_context<0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "        vis2_context_stim_mod=adj_pvals.query('vis2_context<0.05 and vis1_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "        sound1_context_stim_mod=adj_pvals.query('sound1_context<0.05 and sound2_context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "        sound2_context_stim_mod=adj_pvals.query('sound2_context<0.05 and sound1_context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "\n",
    "        both_vis_context_stim_mod=adj_pvals.query('vis1_context<0.05 and vis2_context<0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "        both_aud_context_stim_mod=adj_pvals.query('sound1_context<0.05 and sound2_context<0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "        multi_modal_context_stim_mod=adj_pvals.query('((vis1_context<0.05 or vis2_context<0.05) and (sound1_context<0.05 or sound2_context<0.05)) and any_stim<0.05')\n",
    "\n",
    "        no_context_stim_mod=adj_pvals.query('vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "\n",
    "        n_stim_resp_units=np.sum(adj_pvals['any_stim']<0.05)\n",
    "\n",
    "        area_number_context_stim_mod['area'].append(sel_area)\n",
    "        area_number_context_stim_mod['vis1'].append(len(vis1_context_stim_mod))\n",
    "        area_number_context_stim_mod['vis2'].append(len(vis2_context_stim_mod))\n",
    "        area_number_context_stim_mod['sound1'].append(len(sound1_context_stim_mod))\n",
    "        area_number_context_stim_mod['sound2'].append(len(sound2_context_stim_mod))\n",
    "        area_number_context_stim_mod['both_vis'].append(len(both_vis_context_stim_mod))\n",
    "        area_number_context_stim_mod['both_sound'].append(len(both_aud_context_stim_mod))\n",
    "        area_number_context_stim_mod['mixed'].append(len(multi_modal_context_stim_mod))\n",
    "        area_number_context_stim_mod['none'].append(len(no_context_stim_mod))\n",
    "        area_number_context_stim_mod['total_n'].append(len(sel_units))\n",
    "        area_number_context_stim_mod['n_stim_responsive'].append(n_stim_resp_units)\n",
    "        area_number_context_stim_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "        labels=['vis1 only','vis2 only','both vis',\n",
    "                'sound1 only','sound2 only','both sound',\n",
    "                'mixed','none']\n",
    "        \n",
    "        sizes=[len(vis1_context_stim_mod),len(vis2_context_stim_mod),len(both_vis_context_stim_mod),\n",
    "                len(sound1_context_stim_mod),len(sound2_context_stim_mod),len(both_aud_context_stim_mod),\n",
    "                len(multi_modal_context_stim_mod),len(no_context_stim_mod)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%')\n",
    "                ax.set_title('area='+sel_area+'; n_stim_resp_units='+str(n_stim_resp_units)+'; n_total_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('context modulation of stimulus response')\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\context mod of stimulus response\",sel_area+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\context mod of stimulus response\",sel_area+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_stim_mod=pd.DataFrame(area_number_context_stim_mod)\n",
    "\n",
    "area_fraction_context_stim_mod=area_number_context_stim_mod.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_stim_mod.iterrows():\n",
    "    if row['n_stim_responsive']>0:\n",
    "        area_fraction_context_stim_mod.iloc[rr,1:-4]=row.iloc[1:-4]/row['n_stim_responsive']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_stim_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_mod.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_stim_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_stim_mod.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context mod of evoked stimulus responsiveness by area\n",
    "\n",
    "area_number_context_evoked_stim_mod={\n",
    "        'area':[],\n",
    "        'vis1':[],\n",
    "        'vis2':[],\n",
    "        'sound1':[],\n",
    "        'sound2':[],\n",
    "        'both_vis':[],\n",
    "        'both_sound':[],\n",
    "        'mixed':[],\n",
    "        'none':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "        'n_stim_responsive':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(\"DynamicRouting\") and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_context':fdrcorrection(sel_units['vis1_evoked_context_modulation_p_value'])[1],\n",
    "        'vis2_context':fdrcorrection(sel_units['vis2_evoked_context_modulation_p_value'])[1],\n",
    "        'sound1_context':fdrcorrection(sel_units['sound1_evoked_context_modulation_p_value'])[1],\n",
    "        'sound2_context':fdrcorrection(sel_units['sound2_evoked_context_modulation_p_value'])[1],\n",
    "        })\n",
    "        \n",
    "        adj_pvals['any_stim']=adj_pvals[['vis1','vis2','sound1','sound2']].min(axis=1)\n",
    "        \n",
    "        #stimulus context modulation\n",
    "        vis1_context_evoked_stim_mod=adj_pvals.query('vis1_context<0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "        vis2_context_evoked_stim_mod=adj_pvals.query('vis2_context<0.05 and vis1_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "        sound1_context_evoked_stim_mod=adj_pvals.query('sound1_context<0.05 and sound2_context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "        sound2_context_evoked_stim_mod=adj_pvals.query('sound2_context<0.05 and sound1_context>=0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "\n",
    "        both_vis_context_evoked_stim_mod=adj_pvals.query('vis1_context<0.05 and vis2_context<0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "        both_aud_context_evoked_stim_mod=adj_pvals.query('sound1_context<0.05 and sound2_context<0.05 and vis1_context>=0.05 and vis2_context>=0.05 and any_stim<0.05')\n",
    "        multi_modal_context_evoked_stim_mod=adj_pvals.query('((vis1_context<0.05 or vis2_context<0.05) and (sound1_context<0.05 or sound2_context<0.05)) and any_stim<0.05')\n",
    "\n",
    "        no_context_evoked_stim_mod=adj_pvals.query('vis1_context>=0.05 and vis2_context>=0.05 and sound1_context>=0.05 and sound2_context>=0.05 and any_stim<0.05')\n",
    "\n",
    "        n_stim_resp_units=np.sum(adj_pvals['any_stim']<0.05)\n",
    "\n",
    "        area_number_context_evoked_stim_mod['area'].append(sel_area)\n",
    "        area_number_context_evoked_stim_mod['vis1'].append(len(vis1_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['vis2'].append(len(vis2_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['sound1'].append(len(sound1_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['sound2'].append(len(sound2_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['both_vis'].append(len(both_vis_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['both_sound'].append(len(both_aud_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['mixed'].append(len(multi_modal_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['none'].append(len(no_context_evoked_stim_mod))\n",
    "        area_number_context_evoked_stim_mod['total_n'].append(len(sel_units))\n",
    "        area_number_context_evoked_stim_mod['n_stim_responsive'].append(n_stim_resp_units)\n",
    "        area_number_context_evoked_stim_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "        labels=['vis1 only','vis2 only','both vis',\n",
    "                'sound1 only','sound2 only','both sound',\n",
    "                'mixed','none']\n",
    "        \n",
    "        sizes=[len(vis1_context_evoked_stim_mod),len(vis2_context_evoked_stim_mod),len(both_vis_context_evoked_stim_mod),\n",
    "                len(sound1_context_evoked_stim_mod),len(sound2_context_evoked_stim_mod),len(both_aud_context_evoked_stim_mod),\n",
    "                len(multi_modal_context_evoked_stim_mod),len(no_context_evoked_stim_mod)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%')\n",
    "                ax.set_title('area='+sel_area+'; n_stim_resp_units='+str(n_stim_resp_units)+'; n_total_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('context modulation of evoked stimulus response')\n",
    "                fig.tight_layout()\n",
    "\n",
    "                fig.savefig(\n",
    "                        os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\context mod of evoked stimulus response\",sel_area+\"_DR.png\"),\n",
    "                        dpi=300, facecolor='w', edgecolor='w',\n",
    "                        orientation='portrait', format='png',\n",
    "                        transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                        metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_evoked_stim_mod=pd.DataFrame(area_number_context_evoked_stim_mod)\n",
    "\n",
    "area_fraction_context_evoked_stim_mod=area_number_context_evoked_stim_mod.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_evoked_stim_mod.iterrows():\n",
    "    if row['n_stim_responsive']>0:\n",
    "        area_fraction_context_evoked_stim_mod.iloc[rr,1:-4]=row.iloc[1:-4]/row['n_stim_responsive']\n",
    "\n",
    "area_fraction_context_evoked_stim_mod.to_csv(\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_evoked_stim_mod.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline vs. context modulated units\n",
    "\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_stim_vs_baseline_context_mod={\n",
    "        'area':[],\n",
    "        'baseline':[],\n",
    "        'stim':[],\n",
    "        'both':[],\n",
    "        'neither':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "        'n_stim_responsive':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_context':fdrcorrection(sel_units['vis1_context_modulation_p_value'])[1],\n",
    "        'vis2_context':fdrcorrection(sel_units['vis2_context_modulation_p_value'])[1],\n",
    "        'sound1_context':fdrcorrection(sel_units['sound1_context_modulation_p_value'])[1],\n",
    "        'sound2_context':fdrcorrection(sel_units['sound2_context_modulation_p_value'])[1],\n",
    "        'baseline_context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "        })\n",
    "        \n",
    "        adj_pvals['any_stim']=adj_pvals[['vis1','vis2','sound1','sound2']].min(axis=1)\n",
    "        adj_pvals['any_stim_context']=adj_pvals[['vis1_context','vis2_context','sound1_context','sound2_context']].min(axis=1)\n",
    "        \n",
    "        #stimulus context modulation\n",
    "        stim_context_mod=adj_pvals.query('any_stim_context<0.05 and baseline_context>=0.05')\n",
    "        baseline_context_mod=adj_pvals.query('baseline_context<0.05 and any_stim_context>=0.05')\n",
    "        both_context_stim_mod=adj_pvals.query('any_stim_context<0.05 and baseline_context<0.05')\n",
    "        neither_context_stim_mod=adj_pvals.query('any_stim_context>=0.05 and baseline_context>=0.05')\n",
    "\n",
    "        n_stim_resp_units=np.sum(adj_pvals['any_stim']<0.05)\n",
    "\n",
    "        area_number_stim_vs_baseline_context_mod['area'].append(sel_area)\n",
    "        area_number_stim_vs_baseline_context_mod['baseline'].append(len(baseline_context_mod))\n",
    "        area_number_stim_vs_baseline_context_mod['stim'].append(len(stim_context_mod))\n",
    "        area_number_stim_vs_baseline_context_mod['both'].append(len(both_context_stim_mod))\n",
    "        area_number_stim_vs_baseline_context_mod['neither'].append(len(neither_context_stim_mod))\n",
    "        area_number_stim_vs_baseline_context_mod['total_n'].append(len(sel_units))\n",
    "        area_number_stim_vs_baseline_context_mod['n_stim_responsive'].append(n_stim_resp_units)\n",
    "        area_number_stim_vs_baseline_context_mod['n_sessions'].append(n_sessions)\n",
    "\n",
    "        labels=['stim only','baseline only','both','neither']\n",
    "        \n",
    "        sizes=[len(stim_context_mod),len(baseline_context_mod),len(both_context_stim_mod),\n",
    "                len(neither_context_stim_mod)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                       colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "                        'grey'])\n",
    "                ax.set_title('area='+sel_area+'; n_total_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('context modulation of stimulus and/or baseline')\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\baseline vs stimulus context mod\",sel_area.replace('/','')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\baseline vs stimulus context mod\",sel_area.replace('/','')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_stim_vs_baseline_context_mod=pd.DataFrame(area_number_stim_vs_baseline_context_mod)\n",
    "\n",
    "area_fraction_stim_vs_baseline_context_mod=area_number_stim_vs_baseline_context_mod.copy()\n",
    "\n",
    "for rr,row in area_fraction_stim_vs_baseline_context_mod.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_stim_vs_baseline_context_mod.iloc[rr,1:-3]=row.iloc[1:-3]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_stim_vs_baseline_context_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\baseline vs stimulus context mod.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_stim_vs_baseline_context_mod.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\baseline vs stimulus context mod.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign of context modulation by area\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_context_mod_sign={\n",
    "        'area':[],\n",
    "        'stim_pos_baseline_pos':[],\n",
    "        'stim_pos_baseline_neg':[],\n",
    "        'stim_neg_baseline_pos':[],\n",
    "        'stim_neg_baseline_neg':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "        \n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_context':fdrcorrection(sel_units['vis1_context_modulation_p_value'])[1],\n",
    "        'vis2_context':fdrcorrection(sel_units['vis2_context_modulation_p_value'])[1],\n",
    "        'sound1_context':fdrcorrection(sel_units['sound1_context_modulation_p_value'])[1],\n",
    "        'sound2_context':fdrcorrection(sel_units['sound2_context_modulation_p_value'])[1],\n",
    "        'baseline_context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "\n",
    "        'context_sign':sel_units['baseline_context_modulation_sign'],\n",
    "        'vis1_context_sign':sel_units['vis1_context_modulation_sign'],\n",
    "        'vis2_context_sign':sel_units['vis2_context_modulation_sign'],\n",
    "        'sound1_context_sign':sel_units['sound1_context_modulation_sign'],\n",
    "        'sound2_context_sign':sel_units['sound2_context_modulation_sign'],\n",
    "        })\n",
    "        \n",
    "        adj_pvals['any_stim']=adj_pvals[['vis1','vis2','sound1','sound2']].min(axis=1)\n",
    "        adj_pvals['any_stim_context']=adj_pvals[['vis1_context','vis2_context','sound1_context','sound2_context']].min(axis=1)\n",
    "        \n",
    "        #stimulus context modulation\n",
    "        #of baseline and stim context-modulated units,\n",
    "        #how many both go up, down, or in different directions?\n",
    "\n",
    "        context_stim_and_baseline_mod=adj_pvals.query('baseline_context<0.05 and (vis1_context<0.05 or vis2_context<0.05 or sound1_context<0.05 or sound2_context<0.05)')\n",
    "        # stim_pos=context_stim_and_baseline_mod.query('(vis1_context_sign>0 or vis2_context_sign>0 or sound1_context_sign>0 or sound2_context_sign>0)')\n",
    "\n",
    "        vis1_pos_baseline_pos=context_stim_and_baseline_mod.query('vis1_context_sign>0 and context_sign>0')\n",
    "        vis1_pos_baseline_neg=context_stim_and_baseline_mod.query('vis1_context_sign>0 and context_sign<0')\n",
    "        vis1_neg_baseline_pos=context_stim_and_baseline_mod.query('vis1_context_sign<0 and context_sign>0')\n",
    "        vis1_neg_baseline_neg=context_stim_and_baseline_mod.query('vis1_context_sign<0 and context_sign<0')\n",
    "        vis1_combo=context_stim_and_baseline_mod.query('vis1_context<0.05')\n",
    "\n",
    "        vis2_pos_baseline_pos=context_stim_and_baseline_mod.query('vis2_context_sign>0 and context_sign>0')\n",
    "        vis2_pos_baseline_neg=context_stim_and_baseline_mod.query('vis2_context_sign>0 and context_sign<0')\n",
    "        vis2_neg_baseline_pos=context_stim_and_baseline_mod.query('vis2_context_sign<0 and context_sign>0')\n",
    "        vis2_neg_baseline_neg=context_stim_and_baseline_mod.query('vis2_context_sign<0 and context_sign<0')\n",
    "        vis2_combo=context_stim_and_baseline_mod.query('vis2_context<0.05')\n",
    "\n",
    "        sound1_pos_baseline_pos=context_stim_and_baseline_mod.query('sound1_context_sign>0 and context_sign>0')\n",
    "        sound1_pos_baseline_neg=context_stim_and_baseline_mod.query('sound1_context_sign>0 and context_sign<0')\n",
    "        sound1_neg_baseline_pos=context_stim_and_baseline_mod.query('sound1_context_sign<0 and context_sign>0')\n",
    "        sound1_neg_baseline_neg=context_stim_and_baseline_mod.query('sound1_context_sign<0 and context_sign<0')\n",
    "        sound1_combo=context_stim_and_baseline_mod.query('sound1_context<0.05')\n",
    "\n",
    "        sound2_pos_baseline_pos=context_stim_and_baseline_mod.query('sound2_context_sign>0 and context_sign>0')\n",
    "        sound2_pos_baseline_neg=context_stim_and_baseline_mod.query('sound2_context_sign>0 and context_sign<0')\n",
    "        sound2_neg_baseline_pos=context_stim_and_baseline_mod.query('sound2_context_sign<0 and context_sign>0')\n",
    "        sound2_neg_baseline_neg=context_stim_and_baseline_mod.query('sound2_context_sign<0 and context_sign<0')\n",
    "        sound2_combo=context_stim_and_baseline_mod.query('sound2_context<0.05')\n",
    "\n",
    "\n",
    "        stim_pos_baseline_pos=pd.concat([vis1_pos_baseline_pos,vis2_pos_baseline_pos,sound1_pos_baseline_neg,sound2_pos_baseline_neg],axis=0)\n",
    "        stim_pos_baseline_neg=pd.concat([vis1_pos_baseline_neg,vis2_pos_baseline_neg,sound1_pos_baseline_pos,sound2_pos_baseline_pos],axis=0)\n",
    "        stim_neg_baseline_pos=pd.concat([vis1_neg_baseline_pos,vis2_neg_baseline_pos,sound1_neg_baseline_neg,sound2_neg_baseline_neg],axis=0)\n",
    "        stim_neg_baseline_neg=pd.concat([vis1_neg_baseline_neg,vis2_neg_baseline_neg,sound1_neg_baseline_pos,sound2_neg_baseline_pos],axis=0)\n",
    "        all_stim_combo=pd.concat([vis1_combo,vis2_combo,sound1_combo,sound2_combo],axis=0)\n",
    "\n",
    "\n",
    "        n_stim_resp_units=np.sum(adj_pvals['any_stim']<0.05)\n",
    "\n",
    "        area_number_context_mod_sign['area'].append(sel_area)\n",
    "        area_number_context_mod_sign['stim_pos_baseline_pos'].append(len(stim_pos_baseline_pos))\n",
    "        area_number_context_mod_sign['stim_pos_baseline_neg'].append(len(stim_pos_baseline_neg))\n",
    "        area_number_context_mod_sign['stim_neg_baseline_pos'].append(len(stim_neg_baseline_pos))\n",
    "        area_number_context_mod_sign['stim_neg_baseline_neg'].append(len(stim_neg_baseline_neg))\n",
    "        area_number_context_mod_sign['total_n'].append(len(sel_units))\n",
    "        area_number_context_mod_sign['n_sessions'].append(n_sessions)\n",
    "\n",
    "        \n",
    "        labels=['stim up; same baseline up','stim up, same baseline down','stim down; same baseline up','stim down; same baseline down']\n",
    "        sizes=[len(stim_pos_baseline_pos),len(stim_pos_baseline_neg),len(stim_neg_baseline_pos),\n",
    "                len(stim_neg_baseline_neg)]\n",
    "\n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                colors=['tab:blue', 'tab:orange', 'tab:green',\n",
    "                        'tab:red'])\n",
    "                ax.set_title('area='+sel_area+'; n_total_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('sign of context modulation of stimulus and baseline')\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\baseline vs stimulus context mod sign\",sel_area.replace('/','')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\baseline vs stimulus context mod sign\",sel_area.replace('/','')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_mod_sign=pd.DataFrame(area_number_context_mod_sign)\n",
    "\n",
    "area_fraction_context_mod_sign=area_number_context_mod_sign.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_mod_sign.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_context_mod_sign.iloc[rr,1:-2]=row.iloc[1:-2]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_mod_sign.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\baseline vs stimulus context mod sign.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_mod_sign.to_csv(\n",
    "        r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\baseline vs stimulus context mod sign.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context mod vs not context mod stim responses\n",
    "\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_stim_context_mod_vs_not={\n",
    "        'area':[],\n",
    "        'context_mod':[],\n",
    "        'not_context_mod':[],\n",
    "        'not_stim_mod':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "        'n_stim_responsive':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_context':fdrcorrection(sel_units['vis1_context_modulation_p_value'])[1],\n",
    "        'vis2_context':fdrcorrection(sel_units['vis2_context_modulation_p_value'])[1],\n",
    "        'sound1_context':fdrcorrection(sel_units['sound1_context_modulation_p_value'])[1],\n",
    "        'sound2_context':fdrcorrection(sel_units['sound2_context_modulation_p_value'])[1],\n",
    "        'baseline_context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "        })\n",
    "        \n",
    "        adj_pvals['any_stim']=adj_pvals[['vis1','vis2','sound1','sound2']].min(axis=1)\n",
    "        adj_pvals['any_stim_context']=adj_pvals[['vis1_context','vis2_context','sound1_context','sound2_context']].min(axis=1)\n",
    "        \n",
    "        #stimulus context modulation\n",
    "        stim_context_mod=adj_pvals.query('any_stim_context<0.05 and any_stim<0.05')\n",
    "        not_stim_context_mod=adj_pvals.query('any_stim_context>=0.05 and any_stim<0.05')\n",
    "        not_stim_mod=adj_pvals.query('any_stim>=0.05')\n",
    "\n",
    "        n_stim_resp_units=np.sum(adj_pvals['any_stim']<0.05)\n",
    "\n",
    "        area_number_stim_context_mod_vs_not['area'].append(sel_area)\n",
    "        area_number_stim_context_mod_vs_not['context_mod'].append(len(stim_context_mod))\n",
    "        area_number_stim_context_mod_vs_not['not_context_mod'].append(len(not_stim_context_mod))\n",
    "        area_number_stim_context_mod_vs_not['not_stim_mod'].append(len(not_stim_mod))\n",
    "        area_number_stim_context_mod_vs_not['total_n'].append(len(sel_units))\n",
    "        area_number_stim_context_mod_vs_not['n_stim_responsive'].append(n_stim_resp_units)\n",
    "        area_number_stim_context_mod_vs_not['n_sessions'].append(n_sessions)\n",
    "\n",
    "        labels=['context modulated','context independent','not stim modulated']\n",
    "        \n",
    "        sizes=[len(stim_context_mod),len(not_stim_context_mod),len(not_stim_mod)]\n",
    "        \n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                       colors=['tab:blue', 'tab:orange','grey'])\n",
    "                ax.set_title('area='+sel_area+'; n_total_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('context modulated vs independent stimulus responses')\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\stimulus context mod vs not\",sel_area.replace('/','')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\stimulus context mod vs not\",sel_area.replace('/','')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_stim_context_mod_vs_not=pd.DataFrame(area_number_stim_context_mod_vs_not)\n",
    "\n",
    "area_fraction_stim_context_mod_vs_not=area_number_stim_context_mod_vs_not.copy()\n",
    "\n",
    "for rr,row in area_fraction_stim_context_mod_vs_not.iterrows():\n",
    "    if row['total_n']>0:\n",
    "        area_fraction_stim_context_mod_vs_not.iloc[rr,1:-3]=row.iloc[1:-3]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_stim_context_mod_vs_not.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\stimulus context mod vs not.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_stim_context_mod_vs_not.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\stimulus context mod vs not.csv\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context modulation of target stimuli in same vs. different directions\n",
    "\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "area_number_context_mod_same_vs_diff={\n",
    "        'area':[],\n",
    "        'same_dir':[],\n",
    "        'diff_dir':[],\n",
    "        'total_n':[],\n",
    "        'n_sessions':[],\n",
    "}\n",
    "\n",
    "for sel_area in all_data['structure'].unique():\n",
    "\n",
    "        sel_units=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(@sel_project) and \\\n",
    "                                structure==@sel_area')\n",
    "\n",
    "        n_sessions=len(sel_units['session_id'].unique())\n",
    "\n",
    "        adj_pvals=pd.DataFrame({\n",
    "        'unit_id':sel_units['unit_id'],\n",
    "        'vis1':fdrcorrection(sel_units['vis1_stimulus_modulation_p_value'])[1],\n",
    "        'vis2':fdrcorrection(sel_units['vis2_stimulus_modulation_p_value'])[1],\n",
    "        'sound1':fdrcorrection(sel_units['sound1_stimulus_modulation_p_value'])[1],\n",
    "        'sound2':fdrcorrection(sel_units['sound2_stimulus_modulation_p_value'])[1],\n",
    "        'vis1_context':fdrcorrection(sel_units['vis1_context_modulation_p_value'])[1],\n",
    "        'vis2_context':fdrcorrection(sel_units['vis2_context_modulation_p_value'])[1],\n",
    "        'sound1_context':fdrcorrection(sel_units['sound1_context_modulation_p_value'])[1],\n",
    "        'sound2_context':fdrcorrection(sel_units['sound2_context_modulation_p_value'])[1],\n",
    "        'baseline_context':fdrcorrection(sel_units['baseline_context_modulation_p_value'])[1],\n",
    "        'context_sign':sel_units['baseline_context_modulation_sign'],\n",
    "        'vis1_context_sign':sel_units['vis1_context_modulation_sign'],\n",
    "        'vis2_context_sign':sel_units['vis2_context_modulation_sign'],\n",
    "        'sound1_context_sign':sel_units['sound1_context_modulation_sign'],\n",
    "        'sound2_context_sign':sel_units['sound2_context_modulation_sign'],\n",
    "        })\n",
    "        \n",
    "        # adj_pvals['any_stim']=adj_pvals[['vis1','vis2','sound1','sound2']].min(axis=1)\n",
    "        # adj_pvals['any_stim_context']=adj_pvals[['vis1_context','vis2_context','sound1_context','sound2_context']].min(axis=1)\n",
    "        \n",
    "        #stimulus context modulation\n",
    "        #of baseline and stim context-modulated units,\n",
    "        #how many both go up, down, or in different directions?\n",
    "\n",
    "        #for units with context modulation of a given stim response, how does context modulate each other stim response?\n",
    "        #not exclusive\n",
    "\n",
    "        same_direction_units=adj_pvals.query('(vis1_context<0.05 and vis1_context_sign>0 and sound1_context<0.05 and sound1_context_sign<0) or \\\n",
    "                                             (vis1_context<0.05 and vis1_context_sign<0 and sound1_context<0.05 and sound1_context_sign>0)')\n",
    "        diff_direction_units=adj_pvals.query('(vis1_context<0.05 and vis1_context_sign>0 and sound1_context<0.05 and sound1_context_sign>0) or \\\n",
    "                                                (vis1_context<0.05 and vis1_context_sign<0 and sound1_context<0.05 and sound1_context_sign<0)')\n",
    "        \n",
    "        # n_stim_resp_units=np.sum(adj_pvals['any_stim']<0.05)\n",
    "\n",
    "        area_number_context_mod_same_vs_diff['area'].append(sel_area)\n",
    "        area_number_context_mod_same_vs_diff['same_dir'].append(len(same_direction_units))\n",
    "        area_number_context_mod_same_vs_diff['diff_dir'].append(len(diff_direction_units))\n",
    "        area_number_context_mod_same_vs_diff['total_n'].append(len(sel_units))\n",
    "        area_number_context_mod_same_vs_diff['n_sessions'].append(n_sessions)\n",
    "\n",
    "        labels=['same direction','different directions','none']\n",
    "\n",
    "        sizes=[len(same_direction_units),len(diff_direction_units),len(sel_units)-len(same_direction_units)-len(diff_direction_units)]\n",
    "\n",
    "        if np.sum(sizes)>0:\n",
    "                fig,ax=plt.subplots()\n",
    "                ax.pie(sizes,labels=labels,autopct='%1.1f%%',\n",
    "                       colors=['tab:blue', 'tab:orange','grey'])\n",
    "                ax.set_title('area='+sel_area+'; n_total_units='+str(len(sel_units))+'; n_sessions='+str(n_sessions))\n",
    "                fig.suptitle('context modulation of different stimulus responses')\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                if 'Templeton' in sel_project:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\Templeton\\context mod same vs diff\",sel_area.replace('/','')+\"_Templeton.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "                else:\n",
    "                        fig.savefig(\n",
    "                                os.path.join(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\plots\\context mod same vs diff\",sel_area.replace('/','')+\"_DR.png\"),\n",
    "                                dpi=300, facecolor='w', edgecolor='w',\n",
    "                                orientation='portrait', format='png',\n",
    "                                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                                metadata=None)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "area_number_context_mod_same_vs_diff=pd.DataFrame(area_number_context_mod_same_vs_diff)\n",
    "\n",
    "area_fraction_context_mod_same_vs_diff=area_number_context_mod_same_vs_diff.copy()\n",
    "\n",
    "for rr,row in area_fraction_context_mod_same_vs_diff.iterrows():\n",
    "        if row['total_n']>0:\n",
    "                area_fraction_context_mod_same_vs_diff.iloc[rr,1:-2]=row.iloc[1:-2]/row['total_n']\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_context_mod_same_vs_diff.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\Templeton\\context mod same vs diff.csv\",\n",
    "        )\n",
    "else:\n",
    "        area_fraction_context_mod_same_vs_diff.to_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\context mod same vs diff.csv\",\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_context_mod_same_vs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered bar graphs of top ~10-15 areas for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "sel_project='DynamicRouting'\n",
    "\n",
    "if 'Templeton' in sel_project:\n",
    "        area_fraction_responsive_to_stim=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\Templeton\\area_fraction_responsive_to_stim.csv\",\n",
    "        )\n",
    "        area_fraction_context_mod=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_lick_mod.csv\",\n",
    "        )\n",
    "        area_fraction_context_stim_mod=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_mod.csv\",\n",
    "        )\n",
    "        # area_fraction_context_evoked_stim_mod=pd.read_csv(\n",
    "        #         r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\Templeton\\area_fraction_context_evoked_stim_mod.csv\",\n",
    "        # )\n",
    "elif 'DynamicRouting' in sel_project:\n",
    "        area_fraction_responsive_to_stim=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_responsive_to_stim.csv\",\n",
    "        )\n",
    "        area_fraction_context_mod=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_stim_lick_mod.csv\",\n",
    "        )\n",
    "        \n",
    "        area_fraction_context_stim_mod=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_stim_mod.csv\",\n",
    "        )\n",
    "        area_fraction_context_evoked_stim_mod=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\area_fraction_context_evoked_stim_mod.csv\",\n",
    "        )\n",
    "        area_fraction_stim_vs_baseline_context_mod=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\baseline vs stimulus context mod.csv\",\n",
    "        )\n",
    "        area_fraction_context_mod_sign=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\baseline vs stimulus context mod sign.csv\",\n",
    "        )\n",
    "        area_fraction_stim_context_mod_vs_not=pd.read_csv(\n",
    "                r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\new_annotations\\single unit metrics\\combined\\stimulus context mod vs not.csv\",\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_responsive_to_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulus:\n",
    "fig,ax=plt.subplots(3,1,figsize=(6,8))\n",
    "#vis: vis1+vis1+both_vis\n",
    "vis_resp=area_fraction_responsive_to_stim[['vis1','vis2','both_vis']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['vis_only']=vis_resp\n",
    "sort_by_vis=area_fraction_responsive_to_stim.query('total_n>=30 and n_sessions>=3').sort_values(by='vis_only',ascending=False).head(10)\n",
    "sort_by_vis[['area','vis_only']].plot.bar(ax=ax[0],x='area',y='vis_only',color='tab:blue')\n",
    "ax[0].set_title('visual stimuli')\n",
    "ax[0].set_ylabel('fraction of units responsive')\n",
    "\n",
    "#aud: sound1+sound2+both_sound\n",
    "aud_resp=area_fraction_responsive_to_stim[['sound1','sound2','both_sound']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['aud_only']=aud_resp\n",
    "sort_by_aud=area_fraction_responsive_to_stim.query('total_n>=30 and n_sessions>=3').sort_values(by='aud_only',ascending=False).head(10)\n",
    "sort_by_aud[['area','aud_only']].plot.bar(ax=ax[1],x='area',y='aud_only',color='tab:orange')\n",
    "ax[1].set_title('auditory stimuli')\n",
    "ax[1].set_ylabel('fraction of units responsive')\n",
    "\n",
    "#mixed: mixed\n",
    "sort_by_mixed=area_fraction_responsive_to_stim.query('total_n>=30 and n_sessions>=3').sort_values(by='mixed',ascending=False).head(10)\n",
    "sort_by_mixed[['area','mixed']].plot.bar(ax=ax[2],x='area',y='mixed',color='tab:green')\n",
    "ax[2].set_title('multimodal')\n",
    "ax[2].set_ylabel('fraction of units responsive')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_context_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lick/context/stim:\n",
    "fig,ax=plt.subplots(3,1,figsize=(6,8))\n",
    "#lick: any lick\n",
    "sort_by_lick=area_fraction_context_mod.query('total_n>=30 and n_sessions>=3').sort_values(by='any_lick',ascending=False).head(10)\n",
    "sort_by_lick[['area','any_lick']].plot.bar(ax=ax[0],x='area',y='any_lick',color='tab:purple')\n",
    "ax[0].set_title('most lick responsive areas')\n",
    "ax[0].set_ylabel('fraction of units responsive')\n",
    "\n",
    "#context: any context\n",
    "sort_by_context=area_fraction_context_mod.query('total_n>=30 and n_sessions>=3').sort_values(by='any_context',ascending=False).head(10)\n",
    "sort_by_context[['area','any_context']].plot.bar(ax=ax[1],x='area',y='any_context',color='tab:brown')\n",
    "ax[1].set_title('most context responsive areas')\n",
    "ax[1].set_ylabel('fraction of units responsive')\n",
    "\n",
    "#stim: any stim\n",
    "sort_by_stim=area_fraction_context_mod.query('total_n>=30 and n_sessions>=3').sort_values(by='any_stim',ascending=False).head(10)\n",
    "sort_by_stim[['area','any_stim']].plot.bar(ax=ax[2],x='area',y='any_stim',color='tab:blue')\n",
    "ax[2].set_title('most stimulus responsive areas')\n",
    "ax[2].set_ylabel('fraction of units responsive')\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_context_stim_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context modulation of stimulus\n",
    "fig,ax=plt.subplots(3,1,figsize=(6,8))\n",
    "#vis: vis1+vis2+both_vis\n",
    "vis_context_stim_mod=area_fraction_context_stim_mod[['vis1','vis2','both_vis']].sum(axis=1)\n",
    "area_fraction_context_stim_mod['vis_only']=vis_context_stim_mod\n",
    "sort_by_vis_context_stim=area_fraction_context_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='vis_only',ascending=False).head(10)\n",
    "sort_by_vis_context_stim[['area','vis_only']].plot.bar(ax=ax[0],x='area',y='vis_only',color='tab:blue')\n",
    "ax[0].set_title('context modulation of visual responses')\n",
    "ax[0].set_ylabel('fraction of units modulated')\n",
    "\n",
    "#aud: sound1+sound2+both_sound\n",
    "aud_context_stim_mod=area_fraction_context_stim_mod[['sound1','sound2','both_sound']].sum(axis=1)\n",
    "area_fraction_context_stim_mod['aud_only']=aud_context_stim_mod\n",
    "sort_by_aud_context_stim=area_fraction_context_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='aud_only',ascending=False).head(10)\n",
    "sort_by_aud_context_stim[['area','aud_only']].plot.bar(ax=ax[1],x='area',y='aud_only',color='tab:orange')\n",
    "ax[1].set_title('context modulation of auditory responses')\n",
    "ax[1].set_ylabel('fraction of units modulated')\n",
    "\n",
    "#mixed: mixed\n",
    "sort_by_mixed_context_stim=area_fraction_context_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='mixed',ascending=False).head(10)\n",
    "sort_by_mixed_context_stim[['area','mixed']].plot.bar(ax=ax[2],x='area',y='mixed',color='tab:green')\n",
    "ax[2].set_title('context modulation of multimodal responses')\n",
    "ax[2].set_ylabel('fraction of units modulated')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context modulation of stimulus\n",
    "fig,ax=plt.subplots(1,1,figsize=(8,4))\n",
    "#vis: vis1+vis2+both_vis\n",
    "vis_context_stim_mod=area_fraction_context_stim_mod[['vis1','vis2','both_vis']].sum(axis=1)\n",
    "area_fraction_context_stim_mod['vis_only']=vis_context_stim_mod\n",
    "\n",
    "#aud: sound1+sound2+both_sound\n",
    "aud_context_stim_mod=area_fraction_context_stim_mod[['sound1','sound2','both_sound']].sum(axis=1)\n",
    "area_fraction_context_stim_mod['aud_only']=aud_context_stim_mod\n",
    "\n",
    "#total frac responsive\n",
    "area_fraction_context_stim_mod['any_stim']=area_fraction_context_stim_mod[['vis1','vis2','sound1','sound2','mixed','both_vis','both_sound']].sum(axis=1)\n",
    "\n",
    "sort_by_any_context_mod_stim=area_fraction_context_stim_mod.query('n_stim_responsive>=40 and n_sessions>=4 and not area.str.islower()').sort_values(by='any_stim',ascending=False).head(20)\n",
    "sort_by_any_context_mod_stim[['area','vis_only','aud_only','mixed']].plot.bar(ax=ax,x='area',y=['vis_only','aud_only','mixed'],stacked=True)\n",
    "ax.set_title('context modulation of stimulus responses')\n",
    "ax.set_ylabel('fraction of units modulated')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #context mod of any stimulus response\n",
    "\n",
    "# area_fraction_context_stim_mod['any_stim']=area_fraction_context_stim_mod[['vis1','vis2','sound1','sound2','mixed','both_vis','both_sound']].sum(axis=1)\n",
    "\n",
    "# fig,ax=plt.subplots(1,1,figsize=(10,4))\n",
    "\n",
    "# sort_by_any_stim_context=area_fraction_context_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='any_stim',ascending=False).head(20)\n",
    "# sort_by_any_stim_context[['area','any_stim']].plot.bar(ax=ax,x='area',y='any_stim',color='tab:blue')\n",
    "# ax.set_title('context modulation of any stimulus response')\n",
    "# ax.set_ylabel('fraction of units modulated')\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_context_stim_mod['any_stim']=area_fraction_context_stim_mod[['vis1','vis2','sound1','sound2']].sum(axis=1)\n",
    "area_fraction_context_stim_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context modulation of evoked stimulus\n",
    "fig,ax=plt.subplots(3,1,figsize=(6,8))\n",
    "#vis: vis1+vis2+both_vis\n",
    "vis_context_evoked_stim_mod=area_fraction_context_evoked_stim_mod[['vis1','vis2','both_vis']].sum(axis=1)\n",
    "area_fraction_context_evoked_stim_mod['vis_only']=vis_context_evoked_stim_mod\n",
    "sort_by_vis_context_evoked_stim=area_fraction_context_evoked_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='vis_only',ascending=False).head(10)\n",
    "sort_by_vis_context_evoked_stim[['area','vis_only']].plot.bar(ax=ax[0],x='area',y='vis_only',color='tab:blue')\n",
    "ax[0].set_title('context modulation of evoked visual stim responses')\n",
    "ax[0].set_ylabel('fraction of units modulated')\n",
    "\n",
    "#aud: sound1+sound2+both_sound\n",
    "aud_context_evoked_stim_mod=area_fraction_context_evoked_stim_mod[['sound1','sound2','both_sound']].sum(axis=1)\n",
    "area_fraction_context_evoked_stim_mod['aud_only']=aud_context_evoked_stim_mod\n",
    "sort_by_aud_context_evoked_stim=area_fraction_context_evoked_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='aud_only',ascending=False).head(10)\n",
    "sort_by_aud_context_evoked_stim[['area','aud_only']].plot.bar(ax=ax[1],x='area',y='aud_only',color='tab:orange')\n",
    "ax[1].set_title('context modulation of evoked auditory stim responses')\n",
    "ax[1].set_ylabel('fraction of units modulated')\n",
    "\n",
    "#mixed: mixed\n",
    "sort_by_mixed_context_evoked_stim=area_fraction_context_evoked_stim_mod.query('n_stim_responsive>=30 and n_sessions>=3').sort_values(by='mixed',ascending=False).head(10)\n",
    "sort_by_mixed_context_evoked_stim[['area','mixed']].plot.bar(ax=ax[2],x='area',y='mixed',color='tab:green')\n",
    "ax[2].set_title('context modulation of evoked multimodal stim responses')\n",
    "ax[2].set_ylabel('fraction of units modulated')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline vs. context modulated units\n",
    "area_fraction_stim_vs_baseline_context_mod['any_context_mod']=area_fraction_stim_vs_baseline_context_mod[['baseline','stim','both']].sum(axis=1)\n",
    "area_fraction_stim_vs_baseline_context_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline vs. context modulated units\n",
    "fig,ax=plt.subplots(3,1,figsize=(6,8))\n",
    "#baseline: baseline only\n",
    "sort_by_baseline=area_fraction_stim_vs_baseline_context_mod.query('total_n>=40 and n_sessions>=4').sort_values(by='baseline',ascending=False).head(10)\n",
    "sort_by_baseline[['area','baseline']].plot.bar(ax=ax[0],x='area',y='baseline',color='tab:orange')\n",
    "ax[0].set_title('baseline only')\n",
    "ax[0].set_ylabel('fraction of units modulated')\n",
    "\n",
    "#stim: stim only\n",
    "sort_by_stim=area_fraction_stim_vs_baseline_context_mod.query('total_n>=40 and n_sessions>=4').sort_values(by='stim',ascending=False).head(10)\n",
    "sort_by_stim[['area','stim']].plot.bar(ax=ax[1],x='area',y='stim',color='tab:blue')\n",
    "ax[1].set_title('stimulus only')\n",
    "ax[1].set_ylabel('fraction of units modulated')\n",
    "\n",
    "#both: both\n",
    "sort_by_both=area_fraction_stim_vs_baseline_context_mod.query('total_n>=40 and n_sessions>=4').sort_values(by='both',ascending=False).head(10)\n",
    "sort_by_both[['area','both']].plot.bar(ax=ax[2],x='area',y='both',color='tab:green')\n",
    "ax[2].set_title('both')\n",
    "ax[2].set_ylabel('fraction of units modulated')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked plot of baseline vs. context modulated units\n",
    "area_fraction_stim_vs_baseline_context_mod['any_context_mod']=area_fraction_stim_vs_baseline_context_mod[['baseline','stim','both']].sum(axis=1)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "sort_by_any_context_mod=area_fraction_stim_vs_baseline_context_mod.query('total_n>=40 and n_sessions>=4 and not area.str.islower()').sort_values(by='any_context_mod',ascending=False).head(20)\n",
    "\n",
    "sort_by_any_context_mod[['area','baseline','stim','both']].plot.bar(ax=ax,x='area',y=['baseline','stim','both'],stacked=True)\n",
    "ax.set_title('context modulation of baseline and/or stim')\n",
    "ax.set_ylabel('fraction of units modulated')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot baseline fractino affected vs. decoder performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare sign of context modulation of stimulus and baseline\n",
    "area_fraction_context_mod_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign of context modulation of stimulus and baseline\n",
    "fig,ax=plt.subplots(4,1,figsize=(6,10))\n",
    "#stim_pos_baseline_pos: stim up, baseline up\n",
    "sort_by_stim_pos_baseline_pos=area_fraction_context_mod_sign.query('total_n>=30 and n_sessions>=3').sort_values(by='stim_pos_baseline_pos',ascending=False).head(10)\n",
    "sort_by_stim_pos_baseline_pos[['area','stim_pos_baseline_pos']].plot.bar(ax=ax[0],x='area',y='stim_pos_baseline_pos',color='tab:blue')\n",
    "ax[0].set_title('stim up, baseline up')\n",
    "ax[0].set_ylabel('fraction of units')\n",
    "\n",
    "#stim_pos_baseline_neg: stim up, baseline down\n",
    "sort_by_stim_pos_baseline_neg=area_fraction_context_mod_sign.query('total_n>=30 and n_sessions>=3').sort_values(by='stim_pos_baseline_neg',ascending=False).head(10)\n",
    "sort_by_stim_pos_baseline_neg[['area','stim_pos_baseline_neg']].plot.bar(ax=ax[1],x='area',y='stim_pos_baseline_neg',color='tab:orange')\n",
    "ax[1].set_title('stim up, baseline down')\n",
    "ax[1].set_ylabel('fraction of units')\n",
    "\n",
    "#stim_neg_baseline_pos: stim down, baseline up\n",
    "sort_by_stim_neg_baseline_pos=area_fraction_context_mod_sign.query('total_n>=30 and n_sessions>=3').sort_values(by='stim_neg_baseline_pos',ascending=False).head(10)\n",
    "sort_by_stim_neg_baseline_pos[['area','stim_neg_baseline_pos']].plot.bar(ax=ax[2],x='area',y='stim_neg_baseline_pos',color='tab:green')\n",
    "ax[2].set_title('stim down, baseline up')\n",
    "ax[2].set_ylabel('fraction of units')\n",
    "\n",
    "#stim_neg_baseline_neg: stim down, baseline down\n",
    "sort_by_stim_neg_baseline_neg=area_fraction_context_mod_sign.query('total_n>=30 and n_sessions>=3').sort_values(by='stim_neg_baseline_neg',ascending=False).head(10)\n",
    "sort_by_stim_neg_baseline_neg[['area','stim_neg_baseline_neg']].plot.bar(ax=ax[3],x='area',y='stim_neg_baseline_neg',color='tab:red')\n",
    "ax[3].set_title('stim down, baseline down')\n",
    "ax[3].set_ylabel('fraction of units')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context mod stim responses in same vs diff directions\n",
    "\n",
    "area_fraction_context_mod_same_vs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot context mod of stim responses in same vs diff directions\n",
    "fig,ax=plt.subplots(2,1,figsize=(7,6))\n",
    "\n",
    "#same direction\n",
    "sort_by_same_dir=area_fraction_context_mod_same_vs_diff.query('total_n>=40 and n_sessions>=4 and not area.str.islower()').sort_values(by='same_dir',ascending=False).head(20)\n",
    "sort_by_same_dir[['area','same_dir']].plot.bar(ax=ax[0],x='area',y=['same_dir'],color='tab:blue')\n",
    "ax[0].set_title('context modulation of target stim responses in same direction')\n",
    "ax[0].set_ylabel('fraction of units')\n",
    "\n",
    "sort_by_diff_dir=area_fraction_context_mod_same_vs_diff.query('total_n>=40 and n_sessions>=4 and not area.str.islower()').sort_values(by='diff_dir',ascending=False).head(20)\n",
    "sort_by_diff_dir[['area','diff_dir']].plot.bar(ax=ax[1],x='area',y=['diff_dir'],color='tab:orange')\n",
    "ax[1].set_title('context modulation of target stim responses in diff directions')\n",
    "ax[1].set_ylabel('fraction of units')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context modulated vs. independent stimulus responses\n",
    "\n",
    "area_fraction_stim_context_mod_vs_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context modulated vs. independent stimulus responses\n",
    "fig,ax=plt.subplots(2,1,figsize=(10,6))\n",
    "#context_mod: context modulated\n",
    "sort_by_context_mod=area_fraction_stim_context_mod_vs_not.query('total_n>=30 and n_sessions>=3').sort_values(by='context_mod',ascending=False).head(20)\n",
    "sort_by_context_mod[['area','context_mod']].plot.bar(ax=ax[0],x='area',y='context_mod',color='tab:blue',legend=False)\n",
    "ax[0].set_title('context modulated stimulus responses')\n",
    "ax[0].set_ylabel('fraction of units')\n",
    "\n",
    "#not_context_mod: not context modulated\n",
    "sort_by_not_context_mod=area_fraction_stim_context_mod_vs_not.query('total_n>=30 and n_sessions>=3').sort_values(by='not_context_mod',ascending=False).head(20)\n",
    "sort_by_not_context_mod[['area','not_context_mod']].plot.bar(ax=ax[1],x='area',y='not_context_mod',color='tab:orange',legend=False)\n",
    "ax[1].set_title('context independent stimulus responses')\n",
    "ax[1].set_ylabel('fraction of units')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp Templeton vs. DR context modulation\n",
    "\n",
    "DR_context_mod=pd.read_csv(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\area_fraction_context_stim_lick_mod.csv\")\n",
    "Templ_context_mod=pd.read_csv(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_lick_mod.csv\")\n",
    "\n",
    "merged_context_mod=pd.merge(DR_context_mod,Templ_context_mod,on='area',suffixes=('_DR','_Templeton'))\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(10,3.5))\n",
    "sort_by_context=merged_context_mod.query('total_n_DR>=30 and n_sessions_DR>=3 and total_n_Templeton>=20 and n_sessions_Templeton>=2').sort_values(by='any_context_DR',ascending=False).head(30)\n",
    "sort_by_context[['area','any_context_DR','any_context_Templeton']].plot.bar(ax=ax,x='area')\n",
    "ax.set_ylabel('fraction context modulated units')\n",
    "ax.set_title('context modulation of units in DR vs. Templeton')\n",
    "ax.legend(['DR','Templeton'])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp Templeton vs. DR stimulus modulation\n",
    "\n",
    "DR_context_mod=pd.read_csv(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\area_fraction_context_stim_lick_mod.csv\")\n",
    "Templ_context_mod=pd.read_csv(r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\single unit metrics\\combined\\Templeton\\area_fraction_context_stim_lick_mod.csv\")\n",
    "\n",
    "merged_context_mod=pd.merge(DR_context_mod,Templ_context_mod,on='area',suffixes=('_DR','_Templeton'))\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(10,3.5))\n",
    "sort_by_context=merged_context_mod.query('total_n_DR>=20 and n_sessions_DR>=2 and total_n_Templeton>=20 and n_sessions_Templeton>=2').sort_values(by='any_stim_DR',ascending=False).head(30)\n",
    "sort_by_context[['area','any_stim_DR','any_stim_Templeton']].plot.bar(ax=ax,x='area')\n",
    "ax.set_ylabel('fraction stimulus modulated units')\n",
    "ax.set_title('stimulus modulation of units in DR vs. Templeton')\n",
    "ax.legend(['DR','Templeton'])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further examine the stim & context modulated units - pos vs negative modulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_responsive_to_stim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulus modulation by sign\n",
    "\n",
    "#stimulus:\n",
    "fig,ax=plt.subplots(3,1,figsize=(10,8))\n",
    "#vis: vis1+vis1+both_vis\n",
    "vis_pos_resp=area_fraction_responsive_to_stim[['vis1_pos','vis2_pos','both_vis_pos']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['vis_pos_only']=vis_pos_resp\n",
    "vis_neg_resp=area_fraction_responsive_to_stim[['vis1_neg','vis2_neg','both_vis_neg']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['vis_neg_only']=vis_neg_resp\n",
    "vis_resp=area_fraction_responsive_to_stim[['vis1','vis2','both_vis']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['vis_only']=vis_resp\n",
    "\n",
    "sort_by_vis=area_fraction_responsive_to_stim.query('total_n>=30 and n_sessions>=4').sort_values(by='vis_only',ascending=False).head(20)\n",
    "sort_by_vis[['area','vis_pos_only','vis_neg_only']].plot.bar(ax=ax[0],x='area',stacked=True,color=['tab:blue','lightblue'])\n",
    "ax[0].set_title('visual stimuli')\n",
    "ax[0].set_ylabel('fraction of units responsive')\n",
    "ax[0].legend(['positive','negative'])\n",
    "\n",
    "#aud: sound1+sound2+both_sound\n",
    "aud_pos_resp=area_fraction_responsive_to_stim[['sound1_pos','sound2_pos','both_sound_pos']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['aud_pos_only']=aud_pos_resp\n",
    "aud_neg_resp=area_fraction_responsive_to_stim[['sound1_neg','sound2_neg','both_sound_neg']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['aud_neg_only']=aud_neg_resp\n",
    "aud_resp=area_fraction_responsive_to_stim[['sound1','sound2','both_sound']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['aud_only']=aud_resp\n",
    "\n",
    "sort_by_aud=area_fraction_responsive_to_stim.query('total_n>=30 and n_sessions>=4').sort_values(by='aud_only',ascending=False).head(20)\n",
    "sort_by_aud[['area','aud_pos_only','aud_neg_only']].plot.bar(ax=ax[1],x='area',stacked=True,color=['tab:orange','bisque'])\n",
    "ax[1].set_title('auditory stimuli')\n",
    "ax[1].set_ylabel('fraction of units responsive')\n",
    "ax[1].legend(['positive','negative'])\n",
    "\n",
    "#mixed: mixed\n",
    "mixed_pos_resp=area_fraction_responsive_to_stim[['mixed_pos']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['mixed_pos_only']=mixed_pos_resp\n",
    "mixed_neg_resp=area_fraction_responsive_to_stim[['mixed_neg']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['mixed_neg_only']=mixed_neg_resp\n",
    "mixed_resp=area_fraction_responsive_to_stim[['mixed']].sum(axis=1)\n",
    "area_fraction_responsive_to_stim['mixed_only']=mixed_resp\n",
    "\n",
    "sort_by_mixed=area_fraction_responsive_to_stim.query('total_n>=30 and n_sessions>=4').sort_values(by='mixed',ascending=False).head(20)\n",
    "sort_by_mixed[['area','mixed_pos_only','mixed_neg_only']].plot.bar(ax=ax[2],x='area',stacked=True,color=['tab:green','lightgreen'])\n",
    "ax[2].set_title('multimodal')\n",
    "ax[2].set_ylabel('fraction of units responsive')\n",
    "ax[2].legend(['positive','negative'])\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive vs. negative lick, context, stim modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fraction_context_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lick/context/stim:\n",
    "fig,ax=plt.subplots(3,1,figsize=(10,8))\n",
    "#lick: any lick\n",
    "sort_by_lick=area_fraction_context_mod.query('total_n>=50 and n_sessions>=4').sort_values(by='any_lick',ascending=False).head(20)\n",
    "sort_by_lick[['area','any_lick_pos','any_lick_neg']].plot.bar(ax=ax[0],x='area',color=['tab:purple','thistle'],stacked=True)\n",
    "ax[0].set_title('most lick modulated areas')\n",
    "ax[0].set_ylabel('fraction of units responsive')\n",
    "ax[0].legend(['positive','negative'])\n",
    "\n",
    "#context: any context\n",
    "sort_by_context=area_fraction_context_mod.query('total_n>=50 and n_sessions>=4').sort_values(by='any_context',ascending=False).head(20)\n",
    "sort_by_context[['area','any_context_pos','any_context_neg']].plot.bar(ax=ax[1],x='area',color=['tab:brown','tan'],stacked=True)\n",
    "ax[1].set_title('most context modulated areas')\n",
    "ax[1].set_ylabel('fraction of units responsive')\n",
    "ax[1].legend(['positive','negative'])\n",
    "\n",
    "#stim: any stim\n",
    "sort_by_stim=area_fraction_context_mod.query('total_n>=50 and n_sessions>=4').sort_values(by='any_stim',ascending=False).head(20)\n",
    "sort_by_stim[['area','any_stim_pos','any_stim_neg']].plot.bar(ax=ax[2],x='area',color=['tab:blue','lightblue'],stacked=True)\n",
    "ax[2].set_title('most stimulus modulated areas')\n",
    "ax[2].set_ylabel('fraction of units responsive')\n",
    "ax[2].legend(['positive','negative'])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked barplots for selected areas\n",
    "\n",
    "area_fraction_context_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels=['stimulus only','stimulus and context','context only',\n",
    "#         'context and lick','lick only', 'lick & stimulus & context',\n",
    "#          'lick and stimulus',  'none']\n",
    "labels=['only_stim','stim_and_context','only_context','lick_and_context',\n",
    "        'only_lick','lick_and_stim','lick_and_stim_and_context','none']\n",
    "sizes=np.array([len(only_stim_resp),len(stim_and_context_resp),len(context_resp),\n",
    "                len(lick_and_context_resp),len(lick_resp),len(all_resp),\n",
    "                len(lick_and_stim_resp), len(neither_stim_nor_context_resp)])\n",
    "sizes=sizes/np.sum(sizes)\n",
    "\n",
    "all_df=pd.DataFrame(columns=['area']+labels)\n",
    "\n",
    "all_df.loc[0,0]='all'\n",
    "for x in range(len(sizes)):\n",
    "    all_df.iloc[0,x]=sizes[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdrcorrection(all_data['vis1_stimulus_modulation_p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use adj pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins=np.arange(-1,1.1,0.1)\n",
    "fig,ax=plt.subplots(2,1)\n",
    "\n",
    "dr_good_unit_ids=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(\"DynamicRouting\")')['unit_id'].values\n",
    "\n",
    "templ_good_unit_ids=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                   isi_violations_ratio<=0.1 and \\\n",
    "                                   amplitude_cutoff<=0.1 and \\\n",
    "                                   project.str.contains(\"Templeton\")')['unit_id'].values\n",
    "\n",
    "ax[0].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and unit_id in @dr_good_unit_ids')['vis1_evoked_context_modulation_index'],bins=xbins,alpha=0.5,label='evoked')\n",
    "ax[0].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and unit_id in @dr_good_unit_ids')['vis1_context_modulation_index'],bins=xbins,alpha=0.5,label='raw')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Dynamic Routing units')\n",
    "\n",
    "ax[1].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and unit_id in @templ_good_unit_ids')['vis1_evoked_context_modulation_index'],bins=xbins,alpha=0.5,label='evoked')\n",
    "ax[1].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and unit_id in @templ_good_unit_ids')['vis1_context_modulation_index'],bins=xbins,alpha=0.5,label='raw')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Templeton units')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins=np.arange(-1,1.1,0.1)\n",
    "\n",
    "fig,ax=plt.subplots(2,1)\n",
    "\n",
    "dr_good_unit_ids=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(\"DynamicRouting\")')['unit_id'].values\n",
    "\n",
    "templ_good_unit_ids=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                   isi_violations_ratio<=0.1 and \\\n",
    "                                   amplitude_cutoff<=0.1 and \\\n",
    "                                   project.str.contains(\"Templeton\")')['unit_id'].values\n",
    "\n",
    "ax[0].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_evoked_context_modulation_p_value<0.01 and unit_id in @dr_good_unit_ids')['vis1_evoked_context_modulation_index'],bins=xbins,alpha=0.5,label='evoked')\n",
    "ax[0].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_context_modulation_p_value<0.01 and unit_id in @dr_good_unit_ids')['vis1_context_modulation_index'],bins=xbins,alpha=0.5,label='raw')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Dynamic Routing units')\n",
    "\n",
    "ax[1].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_evoked_context_modulation_p_value<0.01 and unit_id in @templ_good_unit_ids')['vis1_evoked_context_modulation_index'],bins=xbins,alpha=0.5,label='evoked')\n",
    "ax[1].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_context_modulation_p_value<0.01 and unit_id in @templ_good_unit_ids')['vis1_context_modulation_index'],bins=xbins,alpha=0.5,label='raw')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Templeton units')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins=np.arange(-5,5.25,0.25)\n",
    "\n",
    "fig,ax=plt.subplots(2,1)\n",
    "\n",
    "dr_good_unit_ids=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                isi_violations_ratio<=0.1 and \\\n",
    "                                amplitude_cutoff<=0.1 and \\\n",
    "                                project.str.contains(\"DynamicRouting\")')['unit_id'].values\n",
    "\n",
    "templ_good_unit_ids=all_data.query('presence_ratio>=0.99 and \\\n",
    "                                   isi_violations_ratio<=0.1 and \\\n",
    "                                   amplitude_cutoff<=0.1 and \\\n",
    "                                   project.str.contains(\"Templeton\")')['unit_id'].values\n",
    "\n",
    "ax[0].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_evoked_context_modulation_p_value<0.01 and unit_id in @dr_good_unit_ids')['vis1_evoked_context_modulation_zscore'],bins=xbins,alpha=0.5,label='evoked')\n",
    "ax[0].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_context_modulation_p_value<0.01 and unit_id in @dr_good_unit_ids')['vis1_context_modulation_zscore'],bins=xbins,alpha=0.5,label='raw')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Dynamic Routing units')\n",
    "\n",
    "ax[1].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_evoked_context_modulation_p_value<0.01 and unit_id in @templ_good_unit_ids')['vis1_evoked_context_modulation_zscore'],bins=xbins,alpha=0.5,label='evoked')\n",
    "ax[1].hist(all_data.query('vis1_stimulus_modulation_p_value<0.01 and vis1_context_modulation_p_value<0.01 and unit_id in @templ_good_unit_ids')['vis1_context_modulation_zscore'],bins=xbins,alpha=0.5,label='raw')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Templeton units')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of distribution across areas - DR\n",
    "\n",
    "all_areas=all_data['structure'].unique()\n",
    "stim_names=['vis1','vis2','sound1','sound2','catch']\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in stim_names:\n",
    "    fig,ax=plt.subplots(figsize=(10,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=all_data.query('structure==@aa and \\\n",
    "                                    presence_ratio>=0.99 and \\\n",
    "                                    isi_violations_ratio<=0.1 and \\\n",
    "                                    amplitude_cutoff<=0.1 and \\\n",
    "                                    project.str.contains(\"DynamicRouting\")')['unit_id']\n",
    "                            #    peak_to_valley>0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        context_mod_values=all_data.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_zscore'].values\n",
    "        if len(context_mod_values)==0:\n",
    "            continue\n",
    "        context_mod_values=np.hstack(context_mod_values)\n",
    "        context_mod_values=context_mod_values[~np.isnan(context_mod_values)]\n",
    "        #plot distribution\n",
    "        ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('context modulation index')\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_mod_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of units above some threshold of context modulation (both directions?)\n",
    "\n",
    "# threshold value\n",
    "threshold=0.5\n",
    "\n",
    "all_areas=all_data['structure'].unique()\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in trials['stim_name'].unique():\n",
    "    fig,ax=plt.subplots(figsize=(10,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=all_data.query('structure==@aa and \\\n",
    "                               presence_ratio>=0.99 and \\\n",
    "                               isi_violations_ratio<=0.1 and \\\n",
    "                               amplitude_cutoff<=0.1 and \\\n",
    "                                  project.str.contains(\"DynamicRouting\")')['unit_id']\n",
    "                               #peak_to_valley<0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        context_mod_values=all_data.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_index'].values\n",
    "        context_mod_values=context_mod_values[~np.isnan(context_mod_values)]\n",
    "\n",
    "        pos_fraction=np.sum(context_mod_values>=threshold)/len(context_mod_values)\n",
    "        neg_fraction=np.sum(context_mod_values<=-threshold)/len(context_mod_values)\n",
    "\n",
    "        #plot distribution\n",
    "        # ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "        ax.bar(counter,pos_fraction,color='tab:green')\n",
    "        ax.bar(counter,-neg_fraction,color='tab:blue')\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('fraction context mod above +/-'+str(threshold))\n",
    "    ax.set_ylim([-1.05,1.05])\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of units significantly modulated by context\n",
    "\n",
    "# threshold value\n",
    "sig_threshold=0.01\n",
    "\n",
    "all_areas=all_data['structure'].unique()\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in trials['stim_name'].unique():\n",
    "    fig,ax=plt.subplots(figsize=(15,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=all_data.query('structure==@aa and \\\n",
    "                               presence_ratio>=0.99 and \\\n",
    "                               isi_violations_ratio<=0.1 and \\\n",
    "                               amplitude_cutoff<=0.1 and \\\n",
    "                                    project.str.contains(\"Templeton\")')['unit_id']\n",
    "                            #    peak_to_valley>0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        context_mod_values=all_data.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_p_value'].values\n",
    "        # context_mod_values=stim_context_modulation_df.query('unit_id in @area_units')[ss+'_stimulus_modulation_p_value'].values\n",
    "        context_mod_values=context_mod_values[~np.isnan(context_mod_values)]\n",
    "\n",
    "        sig_fraction=np.sum(context_mod_values<threshold)/len(context_mod_values)\n",
    "\n",
    "        #plot distribution\n",
    "        # ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "        ax.bar(counter,sig_fraction,color='tab:green')\n",
    "        # ax.bar(counter,-neg_fraction,color='tab:blue')\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('fraction significantly modulated by context')\n",
    "    ax.set_ylim([0,1.05])\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of units significantly modulated by context\n",
    "\n",
    "# threshold value\n",
    "sig_threshold=0.01\n",
    "\n",
    "all_areas=all_data['structure'].unique()\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in trials['stim_name'].unique():\n",
    "    fig,ax=plt.subplots(figsize=(10,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=all_data.query('structure==@aa and \\\n",
    "                               presence_ratio>=0.99 and \\\n",
    "                               isi_violations_ratio<=0.1 and \\\n",
    "                               amplitude_cutoff<=0.1 and \\\n",
    "                                    project.str.contains(\"DynamicRouting\")')['unit_id']\n",
    "                            #    peak_to_valley>0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        # context_mod_values=all_data.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_p_value'].values\n",
    "        stim_mod_values=all_data.query('unit_id in @area_units')[ss+'_stimulus_modulation_p_value'].values\n",
    "        stim_mod_values=stim_mod_values[~np.isnan(stim_mod_values)]\n",
    "\n",
    "        sig_fraction=np.sum(stim_mod_values<threshold)/len(stim_mod_values)\n",
    "\n",
    "        #plot distribution\n",
    "        # ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "        ax.bar(counter,sig_fraction,color='tab:green')\n",
    "        # ax.bar(counter,-neg_fraction,color='tab:blue')\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('fraction significantly modulated by stimulus')\n",
    "    ax.set_ylim([0,1.05])\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###only include areas with at least 10 units in each of 3 recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "good_unit_ids=units.query('presence_ratio>=0.99 and \\\n",
    "                            isi_violations_ratio<=0.1 and \\\n",
    "                            amplitude_cutoff<=0.1')['unit_id'].values\n",
    "\n",
    "ax.hist(stim_context_modulation_df.query('vis1_stimulus_modulation_p_value<0.01 and unit_id in @good_unit_ids')['vis1_evoked_context_modulation_index'],bins=20,alpha=0.5,label='evoked')\n",
    "ax.hist(stim_context_modulation_df.query('vis1_stimulus_modulation_p_value<0.01 and unit_id in @good_unit_ids')['vis1_context_modulation_index'],bins=20,alpha=0.5,label='raw')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot actual distributions across areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units['peak_to_valley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of distribution across areas\n",
    "\n",
    "all_areas=units['structure'].unique()\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in trials['stim_name'].unique():\n",
    "    fig,ax=plt.subplots(figsize=(10,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=units.query('structure==@aa and \\\n",
    "                               presence_ratio>=0.99 and \\\n",
    "                               isi_violations_ratio<=0.1 and \\\n",
    "                               amplitude_cutoff<=0.1')['unit_id']# and \\\n",
    "                            #    peak_to_valley>0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        context_mod_values=stim_context_modulation_df.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_index'].values\n",
    "        context_mod_values=context_mod_values[~np.isnan(context_mod_values)]\n",
    "        #plot distribution\n",
    "        ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('context modulation index')\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_mod_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of units above some threshold of context modulation (both directions?)\n",
    "\n",
    "# threshold value\n",
    "threshold=0.5\n",
    "\n",
    "all_areas=units['structure'].unique()\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in trials['stim_name'].unique():\n",
    "    fig,ax=plt.subplots(figsize=(10,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=units.query('structure==@aa and \\\n",
    "                               presence_ratio>=0.99 and \\\n",
    "                               isi_violations_ratio<=0.1 and \\\n",
    "                               amplitude_cutoff<=0.1 and \\\n",
    "                               peak_to_valley<0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        context_mod_values=stim_context_modulation_df.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_index'].values\n",
    "        context_mod_values=context_mod_values[~np.isnan(context_mod_values)]\n",
    "\n",
    "        pos_fraction=np.sum(context_mod_values>=threshold)/len(context_mod_values)\n",
    "        neg_fraction=np.sum(context_mod_values<=-threshold)/len(context_mod_values)\n",
    "\n",
    "        #plot distribution\n",
    "        # ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "        ax.bar(counter,pos_fraction,color='tab:green')\n",
    "        ax.bar(counter,-neg_fraction,color='tab:blue')\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('fraction context mod above +/-'+str(threshold))\n",
    "    ax.set_ylim([-1.05,1.05])\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units['structure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of units significantly modulated by context\n",
    "\n",
    "# threshold value\n",
    "sig_threshold=0.01\n",
    "\n",
    "all_areas=units['structure'].unique()\n",
    "\n",
    "#loop through stimuli\n",
    "for ss in trials['stim_name'].unique():\n",
    "    fig,ax=plt.subplots(figsize=(10,4))\n",
    "    ax.axhline(0,color='black',linestyle='--')\n",
    "    #loop through unique areas\n",
    "    for counter,aa in enumerate(all_areas):\n",
    "        \n",
    "        #get unit ids in this area\n",
    "        area_units=units.query('structure==@aa and \\\n",
    "                               presence_ratio>=0.99 and \\\n",
    "                               isi_violations_ratio<=0.1 and \\\n",
    "                               amplitude_cutoff<=0.1')['unit_id']# and \\\n",
    "                            #    peak_to_valley>0.0004')['unit_id']\n",
    "        #get context modulation values for these units\n",
    "        stim_p_val_str=ss+'_stimulus_modulation_p_value'\n",
    "        context_mod_values=stim_context_modulation_df.query('unit_id in @area_units and '+stim_p_val_str+'<0.01')[ss+'_evoked_context_modulation_p_value'].values\n",
    "        # context_mod_values=stim_context_modulation_df.query('unit_id in @area_units')[ss+'_stimulus_modulation_p_value'].values\n",
    "        context_mod_values=context_mod_values[~np.isnan(context_mod_values)]\n",
    "\n",
    "        sig_fraction=np.sum(context_mod_values<threshold)/len(context_mod_values)\n",
    "\n",
    "        #plot distribution\n",
    "        # ax.boxplot(context_mod_values,positions=[counter],showfliers=False)\n",
    "        ax.bar(counter,sig_fraction,color='tab:green')\n",
    "        # ax.bar(counter,-neg_fraction,color='tab:blue')\n",
    "\n",
    "    ax.set_xticks(range(len(all_areas)))\n",
    "    ax.set_xticklabels(all_areas,rotation=90)\n",
    "    ax.set_ylabel('fraction significantly modulated by context')\n",
    "    ax.set_ylim([0,1.05])\n",
    "    ax.set_title('stim_name: '+ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins=np.arange(0,1,0.01)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "ax.hist(adj_pvals['context_roc_auc'],bins=xbins)\n",
    "# ax.hist(adj_pvals['lick_roc_auc'],bins=xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins=np.arange(0,1,0.01)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "ax.hist(adj_pvals['context_roc_auc'],bins=xbins)\n",
    "# ax.hist(adj_pvals['vis1_context_roc_auc'],bins=xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_auc_vals=adj_pvals.query('context_roc_auc<=0.4 or context_roc_auc>=0.6')['structure'].value_counts()\n",
    "total_ns=adj_pvals['structure'].value_counts()\n",
    "\n",
    "fraction_high_auc=(high_auc_vals/total_ns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "fraction_high_auc.head(50).plot.bar(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_auc_vals=adj_pvals.query('vis1_context_roc_auc<=0.4 or vis1_context_roc_auc>=0.6')['structure'].value_counts()\n",
    "total_ns=adj_pvals['structure'].value_counts()\n",
    "\n",
    "fraction_high_auc=(high_auc_vals/total_ns).sort_values(ascending=False)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "fraction_high_auc.head(50).plot.bar(ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urchin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
