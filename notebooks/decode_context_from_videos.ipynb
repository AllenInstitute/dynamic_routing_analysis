{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sg\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import ast\n",
    "from sklearn import svm\n",
    "import glob\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import npc_lims\n",
    "from npc_sessions import DynamicRoutingSession\n",
    "from dynamic_routing_analysis import spike_utils, decoding_utils\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all this to work with npc_sessions framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\npc_analysis\\Lib\\site-packages\\npc_lims\\metadata\\codeocean.py:150: UserWarning: There is more than one asset for session = '686176_2023-12-06'. Defaulting to most recent: ('ecephys_686176_2023-12-06_13-03-34', 'ecephys_686176_2023-12-06_13-03-34')\n",
      "  warnings.warn(\n",
      "c:\\Anaconda3\\envs\\npc_analysis\\Lib\\site-packages\\npc_lims\\metadata\\codeocean.py:150: UserWarning: There is more than one asset for session = '664851_2023-11-14'. Defaulting to most recent: ('ecephys_664851_2023-11-14_12-44-33', 'ecephys_664851_2023-11-14_12-44-33')\n",
      "  warnings.warn(\n",
      "c:\\Anaconda3\\envs\\npc_analysis\\Lib\\site-packages\\npc_lims\\metadata\\codeocean.py:150: UserWarning: There is more than one asset for session = '644866_2023-02-08'. Defaulting to most recent: ('ecephys_644866_2023-02-08_16-01-11', 'ecephys_644866_2023-02-08_16-01-11')\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "all_ephys_sessions = tuple(s for s in npc_lims.get_session_info(is_ephys=True) \n",
    "                            if s.is_uploaded and s.is_annotated and \n",
    "                            (s.project=='TempletonPilotSession' or s.project=='DynamicRouting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=np.load(r\"\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\average video frames and motion\\behavior\\620263_2022-07-26_0_trial_avg_frames.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trial_avg_pixels_motion(session,session_info,vid_angle):\n",
    "\n",
    "    if 'Templeton' in session_info.project:\n",
    "        main_vid_path=r'\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\average video frames and motion'\n",
    "    elif 'DynamicRouting' in session_info.project:\n",
    "        main_vid_path=r'\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\Ethan\\average video frames and motion'\n",
    "\n",
    "    if vid_angle.lower()=='face':\n",
    "        avg_frames_path=os.path.join(main_vid_path,'face')\n",
    "    elif vid_angle.lower()=='behavior':\n",
    "        avg_frames_path=os.path.join(main_vid_path,'behavior')\n",
    "    \n",
    "    frames_file=glob.glob(os.path.join(avg_frames_path,session.id+'*'))\n",
    "    \n",
    "    if len(frames_file)==0:\n",
    "        return [],[]\n",
    "    else:\n",
    "        frames_file=frames_file[0]\n",
    "    \n",
    "    frames=np.load(frames_file)\n",
    "    \n",
    "    return frames['avg_prestim_frames'], frames['avg_prestim_motion']\n",
    "\n",
    "\n",
    "# def custom_decoder(input_data,labels):\n",
    "    \n",
    "#     output={}\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "    \n",
    "#     scaler.fit(input_data)\n",
    "#     X = scaler.transform(input_data)\n",
    "#     y = labels\n",
    "    \n",
    "#     if len(np.unique(labels))>2:\n",
    "#         y_dec_func=np.full((len(y),len(np.unique(labels))), fill_value=np.nan)\n",
    "#     else:\n",
    "#         y_dec_func=np.full(len(y), fill_value=np.nan)\n",
    " \n",
    "#     if type(y[0])==bool:\n",
    "#         ypred=np.full(len(y), fill_value=False)\n",
    "#     elif type(y[0])==str:\n",
    "#         ypred=np.full(len(y), fill_value='       ')\n",
    "#     else:\n",
    "#         ypred=np.full(len(y), fill_value=np.nan)\n",
    "\n",
    "#     tidx_used=[]\n",
    "    \n",
    "#     coefs=[]\n",
    "#     classes=[]\n",
    "# #     feature_names=[]\n",
    "#     intercept=[]\n",
    "#     params=[]\n",
    "\n",
    "#     for train,test in skf.split(X, y):\n",
    "#         clf=svm.LinearSVC(max_iter=5000)\n",
    "#         clf.fit(X[train],y[train])\n",
    "#         ypred[test] = clf.predict(X[test])\n",
    "#         y_dec_func[test] = clf.decision_function(X[test])\n",
    "#         tidx_used.append([test])\n",
    "#         coefs.append(clf.coef_)\n",
    "#         classes.append(clf.classes_)\n",
    "# #         feature_names.append(clf.feature_names_in_)\n",
    "#         intercept.append(clf.intercept_)\n",
    "#         params.append(clf.get_params())\n",
    "\n",
    "#     cr_dict=classification_report(y, ypred, output_dict=True)\n",
    "#     cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "#     output['cr']=cr_df\n",
    "#     output['pred_label']=ypred\n",
    "#     output['true_label']=y\n",
    "#     # output['trial_sel_idx']=trial_sel\n",
    "#     output['trials_used']=tidx_used\n",
    "#     output['decision_function']=y_dec_func\n",
    "#     output['coefs']=coefs\n",
    "#     output['classes']=classes\n",
    "# #     output['feature_names']=feature_names\n",
    "#     output['intercept']=intercept\n",
    "#     output['params']=params\n",
    "    \n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620263_2022-07-26\n",
      "frame data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\npc_analysis\\Lib\\site-packages\\numcodecs\\abc.py:107: UserWarning: Multi-threading is supported for wavpack version>=5.6.4, but current version is 5.5.0. Parallel decoding will not be available.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialSoundArray empty; regenerating sound arrays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aligning sound waveforms: 100%|████████████| 673/673 [02:07<00:00,  5.29trial/s]\n"
     ]
    }
   ],
   "source": [
    "savepath=r'\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\decoding results\\use_raw_video'\n",
    "filename='use_raw_video.pkl'\n",
    "\n",
    "vid_angle='behavior'\n",
    "trnum='all'\n",
    "# f_num=500\n",
    "# f_min=500\n",
    "n_repeats=1\n",
    "binsize=0.2\n",
    "time_bins=np.arange(-0.2,0,binsize)\n",
    "balance_labels=False\n",
    "# keep_n_SVDs=500\n",
    "n_block_repeats=100\n",
    "crossval='5_fold'\n",
    "crossval_index=None\n",
    "labels_as_index=True\n",
    "\n",
    "block_multipliers=[1,2,3,4,5,10]\n",
    "\n",
    "# svc_results={}\n",
    "\n",
    "for sel_session in all_ephys_sessions[-1:]:\n",
    "    \n",
    "    svc_results={}\n",
    "    \n",
    "    session=DynamicRoutingSession(sel_session)\n",
    "    session_info=npc_lims.get_session_info(sel_session)\n",
    "    print(session_info.id)\n",
    "\n",
    "    if session_info.project=='TempletonPilotSession':\n",
    "        generate_labels=True\n",
    "    else:\n",
    "        generate_labels=False\n",
    "\n",
    "    mean_trial_frames,mean_trial_motion = load_trial_avg_pixels_motion(session,session_info,vid_angle)\n",
    "    if len(mean_trial_frames)==0:\n",
    "        print('no frame data, skipping experiment')\n",
    "        continue\n",
    "    print('frame data loaded')\n",
    "    \n",
    "    #mean_trial_behav_SVD[feature, trial]\n",
    "    \n",
    "    #try using running alone, motion alone, SVDs, or all of them\n",
    "    \n",
    "    #save metadata about this session & decoder params\n",
    "    svc_results['metadata']=session_info\n",
    "    svc_results['trial_numbers']=trnum\n",
    "    svc_results['n_repeats']=n_repeats\n",
    "    svc_results['time_bins']=time_bins\n",
    "    svc_results['balance_labels']=balance_labels\n",
    "\n",
    "    predict=['block_ids']\n",
    "    p=predict[0]\n",
    "\n",
    "    if p=='block_ids':\n",
    "        #exclude any trials that had opto stimulation\n",
    "        if 'opto_power' in session.trials[:].columns:\n",
    "            trial_sel = session.trials[:].query('opto_power.isnull() and trial_index_in_block>=5').index\n",
    "        else:\n",
    "            trial_sel = session.trials[:].index\n",
    "\n",
    "    for block_multiplier in block_multipliers:\n",
    "        svc_results[block_multiplier]={}\n",
    "\n",
    "        block_context_names=np.array(['vis','aud'])\n",
    "        start_time=session.trials[:]['start_time'].iloc[0]\n",
    "        context=np.full(len(session.trials[:]), fill_value='nan')\n",
    "        block_nums=np.full(len(session.trials[:]), fill_value=np.nan)\n",
    "\n",
    "        # make \"real\" subdivided blocks\n",
    "        if session_info.project=='TempletonPilotSession':    \n",
    "            if np.random.choice(block_context_names,1)=='vis':\n",
    "                block_context_index=([0]*block_multiplier+[1]*block_multiplier)*3\n",
    "            #elif np.random.choice(block_context_names,1)=='aud': #sometimes this if & elif aren't reached, IDK why\n",
    "            else:\n",
    "                block_context_index=([1]*block_multiplier+[0]*block_multiplier)*3\n",
    "            block_contexts=block_context_names[block_context_index]\n",
    "            for block in range(0,6*block_multiplier):\n",
    "                block_start_time=start_time+block*(10/block_multiplier)*60\n",
    "                block_end_time=start_time+(block+1)*(10/block_multiplier)*60\n",
    "                block_trials=session.trials[:].query('start_time>=@block_start_time').index\n",
    "                context[block_trials]=block_contexts[block]\n",
    "                block_nums[block_trials]=block\n",
    "            block_index=block_nums[trial_sel]\n",
    "            pred_var=context[trial_sel]\n",
    "            \n",
    "        elif session_info.project=='DynamicRouting':\n",
    "            if session.trials[:]['context_name'].iloc[0]=='vis':\n",
    "                block_context_index=([0]*block_multiplier+[1]*block_multiplier)*3\n",
    "            elif session.trials[:]['context_name'].iloc[0]=='aud':\n",
    "                block_context_index=([1]*block_multiplier+[0]*block_multiplier)*3\n",
    "            block_contexts=block_context_names[block_context_index]\n",
    "            for block in range(0,6*block_multiplier):\n",
    "                block_start_time=start_time+block*(10/block_multiplier)*60\n",
    "                block_end_time=start_time+(block+1)*(10/block_multiplier)*60\n",
    "                block_trials=session.trials[:].query('start_time>=@block_start_time').index\n",
    "                context[block_trials]=block_contexts[block]\n",
    "                block_nums[block_trials]=block\n",
    "            block_index=block_nums[trial_sel]\n",
    "            pred_var=context[trial_sel]\n",
    "            # pred_var = session.trials[:]['context_name'][trial_sel].values\n",
    "\n",
    "        #make psuedo blocks\n",
    "        start_time=session.trials[:]['start_time'].iloc[0]\n",
    "        fake_context=np.full(len(session.trials[:]), fill_value='nan')\n",
    "        fake_block_nums=np.full(len(session.trials[:]), fill_value=np.nan)\n",
    "        blocks=np.array([0,1]*3*block_multiplier)\n",
    "        block_context_names=['vis','aud']\n",
    "\n",
    "        block_index_pseudo=[]\n",
    "        pred_var_pseudo=[]\n",
    "\n",
    "        for nn in range(0,n_block_repeats):\n",
    "            block_contexts=np.random.choice(blocks,len(blocks),replace=False)\n",
    "            for block in range(0,6*block_multiplier):\n",
    "                block_start_time=start_time+block*(10/block_multiplier)*60\n",
    "                block_end_time=start_time+(block+1)*(10/block_multiplier)*60\n",
    "                block_trials=session.trials[:].query('start_time>=@block_start_time').index\n",
    "                fake_context[block_trials]=block_context_names[block_contexts[block]]\n",
    "                fake_block_nums[block_trials]=block\n",
    "            block_index_pseudo.append(fake_block_nums[trial_sel])\n",
    "            pred_var_pseudo.append(fake_context[trial_sel])\n",
    "\n",
    "        svc_results[block_multiplier]['block_index']=block_index\n",
    "        svc_results[block_multiplier]['pred_var']=pred_var\n",
    "        svc_results[block_multiplier]['block_index_pseudo']=block_index_pseudo\n",
    "        svc_results[block_multiplier]['pred_var_pseudo']=pred_var_pseudo\n",
    "        \n",
    "        #loop through different ROIs\n",
    "        for vid_type in ['frames','motion']:\n",
    "            svc_results[block_multiplier][vid_type]={}\n",
    "            if vid_type=='frames':\n",
    "                vid_data=mean_trial_frames\n",
    "            elif vid_type=='motion':\n",
    "                vid_data=mean_trial_motion\n",
    "            \n",
    "            #loop through different labels to predict    \n",
    "            # for p in predict:\n",
    "            svc_results[block_multiplier][vid_type][p]={}\n",
    "\n",
    "            # # or, use block IDs\n",
    "            # if generate_labels == False:\n",
    "            #     pred_var = session.trials[:]['context_name'][trial_sel].values\n",
    "            # else:\n",
    "            #     start_time=session.trials[:]['start_time'].iloc[0]\n",
    "            #     fake_context=np.full(len(session.trials[:]), fill_value='nan')\n",
    "            #     fake_block_nums=np.full(len(session.trials[:]), fill_value=np.nan)\n",
    "            #     block_contexts=['vis','aud','vis','aud','vis','aud']\n",
    "            #     for block in range(0,6):\n",
    "            #         block_start_time=start_time+block*10*60\n",
    "            #         block_end_time=start_time+(block+1)*10*60\n",
    "            #         block_trials=session.trials[:].query('start_time>=@block_start_time').index\n",
    "            #         fake_context[block_trials]=block_contexts[block]\n",
    "            #         fake_block_nums[block_trials]=block\n",
    "            #     fake_block_index=fake_block_nums[trial_sel]\n",
    "            #     pred_var=fake_context[trial_sel]\n",
    "\n",
    "            \n",
    "            feature_sel = np.arange(0,vid_data.shape[0]*vid_data.shape[1])\n",
    "\n",
    "            svc_results[block_multiplier][vid_type][p]['n_features']=len(feature_sel)\n",
    "\n",
    "            #loop through time bins\n",
    "            for tt,t_start in enumerate(time_bins):\n",
    "\n",
    "                svc_results[block_multiplier][vid_type][p][tt]={}\n",
    "\n",
    "                #loop through repeats\n",
    "                for nn in range(0,n_repeats):\n",
    "                    \n",
    "                    #could select a subset of features here\n",
    "                    feature_subset = feature_sel\n",
    "\n",
    "                    #option to balance number of labels for training\n",
    "                    if balance_labels:\n",
    "                        subset_ind=[]\n",
    "                        conds = np.unique(pred_var)\n",
    "                        cond_count=[]\n",
    "\n",
    "                        if trnum=='all':\n",
    "                            for cc in conds:\n",
    "                                cond_count.append(np.sum(pred_var==cc))\n",
    "                            use_trnum=np.min(cond_count)\n",
    "                        else:\n",
    "                            use_trnum = trnum\n",
    "\n",
    "                        for cc in conds:\n",
    "                            cond_inds=np.where(pred_var==cc)[0]\n",
    "                            if len(cond_inds)<use_trnum:\n",
    "                                use_trnum=len(cond_inds)\n",
    "                            subset_ind.append(np.random.choice(cond_inds,use_trnum,replace=False))   \n",
    "                        subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "                    else:\n",
    "                        subset_ind=np.arange(0,len(trial_sel))\n",
    "\n",
    "\n",
    "                    input_data = vid_data[:,:,subset_ind].reshape(\n",
    "                        vid_data.shape[0]*vid_data.shape[1],len(subset_ind)).T\n",
    "                    labels=pred_var[subset_ind].flatten()\n",
    "\n",
    "                    if np.sum(np.isnan(input_data))>0:\n",
    "                        continue\n",
    "\n",
    "                    # svc_results[vid_type][p][tt][nn]=custom_decoder(\n",
    "                    #     input_data=sel_data,\n",
    "                    #     labels=pred_var[subset_ind].flatten())\n",
    "\n",
    "                    # svc_results[vid_type][p][tt][nn]['shuffle']=custom_decoder(\n",
    "                    #     input_data=sel_data,\n",
    "                    #     labels=np.random.choice(pred_var[subset_ind],len(pred_var),replace=False).flatten())\n",
    "\n",
    "                    # svc_results[block_multiplier][vid_type][p][tt][nn]=decoding_utils.linearSVC_decoder(\n",
    "                    #             input_data=sel_data,\n",
    "                    #             labels=pred_var[subset_ind].flatten(),\n",
    "                    #             crossval=crossval,\n",
    "                    #             crossval_index=crossval_index,\n",
    "                    #             labels_as_index=labels_as_index)\n",
    "                    svc_results[block_multiplier][vid_type][p][tt]['real']={}\n",
    "                    svc_results[block_multiplier][vid_type][p][tt]['pseudo']={}\n",
    "                    for bb in range(0,n_block_repeats):\n",
    "                            \n",
    "                        svc_results[block_multiplier][vid_type][p][tt]['real'][bb]=decoding_utils.linearSVC_decoder(\n",
    "                        input_data=input_data,\n",
    "                        labels=labels,\n",
    "                        crossval=crossval,\n",
    "                        crossval_index=crossval_index,\n",
    "                        labels_as_index=labels_as_index\n",
    "                        )\n",
    "                        \n",
    "                        temp_block_index=block_index_pseudo[bb]\n",
    "                        temp_pred_var=pred_var_pseudo[bb][subset_ind]\n",
    "                        if crossval=='blockwise':\n",
    "                            pseudo_crossval_index=temp_block_index\n",
    "                        else:\n",
    "                            pseudo_crossval_index=None\n",
    "\n",
    "                        svc_results[block_multiplier][vid_type][p][tt]['pseudo'][bb]=decoding_utils.linearSVC_decoder(\n",
    "                            input_data=input_data,\n",
    "                            labels=temp_pred_var,\n",
    "                            crossval=crossval,\n",
    "                            crossval_index=pseudo_crossval_index,\n",
    "                            labels_as_index=labels_as_index\n",
    "                            )\n",
    "\n",
    "                    # svc_results[block_multiplier][vid_type][p][tt][nn]['trial_sel_idx']=trial_sel[subset_ind]\n",
    "                    # svc_results[block_multiplier][vid_type][p][tt][nn]['feature_sel_idx']=feature_subset\n",
    "\n",
    "    print(session_info.id+' done')\n",
    "\n",
    "    with open(os.path.join(savepath,session.id+'_'+filename), 'wb') as handle:\n",
    "        pickle.dump(svc_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block_ids']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath=r'\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\decoding results\\use_raw_video'\n",
    "# with open(os.path.join(savepath,session.id+'_'+filename), 'wb') as handle:\n",
    "#     pickle.dump(svc_results, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'trial_numbers', 'n_repeats', 'time_bins', 'balance_labels', 'frames', 'motion'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'620263_2022-07-26'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_info.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cr': {'0': {'precision': 0.7126436781609196,\n",
       "   'recall': 0.7230320699708455,\n",
       "   'f1-score': 0.7178002894356006,\n",
       "   'support': 343.0},\n",
       "  '1': {'precision': 0.703125,\n",
       "   'recall': 0.6923076923076923,\n",
       "   'f1-score': 0.6976744186046512,\n",
       "   'support': 325.0},\n",
       "  'accuracy': 0.7080838323353293,\n",
       "  'macro avg': {'precision': 0.7078843390804598,\n",
       "   'recall': 0.7076698811392689,\n",
       "   'f1-score': 0.7077373540201259,\n",
       "   'support': 668.0},\n",
       "  'weighted avg': {'precision': 0.7080125847443045,\n",
       "   'recall': 0.7080838323353293,\n",
       "   'f1-score': 0.708008510962459,\n",
       "   'support': 668.0}},\n",
       " 'pred_label': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0.]),\n",
       " 'true_label': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " 'trials_used': [[array([ 12,  18,  19,  24,  39,  40,  44,  53,  57,  64,  66,  72,  76,\n",
       "           87,  88,  91, 100, 103, 106, 115, 117, 118, 122, 125, 127, 128,\n",
       "          130, 136, 137, 141, 144, 149, 160, 163, 166, 167, 177, 182, 183,\n",
       "          191, 193, 194, 229, 236, 239, 240, 244, 252, 255, 260, 267, 270,\n",
       "          285, 293, 298, 307, 312, 317, 319, 320, 323, 326, 335, 336, 348,\n",
       "          353, 359, 370, 374, 375, 377, 379, 381, 386, 401, 412, 425, 435,\n",
       "          453, 458, 460, 471, 476, 482, 483, 489, 490, 492, 496, 502, 504,\n",
       "          510, 512, 515, 524, 527, 528, 537, 538, 545, 546, 549, 552, 561,\n",
       "          564, 570, 573, 575, 584, 587, 594, 595, 597, 599, 605, 607, 610,\n",
       "          611, 612, 614, 617, 618, 619, 623, 627, 629, 630, 632, 634, 639,\n",
       "          645, 652, 658, 667])],\n",
       "  [array([  9,  11,  13,  20,  22,  23,  26,  35,  38,  50,  61,  63,  69,\n",
       "           79,  81,  82,  85,  89,  94,  95,  96,  97, 105, 121, 124, 132,\n",
       "          135, 138, 139, 146, 148, 153, 157, 161, 172, 179, 185, 190, 192,\n",
       "          195, 199, 208, 216, 223, 233, 245, 247, 250, 251, 257, 258, 263,\n",
       "          264, 272, 276, 279, 281, 284, 288, 289, 296, 299, 309, 310, 315,\n",
       "          329, 332, 342, 343, 347, 352, 362, 363, 364, 366, 369, 380, 383,\n",
       "          394, 395, 397, 399, 402, 404, 406, 408, 413, 414, 419, 422, 424,\n",
       "          427, 428, 430, 439, 440, 441, 442, 446, 448, 449, 455, 461, 462,\n",
       "          468, 473, 475, 479, 481, 486, 491, 497, 498, 513, 526, 539, 540,\n",
       "          542, 550, 554, 556, 563, 578, 581, 590, 592, 600, 608, 609, 640,\n",
       "          648, 649, 661, 662])],\n",
       "  [array([  1,   4,   6,   7,   8,  17,  25,  29,  30,  31,  32,  34,  42,\n",
       "           52,  55,  56,  60,  65,  67,  68,  71,  74,  75,  92, 101, 108,\n",
       "          109, 123, 133, 140, 142, 147, 151, 173, 181, 184, 187, 196, 198,\n",
       "          201, 202, 203, 204, 205, 217, 220, 222, 224, 226, 232, 235, 241,\n",
       "          242, 253, 254, 261, 273, 275, 283, 290, 291, 292, 294, 325, 330,\n",
       "          334, 338, 339, 340, 341, 345, 346, 350, 354, 356, 357, 361, 365,\n",
       "          382, 384, 387, 392, 398, 405, 407, 418, 420, 421, 423, 434, 443,\n",
       "          447, 454, 456, 457, 465, 467, 474, 480, 484, 485, 499, 500, 506,\n",
       "          516, 520, 521, 522, 530, 534, 558, 559, 560, 562, 571, 576, 579,\n",
       "          580, 582, 585, 591, 593, 601, 603, 606, 621, 622, 628, 643, 651,\n",
       "          653, 656, 664, 665])],\n",
       "  [array([  0,   2,  15,  21,  27,  28,  36,  41,  46,  48,  49,  51,  59,\n",
       "           62,  73,  78,  80,  83,  86,  93,  98,  99, 102, 111, 113, 116,\n",
       "          126, 154, 168, 174, 175, 180, 200, 206, 207, 209, 210, 211, 212,\n",
       "          213, 214, 215, 221, 227, 231, 238, 243, 256, 259, 269, 271, 274,\n",
       "          280, 282, 287, 295, 302, 303, 304, 305, 313, 314, 316, 318, 322,\n",
       "          331, 351, 358, 360, 368, 372, 373, 376, 378, 390, 391, 403, 409,\n",
       "          410, 416, 426, 432, 433, 437, 438, 444, 445, 463, 466, 469, 477,\n",
       "          478, 487, 493, 501, 503, 507, 517, 523, 529, 535, 536, 541, 544,\n",
       "          547, 548, 553, 566, 567, 569, 574, 577, 583, 586, 588, 589, 596,\n",
       "          598, 602, 613, 616, 620, 624, 631, 633, 636, 637, 638, 642, 646,\n",
       "          647, 650, 659])],\n",
       "  [array([  3,   5,  10,  14,  16,  33,  37,  43,  45,  47,  54,  58,  70,\n",
       "           77,  84,  90, 104, 107, 110, 112, 114, 119, 120, 129, 131, 134,\n",
       "          143, 145, 150, 152, 155, 156, 158, 159, 162, 164, 165, 169, 170,\n",
       "          171, 176, 178, 186, 188, 189, 197, 218, 219, 225, 228, 230, 234,\n",
       "          237, 246, 248, 249, 262, 265, 266, 268, 277, 278, 286, 297, 300,\n",
       "          301, 306, 308, 311, 321, 324, 327, 328, 333, 337, 344, 349, 355,\n",
       "          367, 371, 385, 388, 389, 393, 396, 400, 411, 415, 417, 429, 431,\n",
       "          436, 450, 451, 452, 459, 464, 470, 472, 488, 494, 495, 505, 508,\n",
       "          509, 511, 514, 518, 519, 525, 531, 532, 533, 543, 551, 555, 557,\n",
       "          565, 568, 572, 604, 615, 625, 626, 635, 641, 644, 654, 655, 657,\n",
       "          660, 663, 666])]],\n",
       " 'decision_function': array([ 1.95596930e+00,  9.41534460e-01,  1.92086342e+00,  2.45250418e+00,\n",
       "         7.23250467e-01,  1.91950811e+00,  3.85806945e+00,  5.32646007e-01,\n",
       "         2.03532629e+00,  2.07483121e+00,  2.59400675e+00,  8.12944814e-01,\n",
       "         1.43764599e+00,  1.51743995e-01,  1.09006406e+00,  7.18805707e-01,\n",
       "         1.57851539e-01,  6.65402703e-01, -3.20334476e-01,  3.77846302e-02,\n",
       "         1.08664608e+00,  7.66757989e-01, -1.19812791e-01,  1.87180536e-01,\n",
       "         2.27352204e-01,  4.92657448e-01,  1.73010723e-01,  1.05545954e-01,\n",
       "         3.34881548e-01,  1.40357869e-01,  5.14061901e-01, -2.66396435e-02,\n",
       "         1.66030073e+00,  7.70457862e-01,  6.61137576e-01,  8.19337932e-01,\n",
       "         2.49362263e+00,  5.82075903e-01,  2.21198532e-01,  6.98364894e-01,\n",
       "         3.02023113e-01, -3.63439043e-01,  6.70260712e-01,  1.33838104e+00,\n",
       "         9.92511290e-01, -2.43051086e-01,  1.39962981e+00,  7.57558834e-01,\n",
       "        -1.27192240e-01,  3.47328720e-01,  8.60177875e-01,  1.79533819e+00,\n",
       "         1.76992038e-01,  1.96171145e+00,  4.09834984e-02,  2.43777196e-01,\n",
       "         4.39056441e-01,  3.30557340e-01,  1.37861640e+00, -2.21173217e-01,\n",
       "         7.77501198e-01,  6.84382941e-02,  6.93406304e-02,  4.19844683e+00,\n",
       "         1.08318964e+00,  4.96649172e-01, -1.66689234e-01,  1.79921626e-01,\n",
       "         1.25929846e+00, -5.36439227e-01,  3.28309631e+00,  4.18740514e-02,\n",
       "         2.14497977e+00,  1.60119773e+00,  1.31245024e+00, -7.32244228e-02,\n",
       "         1.37044713e+00,  3.95991193e-01,  8.50709292e-01, -1.88452442e-01,\n",
       "         5.59377083e-01,  7.05456172e+00,  7.09501929e-01, -3.58844623e-01,\n",
       "         2.16391881e-01,  4.01650748e+00,  8.00981231e-01,  3.39411768e-01,\n",
       "         8.04427030e-01,  1.73710894e+00,  5.43818424e-02,  8.90534783e-01,\n",
       "         1.07435667e+00,  1.39949432e+00,  5.92796422e-02,  3.40698630e-01,\n",
       "         2.18827886e-01,  1.72913005e+00, -2.01819315e-01,  7.29757050e-01,\n",
       "         7.39296755e-01,  8.61917941e-02,  9.24574024e-01,  6.37466658e-01,\n",
       "         2.40989889e-02,  1.08095374e+00,  2.20712443e-01,  1.98266177e+00,\n",
       "         2.50800174e+00,  1.43743312e-01,  1.42673814e-01, -7.70249345e-01,\n",
       "         1.25942680e-01, -8.09271350e-01,  1.80560549e-01,  2.98719312e-01,\n",
       "         1.47170923e-01, -1.87845839e-01,  3.48353818e-01, -9.95662120e-02,\n",
       "         4.67552659e-01, -6.18325982e-01, -1.03478515e-03, -2.74994037e-01,\n",
       "        -6.52952491e-01, -1.07754551e+00,  1.88593854e-01,  8.26597601e-01,\n",
       "         1.13765499e-01, -8.57141970e-01, -9.06836919e-02, -3.32164185e-01,\n",
       "         5.20095503e-01, -1.33411853e-01, -2.28989753e-01, -4.22926926e-01,\n",
       "        -1.83775946e-01, -5.07874379e-02, -2.14199600e-01, -3.27612179e-01,\n",
       "         4.05381735e-01, -2.37187457e-01,  1.54526900e-01,  1.89028915e-01,\n",
       "         3.29858339e-01, -4.74966288e-01, -2.54326869e-01,  1.69961123e-02,\n",
       "        -5.24716564e-01, -3.76060090e-01, -4.63565561e-01, -2.91768666e-01,\n",
       "        -6.31706746e-02,  5.32663308e-01, -3.15655329e-01,  1.44565533e+00,\n",
       "        -1.25505938e+00,  3.46999894e+00, -1.45197604e-01, -1.36843410e+00,\n",
       "        -6.90038553e-01,  3.24639987e-01, -6.93050320e-01, -8.85079129e-02,\n",
       "        -1.02386927e+00, -4.13583722e-01, -1.98357084e+00,  2.58704429e-01,\n",
       "        -6.22550600e-01, -5.26334224e-01, -1.26616842e+00, -2.60736402e-01,\n",
       "        -4.28284641e-01,  1.09137915e-01, -9.90784633e-01, -2.01956472e-01,\n",
       "        -6.24529166e-01,  2.79610291e-01, -1.62629958e-01, -2.04897149e-01,\n",
       "         6.65179250e-01, -3.31594550e-01, -3.63101028e-01, -6.56335793e-02,\n",
       "        -5.80433994e-01, -5.78970562e-01, -2.37487394e+00, -6.66110353e-01,\n",
       "         4.43251417e-01, -6.83288566e-02,  2.29645078e-01, -2.19371832e-01,\n",
       "        -1.17917986e+00,  6.15321405e-01, -5.76374966e-01, -4.33523577e-02,\n",
       "        -1.19002843e-01,  5.49764295e-01,  9.37351745e-02, -5.52004708e-01,\n",
       "        -2.14330959e-02, -1.91524401e-01,  5.16476452e-01, -2.18071065e-01,\n",
       "         2.70474359e-01,  5.86966115e-01,  6.83657619e-01, -3.50443754e-01,\n",
       "         7.92756191e-01, -4.05347434e-01, -3.72641522e-02,  1.05725033e+00,\n",
       "         4.02414392e-01,  1.85548287e-01, -6.93713091e-01, -4.40930281e-01,\n",
       "        -7.37227958e-02, -2.07440665e-01,  4.12611815e-01, -1.27539649e+00,\n",
       "        -4.80638640e-01,  2.99413536e-01, -1.79776930e-01, -6.00146388e-01,\n",
       "         1.41554284e-01, -2.04481208e-01, -1.34286870e-01, -9.66653838e-02,\n",
       "        -1.29866737e+00, -4.49054037e-01,  1.38274422e-01, -2.30044326e-01,\n",
       "        -1.97070159e-01,  1.30881708e-01,  4.55087077e-03, -1.73379277e-01,\n",
       "         1.04170409e-01, -8.35646865e-01, -4.28110116e-01,  2.84540567e-01,\n",
       "         7.15660512e-01, -3.68164485e-01,  2.18846498e-01, -5.83460149e-01,\n",
       "         4.07635462e-01,  6.95177171e-01,  5.41423618e-01,  5.93444683e+00,\n",
       "        -2.82461422e-01,  5.05619631e-01,  3.03767004e-01, -3.87481226e-01,\n",
       "        -1.97114085e-01,  9.08903027e-03, -1.01248746e+00, -4.69671336e-01,\n",
       "         4.41231757e+00, -6.35639573e-02,  1.53664678e-01,  3.68535890e-01,\n",
       "        -2.52041705e-01,  5.20662587e-02, -1.29852855e-01,  2.75920561e-01,\n",
       "        -5.65239250e-02,  5.05079356e-01, -1.27289422e-01,  5.85840012e-01,\n",
       "        -1.71548450e-01, -3.53767051e-02, -1.13773610e-01, -2.41700094e-01,\n",
       "         8.99752972e-01,  1.68469189e-01,  5.63649763e-01, -3.70656799e-01,\n",
       "         6.88398953e-02,  6.12723537e-01,  3.44755827e-03,  5.09395877e-02,\n",
       "         5.95752781e-01,  4.53482655e-02,  3.40914690e-01, -1.97331733e-01,\n",
       "         6.20481447e-01,  3.18369291e-01,  5.76245308e-01,  8.58536709e-01,\n",
       "        -1.13053964e-01, -2.89584032e-02,  5.07258267e-01,  3.30838238e-01,\n",
       "         1.35542496e-01, -4.63121858e-01, -7.92604881e-01, -1.54869819e-01,\n",
       "         3.40686204e-01, -2.34346320e-01,  1.13780843e+00,  1.88641869e-01,\n",
       "        -1.54429895e-01,  4.52326241e-02,  6.21856935e-01,  4.72432403e-01,\n",
       "         3.27217331e-01,  7.44614829e-03, -3.07091279e-01,  1.23607856e-02,\n",
       "         7.69467012e-01,  1.00436665e+00,  1.10283947e-01,  6.02192488e-01,\n",
       "        -3.61807609e-02,  1.34194787e-01,  2.29658975e-01, -7.83936699e-02,\n",
       "         4.85778097e-01, -2.07642366e-01,  8.95673954e-01,  4.31892682e-01,\n",
       "        -1.21642360e+00, -2.66169073e-01,  2.26876798e-01, -4.27300047e-01,\n",
       "        -3.38589914e-01,  1.12691560e-01, -2.97415320e-01,  9.44599183e-02,\n",
       "        -1.19900338e-01,  3.24715978e-01, -1.02354210e-01,  1.44030021e+00,\n",
       "         6.00656055e-01, -4.63160064e-01, -2.05494547e-01,  9.34716681e-01,\n",
       "         7.42459907e-01, -1.08523373e-01,  5.16095775e-02, -9.73296649e-02,\n",
       "        -1.08934464e+00, -6.70634599e-01, -7.08408662e-01, -4.64141076e-01,\n",
       "        -3.16771415e-01, -4.84332105e-01, -2.16760701e-01, -3.87041739e-01,\n",
       "        -1.92569664e-01, -4.80882657e-01, -4.94576810e-02, -1.01107435e+00,\n",
       "        -3.52445883e-01, -7.00421836e-01, -9.20159230e-01, -2.62231836e-01,\n",
       "        -4.25303686e-01, -9.23968410e-01, -3.52527976e-01,  6.13086463e-02,\n",
       "        -7.68675522e-01,  4.09298334e-01,  1.71985908e-01,  9.92671278e-01,\n",
       "         3.39282948e-01,  2.52420220e-01, -5.63414661e-01, -3.29632276e-01,\n",
       "        -1.57630418e-01, -1.55603381e-01, -6.67026146e-01,  1.01092520e-01,\n",
       "         1.57084129e-01, -1.09787655e+00,  4.45074832e-01, -5.24152690e-01,\n",
       "         5.24541741e-02, -3.97001417e-01,  1.04971028e-01, -3.84430115e-01,\n",
       "        -1.24644064e+00, -3.38435092e-01, -3.26440362e-01, -1.21154459e-01,\n",
       "        -1.14231915e-01, -5.16090421e-01,  6.96243911e-01, -1.37521207e-01,\n",
       "        -1.64436685e-01, -4.14837305e-01, -1.32155340e-01,  3.24708721e-02,\n",
       "         2.14995510e-01, -4.84325484e-02,  5.37488649e-01,  2.78423798e-01,\n",
       "        -4.99944781e-01,  8.84914485e-03, -1.29479078e+00, -5.19550527e-01,\n",
       "        -3.68959809e-01,  1.14844244e+00, -9.24390338e-01,  8.76592568e-01,\n",
       "        -9.65886249e-01,  2.78527781e-01, -9.52391766e-01, -6.96140232e-01,\n",
       "        -4.72708479e-01, -1.29698258e+00, -3.19226391e-01, -7.40844119e-01,\n",
       "        -3.01205281e-01, -6.36928206e-01, -1.81465150e-01,  3.58171524e-01,\n",
       "        -9.03416916e-01, -8.24381640e-01, -9.68431289e-02,  1.73425486e-01,\n",
       "        -3.60823757e-01,  3.78114627e-01, -6.59350435e-01, -3.36111133e-01,\n",
       "        -6.94669314e-01, -2.98585137e-01,  2.57642841e-01,  6.31686643e-02,\n",
       "        -5.33052931e-01,  1.32577259e+00, -2.92941820e-01, -2.77141091e-02,\n",
       "        -1.54233024e-01, -6.65165441e-01, -3.34982747e-01,  1.39715847e-01,\n",
       "         1.84551193e-01,  2.65946439e-01,  1.35335261e-01, -2.39442843e-01,\n",
       "         3.80445082e-01, -2.97176932e-01, -1.29572092e-01,  5.21761870e-01,\n",
       "        -4.85161640e-01,  4.86306319e-02, -2.44421295e-01,  9.56842977e-01,\n",
       "        -3.59361793e-01,  2.67871353e-01,  9.49009273e-01,  6.54505993e-01,\n",
       "         3.98525942e-02,  1.04525107e-01,  3.84970492e-01,  3.26984752e-01,\n",
       "         5.94272252e-03,  7.30117407e-01, -1.53028677e-01,  9.94023352e-02,\n",
       "         2.62203222e-01, -8.84778503e-02, -9.76130582e-01, -8.87369616e-01,\n",
       "        -2.35832774e+00,  3.07693564e-01,  3.76641469e-01, -4.46720865e-01,\n",
       "         1.95534451e-01,  2.31265069e-01,  2.66929104e-01, -1.49399099e-01,\n",
       "         1.07659301e-01,  1.57594472e-01,  1.89638272e+00, -2.44900882e-01,\n",
       "         1.51606459e-01,  3.32794876e-01,  3.57632888e-01,  3.19703879e-01,\n",
       "         7.14019502e-01, -5.77275900e-01,  3.61815596e-01, -3.29641281e-01,\n",
       "        -3.80290215e-01,  2.95790819e-02,  1.34108883e+00, -1.11136122e-01,\n",
       "         4.27826792e-01,  7.32584572e-01, -5.35388624e-01,  1.39094434e-01,\n",
       "         4.96872432e-01,  4.24272629e-01, -4.14161967e-01, -4.11477405e-01,\n",
       "         1.53485021e-01,  5.39296755e-01, -7.66237263e-02, -1.18367572e-01,\n",
       "        -1.77924753e-01, -1.00012240e-01,  6.87228085e-01, -3.25716874e-01,\n",
       "         4.75244207e-01,  6.45186284e-01, -2.24650342e-01,  4.03206988e-01,\n",
       "         4.72669261e-01,  1.08192350e-01,  3.00478592e-01, -3.71917499e-01,\n",
       "         4.30178943e-01, -1.01321637e+00,  1.11304172e+00, -2.23898392e+00,\n",
       "         7.44142383e-01,  2.48123494e-01, -5.34536626e-02, -1.68709783e-01,\n",
       "         1.39768862e-01,  9.87985950e-01, -3.46010653e-01, -8.77241524e-02,\n",
       "         5.85676299e-01,  1.06351607e+00, -3.24714594e-01,  1.62510636e+00,\n",
       "        -1.02682039e+00,  5.65201266e-01, -2.77532938e-01,  3.75812245e-02,\n",
       "         3.51816385e-01, -4.99575740e-02,  7.55143302e-02, -7.88135112e-01,\n",
       "        -1.32083672e-01,  3.36000252e+00, -3.20162227e+00,  9.28851718e-01,\n",
       "         6.24684672e-01,  2.58110392e-01, -2.04883637e-01,  4.83271607e-01,\n",
       "         1.54099103e+00,  2.17244798e-01,  1.21598351e+00,  8.16251566e-01,\n",
       "        -7.95665465e-02,  4.20133601e-02,  4.54203556e-02,  5.26343300e-01,\n",
       "        -1.06356660e-01,  7.34222057e-02,  1.92981858e-01,  4.65532301e-01,\n",
       "         2.16731356e-01, -1.47118867e-01, -6.74077518e-01,  1.83197382e-02,\n",
       "        -2.20138012e-01,  2.11445752e-01, -1.60536367e-01,  2.86958542e-01,\n",
       "         1.05667745e-01, -6.77118787e-02, -3.03579647e-01,  3.38329346e-01,\n",
       "        -2.58805023e+00,  1.13538380e+00, -1.38327814e-01, -5.60456314e-01,\n",
       "        -7.96928780e-01, -7.57290974e-01, -9.91233713e-01,  2.34991266e-01,\n",
       "        -2.52311368e-01, -5.87639788e-01, -3.41037510e-01, -7.89396636e-01,\n",
       "        -1.08778461e+00,  4.28947564e-01, -5.92710262e-01, -1.47127337e+00,\n",
       "        -1.18441550e+00, -5.31666307e-01, -9.99696165e-01, -9.89418954e-01,\n",
       "        -5.01019977e-01, -9.24862149e-01, -7.42180999e-01, -5.86367559e-01,\n",
       "        -4.88806341e-01, -7.16449990e-01, -3.56411322e-01, -1.37797659e+00,\n",
       "        -6.13317292e-01, -1.19171992e+00,  7.67373005e-01, -9.93019388e-01,\n",
       "        -7.57827160e-01, -2.62822432e-01, -7.94966634e-01, -1.15195813e+00,\n",
       "        -9.17240780e-01, -5.81327353e-01, -3.01984378e-01, -9.78694336e-01,\n",
       "        -6.13839001e-01, -4.27718633e-01, -1.22555465e+00, -1.02623625e+00,\n",
       "        -9.75135514e-01, -7.18464417e-01, -1.37426713e+00, -1.24823982e-01,\n",
       "        -1.65001600e-01, -6.10805912e-01, -1.56324466e+00, -5.41238654e-01,\n",
       "         3.63232717e-01, -8.02804381e-01, -5.07976684e-01, -8.34059045e-01,\n",
       "        -1.05503214e+00, -7.08250969e-01, -1.52665996e+00, -1.16122082e+00,\n",
       "        -5.03786109e-01, -1.00541091e+00, -1.18769784e+00, -5.70223012e-01,\n",
       "        -7.26101574e-01,  4.64589837e-01, -2.12224723e-01, -6.40525595e-01,\n",
       "        -2.56571919e-01, -7.62210127e-01,  3.08374543e-02, -6.92263776e-01,\n",
       "        -6.32128520e-01, -6.55920955e-01, -4.74665450e-01, -9.06593747e-01,\n",
       "        -4.00442219e-01, -8.03945516e-01, -6.48292530e-01, -6.88871134e-01,\n",
       "        -6.94963465e-01, -6.70395275e-01, -9.85150371e-01, -4.10250381e-01,\n",
       "        -2.47469123e-01,  2.92385945e+00, -1.07656173e+00, -4.56180587e-01,\n",
       "        -1.36117488e+00, -5.48329321e-01, -5.26826617e-01, -8.90181266e-01,\n",
       "        -6.17311497e-01, -5.52683459e-01, -7.27631268e-01,  6.74524384e-01,\n",
       "        -9.70749630e-01, -1.39591108e-01, -7.20727987e-01, -2.03171214e-01]),\n",
       " 'coefs': [array([[ 8.83701658e-05,  6.37887801e-05,  5.76315730e-05, ...,\n",
       "           2.94234730e-05, -9.49337135e-06,  7.37354486e-05]]),\n",
       "  array([[5.51579351e-05, 6.91505422e-05, 6.16900781e-05, ...,\n",
       "          3.90168847e-05, 5.16011970e-05, 1.74951525e-05]]),\n",
       "  array([[-1.59500386e-06,  4.21446431e-05,  4.08910796e-05, ...,\n",
       "           4.82334246e-05,  5.81545163e-05,  3.96690382e-05]]),\n",
       "  array([[2.62081567e-05, 5.99757608e-05, 5.99757608e-05, ...,\n",
       "          4.57651579e-05, 2.87942335e-05, 5.28004635e-05]]),\n",
       "  array([[ 1.16552199e-05,  5.32929272e-05,  4.76506125e-05, ...,\n",
       "          -2.49183053e-05, -8.70175400e-05, -3.76843220e-05]])],\n",
       " 'classes': [array([0, 1], dtype=int64),\n",
       "  array([0, 1], dtype=int64),\n",
       "  array([0, 1], dtype=int64),\n",
       "  array([0, 1], dtype=int64),\n",
       "  array([0, 1], dtype=int64)],\n",
       " 'intercept': [array([-7.01049576e-06]),\n",
       "  array([-5.29824423e-06]),\n",
       "  array([-1.01316037e-05]),\n",
       "  array([-4.46485676e-06]),\n",
       "  array([-3.85361771e-06])],\n",
       " 'params': [{'C': 1.0,\n",
       "   'class_weight': 'balanced',\n",
       "   'dual': 'auto',\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5000,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'random_state': None,\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0},\n",
       "  {'C': 1.0,\n",
       "   'class_weight': 'balanced',\n",
       "   'dual': 'auto',\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5000,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'random_state': None,\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0},\n",
       "  {'C': 1.0,\n",
       "   'class_weight': 'balanced',\n",
       "   'dual': 'auto',\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5000,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'random_state': None,\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0},\n",
       "  {'C': 1.0,\n",
       "   'class_weight': 'balanced',\n",
       "   'dual': 'auto',\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5000,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'random_state': None,\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0},\n",
       "  {'C': 1.0,\n",
       "   'class_weight': 'balanced',\n",
       "   'dual': 'auto',\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5000,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'random_state': None,\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0}],\n",
       " 'balanced_accuracy': 0.7076698811392689,\n",
       " 'pred_label_train': array([1, 1, 1, ..., 0, 0, 0], dtype=int64),\n",
       " 'true_label_train': array([1, 1, 1, ..., 0, 0, 0], dtype=int64),\n",
       " 'cr_train': {'0': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 1372.0},\n",
       "  '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1300.0},\n",
       "  'accuracy': 1.0,\n",
       "  'macro avg': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 2672.0},\n",
       "  'weighted avg': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 2672.0}},\n",
       " 'balanced_accuracy_train': 1.0,\n",
       " 'train_trials': [array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
       "          14,  15,  16,  17,  20,  21,  22,  23,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  33,  34,  35,  36,  37,  38,  41,  42,  43,  45,\n",
       "          46,  47,  48,  49,  50,  51,  52,  54,  55,  56,  58,  59,  60,\n",
       "          61,  62,  63,  65,  67,  68,  69,  70,  71,  73,  74,  75,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  89,  90,  92,  93,\n",
       "          94,  95,  96,  97,  98,  99, 101, 102, 104, 105, 107, 108, 109,\n",
       "         110, 111, 112, 113, 114, 116, 119, 120, 121, 123, 124, 126, 129,\n",
       "         131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 145, 146, 147,\n",
       "         148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162,\n",
       "         164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179,\n",
       "         180, 181, 184, 185, 186, 187, 188, 189, 190, 192, 195, 196, 197,\n",
       "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
       "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "         224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 237, 238,\n",
       "         241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 253, 254, 256,\n",
       "         257, 258, 259, 261, 262, 263, 264, 265, 266, 268, 269, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286,\n",
       "         287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 299, 300, 301,\n",
       "         302, 303, 304, 305, 306, 308, 309, 310, 311, 313, 314, 315, 316,\n",
       "         318, 321, 322, 324, 325, 327, 328, 329, 330, 331, 332, 333, 334,\n",
       "         337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350,\n",
       "         351, 352, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365,\n",
       "         366, 367, 368, 369, 371, 372, 373, 376, 378, 380, 382, 383, 384,\n",
       "         385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
       "         399, 400, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 413,\n",
       "         414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427,\n",
       "         428, 429, 430, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441,\n",
       "         442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 454, 455,\n",
       "         456, 457, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
       "         472, 473, 474, 475, 477, 478, 479, 480, 481, 484, 485, 486, 487,\n",
       "         488, 491, 493, 494, 495, 497, 498, 499, 500, 501, 503, 505, 506,\n",
       "         507, 508, 509, 511, 513, 514, 516, 517, 518, 519, 520, 521, 522,\n",
       "         523, 525, 526, 529, 530, 531, 532, 533, 534, 535, 536, 539, 540,\n",
       "         541, 542, 543, 544, 547, 548, 550, 551, 553, 554, 555, 556, 557,\n",
       "         558, 559, 560, 562, 563, 565, 566, 567, 568, 569, 571, 572, 574,\n",
       "         576, 577, 578, 579, 580, 581, 582, 583, 585, 586, 588, 589, 590,\n",
       "         591, 592, 593, 596, 598, 600, 601, 602, 603, 604, 606, 608, 609,\n",
       "         613, 615, 616, 620, 621, 622, 624, 625, 626, 628, 631, 633, 635,\n",
       "         636, 637, 638, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650,\n",
       "         651, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 664, 665,\n",
       "         666]),\n",
       "  array([  0,   1,   2,   3,   4,   5,   6,   7,   8,  10,  12,  14,  15,\n",
       "          16,  17,  18,  19,  21,  24,  25,  27,  28,  29,  30,  31,  32,\n",
       "          33,  34,  36,  37,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
       "          48,  49,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  62,\n",
       "          64,  65,  66,  67,  68,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  80,  83,  84,  86,  87,  88,  90,  91,  92,  93,  98,  99,\n",
       "         100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "         114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 127, 128,\n",
       "         129, 130, 131, 133, 134, 136, 137, 140, 141, 142, 143, 144, 145,\n",
       "         147, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 162, 163,\n",
       "         164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177,\n",
       "         178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194,\n",
       "         196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210,\n",
       "         211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225,\n",
       "         226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239,\n",
       "         240, 241, 242, 243, 244, 246, 248, 249, 252, 253, 254, 255, 256,\n",
       "         259, 260, 261, 262, 265, 266, 267, 268, 269, 270, 271, 273, 274,\n",
       "         275, 277, 278, 280, 282, 283, 285, 286, 287, 290, 291, 292, 293,\n",
       "         294, 295, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
       "         311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 330, 331, 333, 334, 335, 336, 337, 338, 339,\n",
       "         340, 341, 344, 345, 346, 348, 349, 350, 351, 353, 354, 355, 356,\n",
       "         357, 358, 359, 360, 361, 365, 367, 368, 370, 371, 372, 373, 374,\n",
       "         375, 376, 377, 378, 379, 381, 382, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 396, 398, 400, 401, 403, 405, 407, 409, 410,\n",
       "         411, 412, 415, 416, 417, 418, 420, 421, 423, 425, 426, 429, 431,\n",
       "         432, 433, 434, 435, 436, 437, 438, 443, 444, 445, 447, 450, 451,\n",
       "         452, 453, 454, 456, 457, 458, 459, 460, 463, 464, 465, 466, 467,\n",
       "         469, 470, 471, 472, 474, 476, 477, 478, 480, 482, 483, 484, 485,\n",
       "         487, 488, 489, 490, 492, 493, 494, 495, 496, 499, 500, 501, 502,\n",
       "         503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516,\n",
       "         517, 518, 519, 520, 521, 522, 523, 524, 525, 527, 528, 529, 530,\n",
       "         531, 532, 533, 534, 535, 536, 537, 538, 541, 543, 544, 545, 546,\n",
       "         547, 548, 549, 551, 552, 553, 555, 557, 558, 559, 560, 561, 562,\n",
       "         564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
       "         577, 579, 580, 582, 583, 584, 585, 586, 587, 588, 589, 591, 593,\n",
       "         594, 595, 596, 597, 598, 599, 601, 602, 603, 604, 605, 606, 607,\n",
       "         610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622,\n",
       "         623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635,\n",
       "         636, 637, 638, 639, 641, 642, 643, 644, 645, 646, 647, 650, 651,\n",
       "         652, 653, 654, 655, 656, 657, 658, 659, 660, 663, 664, 665, 666,\n",
       "         667]),\n",
       "  array([  0,   2,   3,   5,   9,  10,  11,  12,  13,  14,  15,  16,  18,\n",
       "          19,  20,  21,  22,  23,  24,  26,  27,  28,  33,  35,  36,  37,\n",
       "          38,  39,  40,  41,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          53,  54,  57,  58,  59,  61,  62,  63,  64,  66,  69,  70,  72,\n",
       "          73,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "          88,  89,  90,  91,  93,  94,  95,  96,  97,  98,  99, 100, 102,\n",
       "         103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "         118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "         132, 134, 135, 136, 137, 138, 139, 141, 143, 144, 145, 146, 148,\n",
       "         149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
       "         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176,\n",
       "         177, 178, 179, 180, 182, 183, 185, 186, 188, 189, 190, 191, 192,\n",
       "         193, 194, 195, 197, 199, 200, 206, 207, 208, 209, 210, 211, 212,\n",
       "         213, 214, 215, 216, 218, 219, 221, 223, 225, 227, 228, 229, 230,\n",
       "         231, 233, 234, 236, 237, 238, 239, 240, 243, 244, 245, 246, 247,\n",
       "         248, 249, 250, 251, 252, 255, 256, 257, 258, 259, 260, 262, 263,\n",
       "         264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 276, 277, 278,\n",
       "         279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 293, 295, 296,\n",
       "         297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "         323, 324, 326, 327, 328, 329, 331, 332, 333, 335, 336, 337, 342,\n",
       "         343, 344, 347, 348, 349, 351, 352, 353, 355, 358, 359, 360, 362,\n",
       "         363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 383, 385, 386, 388, 389, 390, 391, 393,\n",
       "         394, 395, 396, 397, 399, 400, 401, 402, 403, 404, 406, 408, 409,\n",
       "         410, 411, 412, 413, 414, 415, 416, 417, 419, 422, 424, 425, 426,\n",
       "         427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440,\n",
       "         441, 442, 444, 445, 446, 448, 449, 450, 451, 452, 453, 455, 458,\n",
       "         459, 460, 461, 462, 463, 464, 466, 468, 469, 470, 471, 472, 473,\n",
       "         475, 476, 477, 478, 479, 481, 482, 483, 486, 487, 488, 489, 490,\n",
       "         491, 492, 493, 494, 495, 496, 497, 498, 501, 502, 503, 504, 505,\n",
       "         507, 508, 509, 510, 511, 512, 513, 514, 515, 517, 518, 519, 523,\n",
       "         524, 525, 526, 527, 528, 529, 531, 532, 533, 535, 536, 537, 538,\n",
       "         539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
       "         552, 553, 554, 555, 556, 557, 561, 563, 564, 565, 566, 567, 568,\n",
       "         569, 570, 572, 573, 574, 575, 577, 578, 581, 583, 584, 586, 587,\n",
       "         588, 589, 590, 592, 594, 595, 596, 597, 598, 599, 600, 602, 604,\n",
       "         605, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618,\n",
       "         619, 620, 623, 624, 625, 626, 627, 629, 630, 631, 632, 633, 634,\n",
       "         635, 636, 637, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648,\n",
       "         649, 650, 652, 654, 655, 657, 658, 659, 660, 661, 662, 663, 666,\n",
       "         667]),\n",
       "  array([  1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          16,  17,  18,  19,  20,  22,  23,  24,  25,  26,  29,  30,  31,\n",
       "          32,  33,  34,  35,  37,  38,  39,  40,  42,  43,  44,  45,  47,\n",
       "          50,  52,  53,  54,  55,  56,  57,  58,  60,  61,  63,  64,  65,\n",
       "          66,  67,  68,  69,  70,  71,  72,  74,  75,  76,  77,  79,  81,\n",
       "          82,  84,  85,  87,  88,  89,  90,  91,  92,  94,  95,  96,  97,\n",
       "         100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130,\n",
       "         131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157,\n",
       "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171,\n",
       "         172, 173, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187,\n",
       "         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201,\n",
       "         202, 203, 204, 205, 208, 216, 217, 218, 219, 220, 222, 223, 224,\n",
       "         225, 226, 228, 229, 230, 232, 233, 234, 235, 236, 237, 239, 240,\n",
       "         241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
       "         255, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270,\n",
       "         272, 273, 275, 276, 277, 278, 279, 281, 283, 284, 285, 286, 288,\n",
       "         289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 306,\n",
       "         307, 308, 309, 310, 311, 312, 315, 317, 319, 320, 321, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338,\n",
       "         339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352,\n",
       "         353, 354, 355, 356, 357, 359, 361, 362, 363, 364, 365, 366, 367,\n",
       "         369, 370, 371, 374, 375, 377, 379, 380, 381, 382, 383, 384, 385,\n",
       "         386, 387, 388, 389, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
       "         401, 402, 404, 405, 406, 407, 408, 411, 412, 413, 414, 415, 417,\n",
       "         418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431,\n",
       "         434, 435, 436, 439, 440, 441, 442, 443, 446, 447, 448, 449, 450,\n",
       "         451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464,\n",
       "         465, 467, 468, 470, 471, 472, 473, 474, 475, 476, 479, 480, 481,\n",
       "         482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 496,\n",
       "         497, 498, 499, 500, 502, 504, 505, 506, 508, 509, 510, 511, 512,\n",
       "         513, 514, 515, 516, 518, 519, 520, 521, 522, 524, 525, 526, 527,\n",
       "         528, 530, 531, 532, 533, 534, 537, 538, 539, 540, 542, 543, 545,\n",
       "         546, 549, 550, 551, 552, 554, 555, 556, 557, 558, 559, 560, 561,\n",
       "         562, 563, 564, 565, 568, 570, 571, 572, 573, 575, 576, 578, 579,\n",
       "         580, 581, 582, 584, 585, 587, 590, 591, 592, 593, 594, 595, 597,\n",
       "         599, 600, 601, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
       "         614, 615, 617, 618, 619, 621, 622, 623, 625, 626, 627, 628, 629,\n",
       "         630, 632, 634, 635, 639, 640, 641, 643, 644, 645, 648, 649, 651,\n",
       "         652, 653, 654, 655, 656, 657, 658, 660, 661, 662, 663, 664, 665,\n",
       "         666, 667]),\n",
       "  array([  0,   1,   2,   4,   6,   7,   8,   9,  11,  12,  13,  15,  17,\n",
       "          18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,\n",
       "          31,  32,  34,  35,  36,  38,  39,  40,  41,  42,  44,  46,  48,\n",
       "          49,  50,  51,  52,  53,  55,  56,  57,  59,  60,  61,  62,  63,\n",
       "          64,  65,  66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,\n",
       "          79,  80,  81,  82,  83,  85,  86,  87,  88,  89,  91,  92,  93,\n",
       "          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 105, 106, 108,\n",
       "         109, 111, 113, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126,\n",
       "         127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         144, 146, 147, 148, 149, 151, 153, 154, 157, 160, 161, 163, 166,\n",
       "         167, 168, 172, 173, 174, 175, 177, 179, 180, 181, 182, 183, 184,\n",
       "         185, 187, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201,\n",
       "         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
       "         215, 216, 217, 220, 221, 222, 223, 224, 226, 227, 229, 231, 232,\n",
       "         233, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 247, 250,\n",
       "         251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264,\n",
       "         267, 269, 270, 271, 272, 273, 274, 275, 276, 279, 280, 281, 282,\n",
       "         283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
       "         298, 299, 302, 303, 304, 305, 307, 309, 310, 312, 313, 314, 315,\n",
       "         316, 317, 318, 319, 320, 322, 323, 325, 326, 329, 330, 331, 332,\n",
       "         334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348,\n",
       "         350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "         364, 365, 366, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378,\n",
       "         379, 380, 381, 382, 383, 384, 386, 387, 390, 391, 392, 394, 395,\n",
       "         397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
       "         412, 413, 414, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "         427, 428, 430, 432, 433, 434, 435, 437, 438, 439, 440, 441, 442,\n",
       "         443, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458,\n",
       "         460, 461, 462, 463, 465, 466, 467, 468, 469, 471, 473, 474, 475,\n",
       "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 489,\n",
       "         490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
       "         506, 507, 510, 512, 513, 515, 516, 517, 520, 521, 522, 523, 524,\n",
       "         526, 527, 528, 529, 530, 534, 535, 536, 537, 538, 539, 540, 541,\n",
       "         542, 544, 545, 546, 547, 548, 549, 550, 552, 553, 554, 556, 558,\n",
       "         559, 560, 561, 562, 563, 564, 566, 567, 569, 570, 571, 573, 574,\n",
       "         575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
       "         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600,\n",
       "         601, 602, 603, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614,\n",
       "         616, 617, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630,\n",
       "         631, 632, 633, 634, 636, 637, 638, 639, 640, 642, 643, 645, 646,\n",
       "         647, 648, 649, 650, 651, 652, 653, 656, 658, 659, 661, 662, 664,\n",
       "         665, 667])],\n",
       " 'test_trials': [array([ 12,  18,  19,  24,  39,  40,  44,  53,  57,  64,  66,  72,  76,\n",
       "          87,  88,  91, 100, 103, 106, 115, 117, 118, 122, 125, 127, 128,\n",
       "         130, 136, 137, 141, 144, 149, 160, 163, 166, 167, 177, 182, 183,\n",
       "         191, 193, 194, 229, 236, 239, 240, 244, 252, 255, 260, 267, 270,\n",
       "         285, 293, 298, 307, 312, 317, 319, 320, 323, 326, 335, 336, 348,\n",
       "         353, 359, 370, 374, 375, 377, 379, 381, 386, 401, 412, 425, 435,\n",
       "         453, 458, 460, 471, 476, 482, 483, 489, 490, 492, 496, 502, 504,\n",
       "         510, 512, 515, 524, 527, 528, 537, 538, 545, 546, 549, 552, 561,\n",
       "         564, 570, 573, 575, 584, 587, 594, 595, 597, 599, 605, 607, 610,\n",
       "         611, 612, 614, 617, 618, 619, 623, 627, 629, 630, 632, 634, 639,\n",
       "         645, 652, 658, 667]),\n",
       "  array([  9,  11,  13,  20,  22,  23,  26,  35,  38,  50,  61,  63,  69,\n",
       "          79,  81,  82,  85,  89,  94,  95,  96,  97, 105, 121, 124, 132,\n",
       "         135, 138, 139, 146, 148, 153, 157, 161, 172, 179, 185, 190, 192,\n",
       "         195, 199, 208, 216, 223, 233, 245, 247, 250, 251, 257, 258, 263,\n",
       "         264, 272, 276, 279, 281, 284, 288, 289, 296, 299, 309, 310, 315,\n",
       "         329, 332, 342, 343, 347, 352, 362, 363, 364, 366, 369, 380, 383,\n",
       "         394, 395, 397, 399, 402, 404, 406, 408, 413, 414, 419, 422, 424,\n",
       "         427, 428, 430, 439, 440, 441, 442, 446, 448, 449, 455, 461, 462,\n",
       "         468, 473, 475, 479, 481, 486, 491, 497, 498, 513, 526, 539, 540,\n",
       "         542, 550, 554, 556, 563, 578, 581, 590, 592, 600, 608, 609, 640,\n",
       "         648, 649, 661, 662]),\n",
       "  array([  1,   4,   6,   7,   8,  17,  25,  29,  30,  31,  32,  34,  42,\n",
       "          52,  55,  56,  60,  65,  67,  68,  71,  74,  75,  92, 101, 108,\n",
       "         109, 123, 133, 140, 142, 147, 151, 173, 181, 184, 187, 196, 198,\n",
       "         201, 202, 203, 204, 205, 217, 220, 222, 224, 226, 232, 235, 241,\n",
       "         242, 253, 254, 261, 273, 275, 283, 290, 291, 292, 294, 325, 330,\n",
       "         334, 338, 339, 340, 341, 345, 346, 350, 354, 356, 357, 361, 365,\n",
       "         382, 384, 387, 392, 398, 405, 407, 418, 420, 421, 423, 434, 443,\n",
       "         447, 454, 456, 457, 465, 467, 474, 480, 484, 485, 499, 500, 506,\n",
       "         516, 520, 521, 522, 530, 534, 558, 559, 560, 562, 571, 576, 579,\n",
       "         580, 582, 585, 591, 593, 601, 603, 606, 621, 622, 628, 643, 651,\n",
       "         653, 656, 664, 665]),\n",
       "  array([  0,   2,  15,  21,  27,  28,  36,  41,  46,  48,  49,  51,  59,\n",
       "          62,  73,  78,  80,  83,  86,  93,  98,  99, 102, 111, 113, 116,\n",
       "         126, 154, 168, 174, 175, 180, 200, 206, 207, 209, 210, 211, 212,\n",
       "         213, 214, 215, 221, 227, 231, 238, 243, 256, 259, 269, 271, 274,\n",
       "         280, 282, 287, 295, 302, 303, 304, 305, 313, 314, 316, 318, 322,\n",
       "         331, 351, 358, 360, 368, 372, 373, 376, 378, 390, 391, 403, 409,\n",
       "         410, 416, 426, 432, 433, 437, 438, 444, 445, 463, 466, 469, 477,\n",
       "         478, 487, 493, 501, 503, 507, 517, 523, 529, 535, 536, 541, 544,\n",
       "         547, 548, 553, 566, 567, 569, 574, 577, 583, 586, 588, 589, 596,\n",
       "         598, 602, 613, 616, 620, 624, 631, 633, 636, 637, 638, 642, 646,\n",
       "         647, 650, 659]),\n",
       "  array([  3,   5,  10,  14,  16,  33,  37,  43,  45,  47,  54,  58,  70,\n",
       "          77,  84,  90, 104, 107, 110, 112, 114, 119, 120, 129, 131, 134,\n",
       "         143, 145, 150, 152, 155, 156, 158, 159, 162, 164, 165, 169, 170,\n",
       "         171, 176, 178, 186, 188, 189, 197, 218, 219, 225, 228, 230, 234,\n",
       "         237, 246, 248, 249, 262, 265, 266, 268, 277, 278, 286, 297, 300,\n",
       "         301, 306, 308, 311, 321, 324, 327, 328, 333, 337, 344, 349, 355,\n",
       "         367, 371, 385, 388, 389, 393, 396, 400, 411, 415, 417, 429, 431,\n",
       "         436, 450, 451, 452, 459, 464, 470, 472, 488, 494, 495, 505, 508,\n",
       "         509, 511, 514, 518, 519, 525, 531, 532, 533, 543, 551, 555, 557,\n",
       "         565, 568, 572, 604, 615, 625, 626, 635, 641, 644, 654, 655, 657,\n",
       "         660, 663, 666])],\n",
       " 'models': [LinearSVC(class_weight='balanced', dual='auto', max_iter=5000),\n",
       "  LinearSVC(class_weight='balanced', dual='auto', max_iter=5000),\n",
       "  LinearSVC(class_weight='balanced', dual='auto', max_iter=5000),\n",
       "  LinearSVC(class_weight='balanced', dual='auto', max_iter=5000),\n",
       "  LinearSVC(class_weight='balanced', dual='auto', max_iter=5000)],\n",
       " 'scaler': RobustScaler(),\n",
       " 'label_names': array(['aud', 'vis'], dtype='<U3'),\n",
       " 'labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " 'trial_sel_idx': Int64Index([  5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "             ...\n",
       "             663, 664, 665, 666, 667, 668, 669, 670, 671, 672],\n",
       "            dtype='int64', name='id', length=668),\n",
       " 'feature_sel_idx': array([     0,      1,      2, ..., 323733, 323734, 323735])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_results['frames']['block_ids'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SessionInfo(id='620263_2022-07-26', project='TempletonPilotSession', is_ephys=True, is_sync=True, allen_path=WindowsUPath('//allen/programs/mindscope/workgroups/templeton/TTOC/2022-07-26_14-09-36_620263'), experiment_day=1, session_kwargs={}, notes='', issues=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ephys_sessions[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npc_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
